                                                                                     NamasteSQL

Q 1 - Return Orders Customer Feedback:
Statement - Namastekart, an e-commerce company, has observed a notable surge in return orders recently. They suspect that a specific group of customers may be responsible for a significant portion of these returns. To address this issue, their initial goal is to identify customers who have returned more than 50% of their orders. This way, they can proactively reach out to these customers to gather feedback.

Write an SQL to find list of customers along with their return percent (Round to 2 decimal places), display the output in ascending order of customer name.

Table: 

CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    order_date DATE,
    customer_name VARCHAR(50),
    sales DECIMAL(10, 2)
);

INSERT INTO orders (order_id, order_date, customer_name, sales) VALUES
(1, '2023-01-01', 'Alexa', 100),
(2, '2023-01-02', 'Alexa', 200),
(3, '2023-01-03', 'Alexa', 300),
(4, '2023-01-03', 'Alexa', 400),
(5, '2023-01-01', 'Ramesh', 500),
(6, '2023-01-02', 'Ramesh', 600),
(7, '2023-01-03', 'Ramesh', 700),
(8, '2023-01-03', 'Neha', 800),
(9, '2023-01-03', 'Ankit', 800),
(10, '2023-01-04', 'Ankit', 900);


CREATE TABLE returns (
    order_id INT,
    return_date DATE
);

INSERT INTO returns (order_id, return_date) VALUES
(1, '2023-01-02'),
(2, '2023-01-04'),
(3, '2023-01-05'),
(7, '2023-01-06'),
(9, '2023-01-06'),
(10, '2023-01-07');


Output:
+---------------+----------------+
| customer_name | return_percent |
+---------------+----------------+
| Alexa         |          75.00 |
| Ankit         |         100.00 |
+---------------+----------------+


-------------------------------------------------------------------------------------------------------------------------------------------


Q 2 - Product Category
Statement - You are provided with a table named Products containing information about various products, including their names and prices. Write a SQL query to count number of products in each category based on its price into three categories below. Display the output in descending order of no of products.

 

1- "Low Price" for products with a price less than 100
2- "Medium Price" for products with a price between 100 and 500 (inclusive)
3- "High Price" for products with a price greater than 500.

Tables: 

CREATE TABLE products (
    product_id INT,
    product_name VARCHAR(255),
    price DECIMAL(10, 2)
);

INSERT INTO products (product_id, product_name, price) VALUES
(1, 'Laptop', 800),
(2, 'Smartphone', 600),
(3, 'Headphones', 50),
(4, 'Tablet', 400),
(5, 'Keyboard', 30),
(6, 'Mouse', 15),
(7, 'Monitor', 350),
(8, 'Printer', 120),
(9, 'USB Drive', 10),
(10, 'External Hard Drive', 150),
(11, 'Wireless Router', 80),
(12, 'Bluetooth Speaker', 70),
(13, 'Webcam', 45),
(14, 'Microphone', 25),
(15, 'Gaming Mouse', 50);


Output:

+--------------+----------------+
| category     | no_of_products |
+--------------+----------------+
| Low Price    |              9 |
| Medium Price |              4 |
| High Price   |              2 |
+--------------+----------------+


-------------------------------------------------------------------------------------------------------------------------------------------

Q 3 - LinkedIn Top Voice

Statement - LinkedIn is a professional social networking app. They want to give top voice badge to their best creators to encourage them to create more quality content. A creator qualifies for the badge if he/she satisfies following criteria.

 

1- Creator should have more than 50k followers.
2- Creator should have more than 100k impressions on the posts that they published in the month of Dec-2023.
3- Creator should have published atleast 3 posts in Dec-2023.

 

Write a SQL to get the list of top voice creators name along with no of posts and impressions by them in the month of Dec-2023.


Tables:

CREATE TABLE creators (
    creator_id INT,
    creator_name VARCHAR(255),
    followers INT
);

INSERT INTO creators (creator_id, creator_name, followers) VALUES
(1, 'Pavitra Nataraj', 900),
(2, 'Ankit Bansal', 150000),
(3, 'Rahul Gupta', 70000),
(4, 'Shomil Sharma', 55000);


CREATE TABLE posts (
    creator_id INT,
    post_id VARCHAR(10),
    publish_date DATE,
    impressions INT
);

INSERT INTO posts (creator_id, post_id, publish_date, impressions) VALUES
(1, 'p1', '2023-12-03', 120000),
(2, 'p2', '2023-12-02', 51000),
(2, 'p3', '2023-12-09', 39000),
(2, 'p4', '2023-12-20', 42000),
(3, 'p5', '2023-11-20', 22000),
(3, 'p6', '2023-12-04', 32000),
(3, 'p7', '2023-12-10', 22000),
(3, 'p8', '2023-12-01', 41000),
(4, 'p9', '2023-12-03', 41000),
(4, 'p10', '2023-12-04', 71000);




Output - 

+--------------+-------------+-------------------+
| creator_name | no_of_posts | total_impressions |
+--------------+-------------+-------------------+
| Ankit Bansal |           3 |            132000 |
+--------------+-------------+-------------------+


-------------------------------------------------------------------------------------------------------------------------------------------


Q 4 - Premium Customers
Statement - An e-commerce company want to start special reward program for their premium customers.  The customers who have placed a greater number of orders than the average number of orders placed by customers are considered as premium customers.

Write an SQL to find the list of premium customers along with the number of orders placed by each of them, display the results in highest to lowest no of orders.

Table:

CREATE TABLE orders (
    order_id INT,
    order_date DATE,
    customer_name VARCHAR(255),
    sales DECIMAL(10, 2)
);

INSERT INTO orders (order_id, order_date, customer_name, sales) VALUES
(1, '2023-01-01', 'Alexa', 2000),
(2, '2023-01-02', 'Alexa', 300),
(3, '2023-01-03', 'Alexa', 1100),
(4, '2023-01-03', 'Alexa', 1350),
(5, '2023-01-01', 'Ramesh', 3500),
(6, '2023-01-02', 'Ramesh', 1600),
(7, '2023-01-03', 'Ramesh', 1100),
(8, '2023-01-03', 'Neha', 1200),
(9, '2023-01-03', 'Subhash', 1000),
(10, '2023-01-03', 'Subhash', 1050);


Output -

+---------------+--------------+
| customer_name | no_of_orders |
+---------------+--------------+
| Alexa         |            4 |
| Ramesh        |            3 |
+---------------+--------------+


-------------------------------------------------------------------------------------------------------------------------------------------

Q 5 - CIBIL Score

Statement - CIBIL score, often referred to as a credit score, is a numerical representation of an individual's credit worthiness. While the exact formula used by credit bureaus like CIBIL may not be publicly disclosed and can vary slightly between bureaus, the following are some common factors that typically influence the calculation of a credit score:

 

1- Payment History: This accounts for the largest portion of your credit score. 
 It includes factors such as whether you pay your bills on time, any late payments, defaults, bankruptcies, etc.
 Assume this accounts for 70 percent of your credit score.

2- Credit Utilization Ratio: This is the ratio of your credit card balances to your credit limits.
 Keeping this ratio low (ideally below 30%) indicates responsible credit usage. 
 Assume it accounts for 30% of your score and below logic to calculate it: 
 Utilization below 30% = 1
 Utilization between 30% and 50% = 0.7
 Utilization above 50% = 0.5
Assume that we have credit card bills data for March 2023 based on that we need to calculate credit utilization ratio. round the result to 1 decimal place.

 

Final Credit score formula = (on_time_loan_or_bill_payment)/total_bills_and_loans * 70 + Credit Utilization Ratio * 30 
Display the output in ascending order of customer id.

 

Table:

CREATE TABLE loans (
    customer_id INT,
    loan_id INT,
    loan_due_date DATE
);

INSERT INTO loans (customer_id, loan_id, loan_due_date) VALUES
(1, 101, '2022-05-10'),
(1, 102, '2023-06-30'),
(2, 103, '2023-08-15');


CREATE TABLE customers (
    customer_id INT,
    credit_limit DECIMAL(10, 2)
);

INSERT INTO customers (customer_id, credit_limit) VALUES
(1, 80000),
(2, 75000);


CREATE TABLE credit_card_bills (
    customer_id INT,
    bill_id INT,
    bill_due_date DATE,
    bill_amount DECIMAL(10, 2)
);

INSERT INTO credit_card_bills (customer_id, bill_id, bill_due_date, bill_amount) VALUES
(1, 201, '2023-03-17', 8000),
(1, 202, '2023-03-15', 12000),
(2, 301, '2023-03-20', 15000),
(2, 302, '2023-03-22', 13000);


CREATE TABLE customer_transactions (
    loan_bill_id INT,
    transaction_type VARCHAR(10),
    transaction_date DATE
);

INSERT INTO customer_transactions (loan_bill_id, transaction_type, transaction_date) VALUES
(101, 'loan', '2022-04-12'),
(102, 'loan', '2023-07-05'),
(201, 'payment', '2023-03-17'),
(202, 'payment', '2023-03-01'),
(103, 'loan', '2023-08-10'),
(301, 'payment', '2023-03-05'),
(302, 'payment', '2023-03-05');


Output -
+-------------+-------------+
| customer_id | cibil_score |
+-------------+-------------+
|           1 |        82.5 |
|           2 |        91.0 |
+-------------+-------------+


-------------------------------------------------------------------------------------------------------------------------------------------
Q 6 - Electricity Consumption

Statement - You have access to data from an electricity billing system, detailing the electricity usage and cost for specific households over billing periods in the years 2023 and 2024. Your objective is to present the total electricity consumption, total cost and average monthly consumption for each household per year display the output in ascending order of each household id & year of the bill.

 

Tables:


CREATE TABLE electricity_bill (
    bill_id INT,
    household_id INT,
    billing_period CHAR(7),
    consumption_kwh DECIMAL(10, 2),
    total_cost DECIMAL(10, 2)
);

INSERT INTO electricity_bill (bill_id, household_id, billing_period, consumption_kwh, total_cost) VALUES
(1, 101, '2023-01', 320.50, 48.08),
(2, 101, '2023-02', 280.00, 42.00),
(3, 101, '2023-03', 310.50, 46.58),
(4, 101, '2023-04', 330.50, 49.58),
(5, 101, '2023-05', 310.00, 46.50),
(6, 101, '2023-06', 290.50, 43.58),
(7, 101, '2023-07', 320.00, 48.00),
(8, 101, '2023-08', 340.50, 51.08),
(9, 101, '2023-09', 300.00, 45.00),
(10, 101, '2023-10', 310.50, 46.58),
(11, 101, '2023-11', 320.00, 48.00),
(12, 101, '2023-12', 310.50, 46.58),
(13, 101, '2024-01', 320.50, 48.08),
(14, 101, '2024-02', 280.00, 42.00),
(15, 101, '2024-03', 310.50, 46.58),
(16, 101, '2024-04', 330.50, 49.58),
(17, 101, '2024-05', 310.00, 46.50),
(18, 101, '2024-06', 290.50, 43.58),
(19, 101, '2024-07', 320.00, 48.00),
(20, 101, '2024-08', 340.50, 51.08),
(21, 101, '2024-09', 300.00, 45.00),
(22, 101, '2024-10', 310.50, 46.58),
(23, 101, '2024-11', 320.00, 48.00),
(24, 101, '2024-12', 310.50, 46.58),
(25, 102, '2023-01', 450.00, 67.50),
(26, 102, '2023-02', 470.00, 70.50),
(27, 102, '2023-03', 480.00, 72.00),
(28, 102, '2023-04', 460.00, 69.00),
(29, 102, '2023-05', 480.00, 72.00),
(30, 102, '2023-06', 490.00, 73.50),
(31, 102, '2023-07', 500.00, 75.00),
(32, 102, '2023-08', 510.00, 76.50),
(33, 102, '2023-09', 520.00, 78.00),
(34, 102, '2023-10', 530.00, 79.50),
(35, 102, '2023-11', 540.00, 81.00),
(36, 102, '2023-12', 550.00, 82.50),
(37, 102, '2024-01', 560.00, 84.00),
(38, 102, '2024-02', 570.00, 85.50),
(39, 102, '2024-03', 580.00, 87.00),
(40, 102, '2024-04', 590.00, 88.50),
(41, 102, '2024-05', 600.00, 90.00),
(42, 102, '2024-06', 610.00, 91.50),
(43, 102, '2024-07', 620.00, 93.00),
(44, 102, '2024-08', 630.00, 94.50),
(45, 102, '2024-09', 640.00, 96.00),
(46, 102, '2024-10', 650.00, 97.50),
(47, 102, '2024-11', 660.00, 99.00),
(48, 102, '2024-12', 670.00, 100.50),
(49, 103, '2023-01', 510.70, 76.61),
(50, 103, '2023-02', 520.70, 78.11),
(51, 103, '2023-03', 530.70, 79.61),
(52, 103, '2023-04', 540.70, 81.11),
(53, 103, '2023-05', 550.70, 82.61),
(54, 103, '2023-06', 560.70, 84.11),
(55, 103, '2023-07', 570.70, 85.61),
(56, 103, '2023-08', 580.70, 87.11),
(57, 103, '2023-09', 590.70, 88.61),
(58, 103, '2023-10', 600.70, 90.11),
(59, 103, '2023-11', 610.70, 91.61),
(60, 103, '2023-12', 620.70, 93.11),
(61, 103, '2024-01', 630.70, 94.61),
(62, 103, '2024-02', 640.70, 96.11),
(63, 103, '2024-03', 650.70, 97.61),
(64, 103, '2024-04', 660.70, 99.11),
(65, 103, '2024-05', 670.70, 100.61),
(66, 103, '2024-06', 680.70, 102.11),
(67, 103, '2024-07', 690.70, 103.61),
(68, 103, '2024-08', 700.70, 105.11),
(69, 103, '2024-09', 710.70, 106.61),
(70, 103, '2024-10', 720.70, 108.11),
(71, 103, '2024-11', 730.70, 109.61),
(72, 103, '2024-12', 740.70, 111.11);



Output -
+--------------+-----------+-----------------+------------+---------------------+
| household_id | bill_year | consumption_kwh | total_cost | avg_consumption_kwh |
+--------------+-----------+-----------------+------------+---------------------+
|          101 | 2023      |         3743.50 |     561.56 |          311.958333 |
|          101 | 2024      |         3743.50 |     561.56 |          311.958333 |
|          102 | 2023      |         5980.00 |     897.00 |          498.333333 |
|          102 | 2024      |         7380.00 |    1107.00 |          615.000000 |
|          103 | 2023      |         6788.40 |    1018.32 |          565.700000 |
|          103 | 2024      |         8228.40 |    1234.32 |          685.700000 |
+--------------+-----------+-----------------+------------+---------------------+



-------------------------------------------------------------------------------------------------------------------------------------------



Q 7 - Airbnb Top Hosts

Statement - Suppose you are a data analyst working for a travel company that offers vacation rentals similar to Airbnb. Your company wants to identify the top hosts with the highest average ratings for their listings. This information will be used to recognize exceptional hosts and potentially offer them incentives to continue providing outstanding service.

 

Your task is to write an SQL query to find the top 2 hosts with the highest average ratings for their listings. However, you should only consider hosts who have at least 2 listings, as hosts with fewer listings may not be representative.

Display output in descending order of average ratings and round the average ratings to 2 decimal places.

 

Table:

CREATE TABLE listings (
    listing_id INT,
    host_id INT,
    neighborhood VARCHAR(50),
    room_type VARCHAR(50),
    price DECIMAL(10, 2),
    minimum_nights INT
);

INSERT INTO listings (listing_id, host_id, neighborhood, room_type, price, minimum_nights) VALUES
(1, 101, 'Downtown', 'Entire home/apt', 150.00, 2),
(2, 101, 'Downtown', 'Private room', 80.00, 1),
(3, 101, 'Downtown', 'Entire home/apt', 200.00, 3),
(4, 102, 'Downtown', 'Entire home/apt', 120.00, 2),
(5, 102, 'Downtown', 'Private room', 100.00, 1),
(6, 102, 'Midtown', 'Entire home/apt', 250.00, 2),
(7, 103, 'Midtown', 'Private room', 70.00, 1),
(8, 103, 'Queens', 'Private room', 90.00, 1),
(9, 104, 'Midtown', 'Private room', 170.00, 1);


CREATE TABLE reviews (
    review_id INT,
    listing_id INT,
    review_date DATE,
    rating INT
);

INSERT INTO reviews (review_id, listing_id, review_date, rating) VALUES
(1, 1, '2023-01-05', 4),
(2, 1, '2023-01-10', 5),
(3, 2, '2023-01-15', 4),
(4, 3, '2023-01-20', 5),
(5, 3, '2023-01-25', 3),
(6, 3, '2023-01-30', 4),
(7, 4, '2023-02-05', 5),
(8, 5, '2023-02-10', 4),
(9, 6, '2023-02-15', 5),
(10, 6, '2023-02-20', 4),
(11, 7, '2023-02-25', 5),
(12, 8, '2023-03-05', 5),
(13, 9, '2023-03-05', 5);



Output-

+---------+----------------+------------+
| host_id | no_of_listings | avg_rating |
+---------+----------------+------------+
|     103 |              2 |       5.00 |
|     102 |              3 |       4.50 |
+---------+----------------+------------+



-------------------------------------------------------------------------------------------------------------------------------------------

Q 8 - Library Borrowing Habits

Statement- Imagine you're working for a library and you're tasked with generating a report on the borrowing habits of patrons. You have two tables in your database: Books and Borrowers.

Write an SQL to display the name of each borrower along with a comma-separated list of the books they have borrowed in alphabetical order, display the output in ascending order of Borrower Name.

 
Tables:

CREATE TABLE Books (
    BookID INT,
    BookName VARCHAR(100),
    Genre VARCHAR(50)
);

INSERT INTO Books (BookID, BookName, Genre) VALUES
(1, 'The Great Gatsby', 'Fiction'),
(2, 'To Kill a Mockingbird', 'Fiction'),
(3, '1984', 'Fiction'),
(4, 'The Catcher in the Rye', 'Fiction'),
(5, 'Pride and Prejudice', 'Romance'),
(6, 'Romeo and Juliet', 'Romance'),
(7, 'The Notebook', 'Romance'),
(8, 'The Hunger Games', 'Science Fiction'),
(9, 'Dune', 'Science Fiction'),
(10, 'Foundation', 'Science Fiction');


CREATE TABLE Borrowers (
    BorrowerID INT,
    BorrowerName VARCHAR(100),
    BookID INT
);

INSERT INTO Borrowers (BorrowerID, BorrowerName, BookID) VALUES
(1, 'Alice', 1),
(2, 'Bob', 2),
(3, 'Charlie', 3),
(4, 'David', 4),
(5, 'Eve', 5),
(6, 'Frank', 6),
(7, 'Grace', 7),
(1, 'Alice', 5),
(2, 'Bob', 6),
(3, 'Charlie', 7),
(4, 'David', 8),
(6, 'Frank', 10),
(8, 'Harry', 2),
(9, 'Ivy', 3);


Output:


+--------------+-----------------------------------------+
| BorrowerName | BorrowedBooks                           |
+--------------+-----------------------------------------+
| Alice        | Pride and Prejudice,The Great Gatsby    |
| Bob          | Romeo and Juliet,To Kill a Mockingbird  |
| Charlie      | 1984,The Notebook                       |
| David        | The Catcher in the Rye,The Hunger Games |
| Eve          | Pride and Prejudice                     |
| Frank        | Foundation,Romeo and Juliet             |
| Grace        | The Notebook                            |
| Harry        | To Kill a Mockingbird                   |
| Ivy          | 1984                                    |
+--------------+-----------------------------------------+



-------------------------------------------------------------------------------------------------------------------------------------------

Q 9 - New and Repeat Customers

Statement - Flipkart wants to build a very important business metrics where they want to track on daily basis how many new and repeat customers are purchasing products from their website. A new customer is defined when he purchased anything for the first time from the website and repeat customer is someone who has done at least one purchase in the past.
Display order date , new customers , repeat customers  in ascending order of repeat customers.

Table:

CREATE TABLE customer_orders (
    order_id INT,
    customer_id INT,
    order_date DATE,
    order_amount DECIMAL(10, 2)
);

INSERT INTO customer_orders (order_id, customer_id, order_date, order_amount) VALUES
(1, 100, '2022-01-01', 2000),
(2, 200, '2022-01-01', 2500),
(3, 300, '2022-01-01', 2100),
(4, 100, '2022-01-02', 2000),
(5, 400, '2022-01-02', 2200),
(6, 500, '2022-01-02', 2700),
(7, 100, '2022-01-03', 3000),
(8, 400, '2022-01-03', 1000),
(9, 600, '2022-01-03', 3000);



Output:
+------------+---------------+------------------+
| order_date | new_customers | repeat_customers |
+------------+---------------+------------------+
| 2022-01-01 |             3 |                0 |
| 2022-01-02 |             2 |                1 |
| 2022-01-03 |             1 |                2 |
+------------+---------------+------------------+



-------------------------------------------------------------------------------------------------------------------------------------------

Q 10 - The Little Master

Statement - Sachin Tendulkar - Also known as little master. You are given runs scored by Sachin in his first 10 matches. You need to write an SQL to get match number when he completed 500 runs and his batting average at the end of 10 matches.
Batting Average = (Total runs scored) / (no of times batsman got out)
Round the result to 2 decimal places.


Table:

CREATE TABLE sachin (
    match_no INT,
    runs_scored INT,
    status VARCHAR(10)
);

INSERT INTO sachin (match_no, runs_scored, status) VALUES
(1, 53, 'out'),
(2, 59, 'not-out'),
(3, 113, 'out'),
(4, 29, 'out'),
(5, 0, 'out'),
(6, 39, 'out'),
(7, 73, 'out'),
(8, 149, 'out'),
(9, 93, 'out'),
(10, 25, 'out');


Output:

+----------+-----------------+
| match_no | batting_average |
+----------+-----------------+
|        8 |           70.33 |
+----------+-----------------+


-------------------------------------------------------------------------------------------------------------------------------------------


Q 11 - Math Champions

Statement - You are provided with two tables: Students and Grades. Write a SQL query to find students who have higher grade in Math than the average grades of all the students together in Math. Display student name and grade in Math order by grades.

Tables:

CREATE TABLE students (
    student_id INT,
    student_name VARCHAR(100),
    class_id INT
);

INSERT INTO students (student_id, student_name, class_id) VALUES
(1, 'John Doe', 1),
(2, 'Jane Smith', 2),
(3, 'Alice Johnson', 1),
(4, 'Bob Brown', 3),
(5, 'Emily Clark', 2),
(6, 'Michael Lee', 1),
(7, 'Sarah Taylor', 3),
(8, 'David Martinez', 2),
(9, 'Laura White', 3),
(10, 'Chris Wilson', 1);


CREATE TABLE grades (
    student_id INT,
    subject VARCHAR(50),
    grade INT
);

INSERT INTO grades (student_id, subject, grade) VALUES
(1, 'Math', 85),
(2, 'Math', 78),
(3, 'Math', 92),
(4, 'Math', 79),
(5, 'Math', 88),
(6, 'Math', 95),
(7, 'Math', 83),
(8, 'Math', 90),
(9, 'Math', 86),
(10, 'Math', 82),
(1, 'Science', 75),
(2, 'Science', 82),
(3, 'Science', 88),
(4, 'Science', 70),
(5, 'Science', 79),
(6, 'Science', 85),
(7, 'Science', 77),
(8, 'Science', 90),
(9, 'Science', 84),
(10, 'Science', 81),
(1, 'English', 88),
(2, 'English', 85),
(3, 'English', 92),
(4, 'English', 80),
(5, 'English', 75),
(6, 'English', 89),
(7, 'English', 86),
(8, 'English', 91),
(9, 'English', 83),
(10, 'English', 87),
(1, 'History', 70),
(2, 'History', 82),
(3, 'History', 88),
(4, 'History', 75),
(5, 'History', 78),
(6, 'History', 90),
(7, 'History', 83),
(8, 'History', 88),
(9, 'History', 82),
(10, 'History', 85);



Output:
+----------------+------------+
| student_name   | math_grade |
+----------------+------------+
| Laura White    |         86 |
| Emily Clark    |         88 |
| David Martinez |         90 |
| Alice Johnson  |         92 |
| Michael Lee    |         95 |
+----------------+------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 12 - Deliveroo Top Customer

Statement - You are provided with data from a food delivery service called Deliveroo. Each order has details about the delivery time, the rating given by the customer, and the total cost of the order. Write an SQL to find customer with highest total expenditure. Display customer id and total expense by him/her.

Tables:

CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    restaurant_id INT,
    delivery_time INT,
    total_cost DECIMAL(10, 2)
);

INSERT INTO orders (order_id, customer_id, restaurant_id, delivery_time, total_cost) VALUES
(1, 101, 201, 30, 2550.00),
(2, 102, 202, 40, 3000.00),
(3, 101, 203, 25, 1575.00),
(4, 103, 201, 50, 2200.00),
(5, 104, 202, 45, 1850.00),
(6, 105, 204, 35, 2725.00),
(7, 106, 203, 20, 1600.00),
(8, 107, 202, 55, 1975.00),
(9, 108, 201, 60, 2000.00),
(10, 109, 204, 25, 2400.00);



Output:

+-------------+---------------+
| customer_id | total_expense |
+-------------+---------------+
|         101 |          4125 |
+-------------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 13 - Best Employee Award

Statement - TCS wants to award employees based on number of projects completed by each individual each month.  Write an SQL to find best employee for each month along with number of projects completed by him/her in that month, display the output in descending order of number of completed projects.

Table:
CREATE TABLE projects (
    project_id INT,
    employee_name VARCHAR(100),
    project_completion_date DATE
);

INSERT INTO projects (project_id, employee_name, project_completion_date) VALUES
(100, 'Ankit', '2022-12-15'),
(101, 'Shilpa', '2023-01-03'),
(102, 'Shilpa', '2023-01-15'),
(103, 'Shilpa', '2023-01-22'),
(104, 'Rahul', '2023-01-05'),
(105, 'Rahul', '2023-01-12'),
(106, 'Mukesh', '2023-01-23'),
(108, 'Mukesh', '2023-02-04'),
(109, 'Mukesh', '2023-02-16'),
(110, 'Shilpa', '2023-02-24'),
(112, 'Rahul', '2023-02-25');


Output:
+---------------+--------------------------+-----------+
| employee_name | no_of_completed_projects | yearmonth |
+---------------+--------------------------+-----------+
| Shilpa        |                        3 | 202301    |
| Mukesh        |                        2 | 202302    |
| Ankit         |                        1 | 202212    |
+---------------+--------------------------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 14 - Workaholics Employees

Statement - Write a query to find workaholics employees.  Workaholics employees are those who satisfy at least one of the given criterions:

1- Worked for more than 8 hours a day for at least 3 days in a week. 
2- worked for more than 10 hours a day for at least 2 days in a week. 
You are given the login and logout timings of all the employees for a given week. Write a SQL to find all the workaholic employees along with the criterion that they are satisfying (1,2 or both), display it in the order of increasing employee id

Table:

CREATE TABLE employees (
    emp_id INT,
    login DATETIME,
    logout DATETIME
);

INSERT INTO employees (emp_id, login, logout) VALUES
(100, '2024-02-19 09:15:00', '2024-02-19 18:20:00'),
(100, '2024-02-20 09:05:00', '2024-02-20 17:00:00'),
(100, '2024-02-21 09:00:00', '2024-02-21 17:10:00'),
(100, '2024-02-22 10:00:00', '2024-02-22 16:55:00'),
(100, '2024-02-23 10:30:00', '2024-02-23 19:15:00'),
(200, '2024-02-19 08:00:00', '2024-02-19 18:20:00'),
(200, '2024-02-20 09:00:00', '2024-02-20 16:30:00'),
(200, '2024-02-21 09:15:00', '2024-02-21 19:20:00'),
(200, '2024-02-22 11:00:00', '2024-02-22 17:05:00'),
(200, '2024-02-23 09:30:00', '2024-02-23 17:20:00'),
(300, '2024-02-19 07:00:00', '2024-02-19 18:15:00'),
(300, '2024-02-20 09:00:00', '2024-02-20 19:10:00'),
(300, '2024-02-21 09:15:00', '2024-02-21 18:20:00'),
(300, '2024-02-22 11:00:00', '2024-02-22 17:00:00'),
(300, '2024-02-23 09:30:00', '2024-02-23 16:30:00');


Output:
+--------+-----------+
| emp_id | criterian |
+--------+-----------+
|    100 | 1         |
|    200 | 2         |
|    300 | both      |
+--------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 15 - Lift Overloaded (Part 1)

Statement - You are given a table of list of lifts , their maximum capacity and people along with their weight who wants to enter into it. You need to make sure maximum people enter into the lift without lift getting overloaded.

For each lift find the comma separated list of people who can be accommodated. The comma separated list should have people in the order of their weight in increasing order, display the output in increasing order of id.

Table:

CREATE TABLE lifts (
    id INT,
    capacity_kg INT
);

INSERT INTO lifts (id, capacity_kg) VALUES
(1, 300),
(2, 350);


CREATE TABLE lift_passengers (
    passenger_name VARCHAR(50),
    weight_kg INT,
    lift_id INT
);

INSERT INTO lift_passengers (passenger_name, weight_kg, lift_id) VALUES
('Rahul', 85, 1),
('Adarsh', 73, 1),
('Riti', 95, 1),
('Dheeraj', 80, 1),
('Vimal', 83, 2),
('Neha', 77, 2),
('Priti', 73, 2),
('Himanshi', 85, 2);


Output:

+------+---------------------------+
| id   | passenger_list            |
+------+---------------------------+
|    1 | Adarsh,Dheeraj,Rahul      |
|    2 | Priti,Neha,Vimal,Himanshi |
+------+---------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 16 - Lift Overloaded (Part 2)

Statement: You are given a table of list of lifts , their maximum capacity and people along with their weight and gender who wants to enter into it. You need to make sure maximum people enter into the lift without lift getting overloaded but you need to give preference to female passengers first.

For each lift find the comma separated list of people who can be accomodated. The comma separated list should have female first and then people in the order of their weight in increasing order, display the output in increasing order of id.

Table:
CREATE TABLE lifts (
    id INT,
    capacity_kg INT
);

INSERT INTO lifts (id, capacity_kg) VALUES
(1, 300),
(2, 350);


CREATE TABLE lift_passengers (
    passenger_name VARCHAR(50),
    weight_kg INT,
    gender CHAR(1),
    lift_id INT
);

INSERT INTO lift_passengers (passenger_name, weight_kg, gender, lift_id) VALUES
('Rahul', 85, 'M', 1),
('Adarsh', 73, 'M', 1),
('Riti', 95, 'F', 1),
('Dheeraj', 80, 'M', 1),
('Vimal', 83, 'M', 2),
('Neha', 77, 'F', 2),
('Priti', 73, 'F', 2),
('Himanshi', 85, 'F', 2);

Output:
+------+---------------------------+
| id   | passenger_list            |
+------+---------------------------+
|    1 | Riti,Adarsh,Dheeraj       |
|    2 | Priti,Neha,Himanshi,Vimal |
+------+---------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 17 - Business Expansion

Statement - Amazon is expanding their pharmacy business to new cities every year. You are given a table of business operations where you have information about cities where Amazon is doing operations along with the business date information.
Write a SQL to find year wise number of new cities added to the business, display the output in increasing order of year.

Table:
CREATE TABLE business_operations (
    business_date DATE,
    city_id INT
);

INSERT INTO business_operations (business_date, city_id) VALUES
('2020-01-02', 3),
('2020-07-01', 7),
('2021-01-01', 3),
('2021-02-03', 19),
('2022-12-01', 3),
('2022-12-15', 3),
('2022-02-28', 12);


Output:
+----------------------+------------------+
| first_operation_year | no_of_new_cities |
+----------------------+------------------+
|                 2020 |                2 |
|                 2021 |                1 |
|                 2022 |                1 |
+----------------------+------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 18 - Hero Products

Statement - Flipkart an ecommerce company wants to find out its top most selling product by quantity in each category. In case of a tie when quantities sold are same for more than 1 product, then we need to give preference to the product with higher sales value.
Display category and product in output with category in ascending order.

Table:
CREATE TABLE orders (
    order_id INT,
    product_id VARCHAR(50),
    category VARCHAR(50),
    unit_price DECIMAL(10, 2),
    quantity INT
);

INSERT INTO orders (order_id, product_id, category, unit_price, quantity) VALUES
(100, 'Chair-1221', 'Furniture', 1500, 1),
(101, 'Table-3421', 'Furniture', 2000, 3),
(102, 'Chair-1221', 'Furniture', 1500, 2),
(103, 'Table-9762', 'Furniture', 7000, 2),
(104, 'Shoes-1221', 'Footwear', 1700, 1),
(105, 'floaters-3421', 'Footwear', 2000, 1),
(106, 'floaters-3421', 'Footwear', 2000, 1),
(107, 'floaters-9875', 'Footwear', 1500, 2);


Output:
+-----------+---------------+
| category  | product_id    |
+-----------+---------------+
| Footwear  | floaters-3421 |
| Furniture | Table-3421    |
+-----------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 19 - Order Fulfilment
Statement: You are given two tables: products and orders. The products table contains information about each product, including the product ID and available quantity in the warehouse. The orders table contains details about customer orders, including the order ID, product ID, order date, and quantity requested by the customer.

Write an SQL query to generate a report listing the orders that can be fulfilled based on the available inventory in the warehouse, following a first-come-first-serve approach based on the order date. Each row in the report should include the order ID, product name, quantity requested by the customer, quantity actually fulfilled, and a comments column as below:

 

If the order can be completely fulfilled then 'Full Order'.
If the order can be partially fulfilled then 'Partial Order'.
If order can not be fulfilled at all then 'No Order' .
Display the output in ascending order of order id.

Table:

CREATE TABLE products (
    product_id INT,
    product_name VARCHAR(50),
    available_quantity INT
);

INSERT INTO products (product_id, product_name, available_quantity) VALUES
(1, 'Product A', 10),
(2, 'Product B', 20),
(3, 'Product C', 15),
(4, 'Product D', 10);


CREATE TABLE orders (
    order_id INT,
    product_id INT,
    order_date DATE,
    quantity_requested INT
);

INSERT INTO orders (order_id, product_id, order_date, quantity_requested) VALUES
(1, 1, '2024-01-01', 5),
(2, 1, '2024-01-02', 7),
(3, 2, '2024-01-03', 10),
(4, 2, '2024-01-04', 10),
(5, 2, '2024-01-05', 5),
(6, 3, '2024-01-06', 4),
(7, 3, '2024-01-07', 5),
(8, 4, '2024-01-08', 4),
(9, 4, '2024-01-09', 5),
(10, 4, '2024-01-10', 8),
(11, 4, '2024-01-11', 5);


Output:
+----------+--------------+--------------------+---------------+---------------+
| order_id | product_name | quantity_requested | qty_fulfilled | comments      |
+----------+--------------+--------------------+---------------+---------------+
|        1 | Product A    |                  5 |             5 | Full Order    |
|        2 | Product A    |                  7 |             5 | Partial Order |
|        3 | Product B    |                 10 |            10 | Full Order    |
|        4 | Product B    |                 10 |            10 | Full Order    |
|        5 | Product B    |                  5 |             0 | No Order      |
|        6 | Product C    |                  4 |             4 | Full Order    |
|        7 | Product C    |                  5 |             5 | Full Order    |
|        8 | Product D    |                  4 |             4 | Full Order    |
|        9 | Product D    |                  5 |             5 | Full Order    |
|       10 | Product D    |                  8 |             1 | Partial Order |
|       11 | Product D    |                  5 |             0 | No Order      |
+----------+--------------+--------------------+---------------+---------------+



---------------------------------------------------------------------------------------------------------------------------------------------

Q 20 - Trending Products

Statement - Amazon wants to find out the trending products for each month. Trending products are those for which any given month sales are more than the sum of previous 2 months sales for that product.
Please note that for first 2 months of operations this metrics does not make sense. So output should start from 3rd month only.  Assume that each product has at least 1 sale each month, display order month and product id. Sort by order month.

Table: 

CREATE TABLE orders (
    order_month INT,
    product_id VARCHAR(10),
    sales INT
);

INSERT INTO orders (order_month, product_id, sales) VALUES
(202301, 'p1', 100),
(202301, 'p2', 500),
(202302, 'p1', 700),
(202302, 'p2', 300),
(202303, 'p1', 900),
(202303, 'p2', 700),
(202304, 'p1', 2000),
(202304, 'p2', 1100),
(202305, 'p1', 1500),
(202305, 'p2', 1300),
(202306, 'p1', 1700),
(202306, 'p2', 1200),
(202307, 'p1', 1900),
(202307, 'p2', 1400),
(202308, 'p1', 2100),
(202308, 'p2', 1600),
(202309, 'p1', 2300),
(202309, 'p2', 1800),
(202310, 'p1', 5000),
(202310, 'p2', 2000);


Output:
+-------------+------------+
| order_month | product_id |
+-------------+------------+
| 202303      | p1         |
| 202304      | p1         |
| 202304      | p2         |
| 202310      | p1         |
+-------------+------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 21 - Uber Profit Rides

Statement - A profit ride for a Uber driver is considered when the start location and start time of a ride exactly match with the previous ride's end location and end time. 
Write an SQL to calculate total number of rides and total profit rides by each driver, display the output in ascending order of id.

Table:
CREATE TABLE drivers (
    id VARCHAR(10),
    start_time TIME,
    end_time TIME,
    start_loc VARCHAR(10),
    end_loc VARCHAR(10)
);

INSERT INTO drivers (id, start_time, end_time, start_loc, end_loc) VALUES
('dri_1', '09:00:00', '09:30:00', 'a', 'b'),
('dri_1', '09:30:00', '10:30:00', 'b', 'c'),
('dri_1', '11:00:00', '11:30:00', 'd', 'e'),
('dri_1', '12:00:00', '12:30:00', 'f', 'g'),
('dri_1', '13:30:00', '14:30:00', 'c', 'h'),
('dri_2', '12:15:00', '12:30:00', 'f', 'g'),
('dri_2', '12:30:00', '14:30:00', 'c', 'h');


Output:
+-------+-------------+--------------+
| id    | total_rides | profit_rides |
+-------+-------------+--------------+
| dri_1 |           5 |            1 |
| dri_2 |           2 |            0 |
+-------+-------------+--------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 22 - The United States of America
Statement: In some poorly designed UI applications, there's often a lack of data input restrictions. For instance, in a free text field for the country, users might input variations such as 'USA,' 'United States of America,' or 'US.'

Suppose we have survey data from individuals in the USA about their job satisfaction, rated on a scale of 1 to 5. Write a SQL query to count the number of respondents for each rating on the scale. Additionally, include the country name in the format that occurs most frequently in that scale, display the output in ascending order of job satisfaction.

Table:
CREATE TABLE survey (
    name VARCHAR(50),
    job_satisfaction INT,
    country VARCHAR(50)
);

INSERT INTO survey (name, job_satisfaction, country) VALUES
('Alex', 4, 'USA'),
('Saurabh', 5, 'US'),
('Mark', 4, 'United States'),
('Shane', 4, 'USA'),
('Kim', 5, 'United States'),
('Joe', 5, 'USA'),
('Mira', 5, 'United States'),
('John', 3, 'USA'),
('Jane', 4, 'United States'),
('Sam', 3, 'US'),
('Sara', 4, 'USA'),
('Luis', 5, 'United States'),
('Carlos', 4, 'US'),
('Anna', 3, 'USA'),
('Maria', 5, 'United States');


Output:
+------------------+---------------+-----------------------+
| job_satisfaction | country       | number_of_respondents |
+------------------+---------------+-----------------------+
|                3 | USA           |                     3 |
|                4 | USA           |                     6 |
|                5 | United States |                     6 |
+------------------+---------------+-----------------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 23 - Product Recommendation

Statement - Product recommendation. Just the basic type (“customers who bought this also bought…”). That, in its simplest form, is an outcome of basket analysis. Write a SQL to find the product pairs which have been purchased together in same order along with the purchase frequency (count of times they have been purchased together). Based on this data Amazon can recommend frequently bought together products to other users.

Order the output by purchase frequency in descending order. Please make in the output first product column has id greater than second product column. 

Table:

CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    product_id VARCHAR(10)
);

INSERT INTO orders (order_id, customer_id, product_id) VALUES
(1, 1, 'p1'),
(1, 1, 'p2'),
(1, 1, 'p3'),
(2, 2, 'p1'),
(2, 2, 'p2'),
(2, 2, 'p4'),
(3, 1, 'p5'),
(3, 1, 'p6'),
(4, 3, 'p1'),
(4, 3, 'p3'),
(4, 3, 'p5'),
(5, 4, 'p2'),
(5, 4, 'p4'),
(5, 4, 'p1');

Output:
+-----------+-----------+--------------------+
| product_1 | product_2 | purchase_frequency |
+-----------+-----------+--------------------+
| p2        | p1        |                  3 |
| p3        | p1        |                  2 |
| p4        | p1        |                  2 |
| p4        | p2        |                  2 |
| p3        | p2        |                  1 |
| p6        | p5        |                  1 |
| p5        | p1        |                  1 |
| p5        | p3        |                  1 |
+-----------+-----------+--------------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 24 - Account Balance

Statement: You are given a list of users and their opening account balance along with the transactions done by them. Write a SQL to calculate their account balance at the end of all the transactions. Please note that users can do transactions among themselves as well, display the output in ascending order of the final balance.

Table:

CREATE TABLE users (
    user_id INT,
    username VARCHAR(50),
    opening_balance DECIMAL(10, 2)
);

INSERT INTO users (user_id, username, opening_balance) VALUES
(100, 'Ankit', 1000),
(101, 'Rahul', 9000),
(102, 'Amit', 5000),
(103, 'Agam', 7500);


CREATE TABLE transactions (
    id INT,
    from_userid INT,
    to_userid INT,
    amount DECIMAL(10, 2)
);

INSERT INTO transactions (id, from_userid, to_userid, amount) VALUES
(1, 100, 102, 500),
(2, 102, 101, 700),
(3, 101, 102, 600),
(4, 102, 100, 1500),
(5, 102, 101, 800),
(6, 102, 101, 300);

Output:
+----------+---------------+
| username | final_balance |
+----------+---------------+
| Ankit    |          2000 |
| Amit     |          2800 |
| Agam     |          7500 |
| Rahul    |         10200 |
+----------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 25 - boAt Lifestyle Marketing

Statement: boAt Lifestyle is focusing on influencer marketing to build and scale their brand. They want to partner with power creators for their upcoming campaigns. The creators should satisfy below conditions to qualify:

1- They should have 100k+ followers on at least 2 social media platforms and
2- They should have at least 50k+ views on their latest YouTube video.
Write an SQL to get creator id and name satisfying above conditions.

Table:

CREATE TABLE creators (
    id INT,
    name VARCHAR(50),
    platform VARCHAR(50),
    followers INT
);

INSERT INTO creators (id, name, platform, followers) VALUES
(100, 'Ankit', 'YouTube', 90000),
(100, 'Ankit', 'LinkedIn', 150000),
(101, 'Warikoo', 'YouTube', 500000),
(101, 'Warikoo', 'LinkedIn', 600000),
(101, 'Warikoo', 'Instagram', 800000),
(102, 'Dhruv', 'LinkedIn', 60000),
(102, 'Dhruv', 'YouTube', 900000),
(102, 'Dhruv', 'Instagram', 800000),
(103, 'Ravi', 'YouTube', 100000),
(103, 'Ravi', 'LinkedIn', 120000),
(103, 'Ravi', 'Instagram', 95000),
(104, 'Neha', 'YouTube', 250000),
(104, 'Neha', 'LinkedIn', 300000),
(104, 'Neha', 'Instagram', 350000),
(105, 'Amit', 'YouTube', 450000),
(105, 'Amit', 'LinkedIn', 500000),
(105, 'Amit', 'Instagram', 550000);


CREATE TABLE youtube_videos (
    id INT,
    creator_id INT,
    publish_date DATE,
    views INT
);

INSERT INTO youtube_videos (id, creator_id, publish_date, views) VALUES
(1, 100, '2024-01-01', 52000),
(2, 100, '2024-01-06', 62000),
(3, 101, '2024-01-05', 59000),
(4, 101, '2024-01-07', 22000),
(5, 102, '2024-01-05', 70000),
(6, 102, '2024-01-09', 90000),
(7, 103, '2024-01-11', 48000),
(8, 103, '2024-01-12', 53000),
(9, 104, '2024-01-15', 76000),
(10, 104, '2024-01-17', 81000),
(11, 105, '2024-01-20', 95000),
(12, 105, '2024-01-22', 99000);


Output:
+------+-------+
| id   | name  |
+------+-------+
|  102 | Dhruv |
|  104 | Neha  |
|  105 | Amit  |
+------+-------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 26 - Dynamic Pricing

Statement - You are given a products table where a new row is inserted every time the price of a product changes. Additionally, there is a transaction table containing details such as order_date and product_id for each order.

Write an SQL query to calculate the total sales value for each product, considering the cost of the product at the time of the order date, display the output in ascending order of the product_id.

Table:

CREATE TABLE products (
    product_id INT,
    price_date DATE,
    price DECIMAL(10, 2)
);

INSERT INTO products (product_id, price_date, price) VALUES
(100, '2024-01-01', 150),
(100, '2024-01-21', 170),
(100, '2024-02-01', 190),
(101, '2024-01-01', 1000),
(101, '2024-01-27', 1200),
(101, '2024-02-05', 1250);


CREATE TABLE orders (
    order_id INT,
    order_date DATE,
    product_id INT
);

INSERT INTO orders (order_id, order_date, product_id) VALUES
(1, '2024-01-05', 100),
(2, '2024-01-21', 100),
(3, '2024-02-20', 100),
(4, '2024-01-07', 101),
(5, '2024-02-04', 101),
(6, '2024-02-05', 101);


Output:
+------------+-------------+
| product_id | total_sales |
+------------+-------------+
|        100 |         510 |
|        101 |        3450 |
+------------+-------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 27 - Income Tax Returns

Statement - Given two tables: income_tax_dates and users, write a query to identify users who either filed their income tax returns late or completely skipped filing for certain financial years.

A return is considered late if the return_file_date is after the file_due_date.
A return is considered missed if there is no entry for the user in the users table for a given financial year (i.e., the user did not file at all).
Your task is to generate a list of users along with the financial year for which they either filed late or missed filing, and also include a comment column specifying whether it is a 'late return' or 'missed'. The result should be sorted by financial year in ascending order.

Table:

CREATE TABLE users (
    user_id INT,
    financial_year VARCHAR(10),
    return_file_date DATE
);

INSERT INTO users (user_id, financial_year, return_file_date) VALUES
(1, 'FY20', '2020-05-10'),
(1, 'FY21', '2021-10-10'),
(1, 'FY23', '2023-08-20'),
(2, 'FY20', '2020-05-15'),
(2, 'FY21', '2021-09-10'),
(2, 'FY22', '2022-08-20'),
(2, 'FY23', '2023-10-10');

CREATE TABLE income_tax_dates (
    financial_year VARCHAR(10),
    file_start_date DATE,
    file_due_date DATE
);

INSERT INTO income_tax_dates (financial_year, file_start_date, file_due_date) VALUES
('FY20', '2020-05-01', '2020-08-31'),
('FY21', '2021-06-01', '2021-09-30'),
('FY22', '2022-05-05', '2022-08-29'),
('FY23', '2023-05-05', '2023-08-31');


Output:

+---------+----------------+-------------+
| user_id | financial_year | comment     |
+---------+----------------+-------------+
|       1 | FY21           | late return |
|       1 | FY22           | missed      |
|       2 | FY23           | late return |
+---------+----------------+-------------+



---------------------------------------------------------------------------------------------------------------------------------------------


Q 28 - Malware Detection

Statement - There are multiple antivirus software which are running on the system and you have the data of how many malware they have detected in each run.  You need to find out how many malwares each software has detected in their latest run and what is the difference between the number of malwares detected in latest run and the second last run for each software. 

Please note that list only the software which have run for at least 2 times and have detected at least 10 malware in the latest run.

Table:

CREATE TABLE malware (
    software_id INT,
    run_date DATETIME,
    malware_detected INT
);

INSERT INTO malware (software_id, run_date, malware_detected) VALUES
(100, '2024-01-01 02:00:01', 12),
(100, '2024-01-01 03:12:01', 15),
(100, '2024-01-01 16:00:01', 9),
(101, '2024-01-01 12:00:00', 9),
(101, '2024-01-01 16:00:00', 10),
(101, '2024-01-01 18:00:00', 12),
(102, '2024-01-01 12:00:00', 14),
(102, '2024-01-01 14:00:00', 13),
(103, '2024-01-01 15:00:00', 11),
(103, '2024-01-01 17:00:00', 16),
(104, '2024-01-01 18:30:00', 8),
(104, '2024-01-01 19:45:00', 7),
(105, '2024-01-01 10:45:00', 15);


Output:

software_id latest_run_count difference_to_previous
----------- ---------------- ----------------------
        101               12                      2
        102               13                     -1
        103               16                      5
+--------------------+--------------------+----------+


---------------------------------------------------------------------------------------------------------------------------------------------



Q 29 - Software vs Data Analytics Engineers

Software - You are given the details of employees of a new startup. Write an SQL query to retrieve number of Software Engineers , Data Professionals and Managers in the team to separate columns. Below are the rules to identify them using Job Title. 

1- Software Engineers  :  The title should starts with “Software”
2- Data Professionals :  The title should starts with “Data”
3- Managers : The title should contain "Managers"

Tables: 
CREATE TABLE employees (
    EmployeeID INT,
    Name VARCHAR(100),
    JoinDate DATE,
    JobTitle VARCHAR(50)
);

INSERT INTO employees (EmployeeID, Name, JoinDate, JobTitle) VALUES
(1, 'John Doe', '2021-02-15', 'Software Engineer'),
(2, 'Jane Smith', '2022-03-20', 'Software Developer'),
(3, 'Alice Johnson', '2021-12-10', 'Software Engineer'),
(4, 'Bob Anderson', '2022-01-05', 'Project Manager'),
(5, 'Ella Williams', '2022-04-25', 'Software Engineer'),
(6, 'Michael Brown', '2022-03-10', 'Data Analyst'),
(7, 'Sophia Garcia', '2022-02-28', 'Software Engineer'),
(8, 'James Martinez', '2022-01-15', 'Project Manager'),
(9, 'Olivia Robinson', '2022-04-05', 'Software Engineer'),
(10, 'Liam Clark', '2022-03-01', 'Software Engineer'),
(11, 'Noah Thompson', '2022-05-10', 'Data Scientist'),
(12, 'Emma Lee', '2022-06-20', 'HR Manager'),
(13, 'Ava Lewis', '2022-07-15', 'Software Engineer'),
(14, 'Lucas Walker', '2022-08-10', 'Data Engineer'),
(15, 'Mia Hall', '2022-09-05', 'Software Engineer');



Output:
+--------------------+--------------------+----------+
| Software_Engineers | Data_Professionals | Managers |
+--------------------+--------------------+----------+
|                  9 |                  3 |        3 |
+--------------------+--------------------+----------+



---------------------------------------------------------------------------------------------------------------------------------------------



Q 30 - Employee Salary Levels

Statement - Write an SQL query to find the average salaries of employees at each salary level. "Salary Level" are defined as per below conditions:

If the salary is less than 50000, label it as "Low".
If the salary is between 50000 and 100000 (inclusive), label it as "Medium".
If the salary is greater than 100000, label it as "High".
Round the average to nearest integer. Display the output in ascending order of salary level.

Tables:

CREATE TABLE employees (
    employee_id INT,
    employee_name VARCHAR(100),
    salary DECIMAL(10, 2)
);

INSERT INTO employees (employee_id, employee_name, salary) VALUES
(1, 'John Doe', 45000),
(2, 'Jane Smith', 60000),
(3, 'Michael Johnson', 100000),
(4, 'Emily Brown', 75000),
(5, 'Christopher Lee', 48000),
(6, 'Amanda Wilson', 90000),
(7, 'Ankit Bansal', 110000),
(8, 'Sarah Davis', 50000),
(9, 'David Martinez', 85000),
(10, 'James Anderson', 95000),
(11, 'Patricia Thomas', 68000),
(12, 'Robert Jackson', 78000),
(13, 'Linda Harris', 72000),
(14, 'Charles Clark', 88000),
(15, 'Barbara Lewis', 56000);


Output:
+--------------+------------+
| Salary_Level | avg_salary |
+--------------+------------+
| High         |     110000 |
| Low          |      46500 |
| Medium       |      76417 |
+--------------+------------+



---------------------------------------------------------------------------------------------------------------------------------------------



Q 31 - Highly Paid Employees

Statement: You are given the data of employees along with their salary and department. Write an SQL to find list of employees who have salary greater than average employee salary of the company.  However, while calculating the company average salary to compare with an employee salary do not consider salaries of that employee's department, display the output in ascending order of employee ids.

Table:

CREATE TABLE employee (
    emp_id INT,
    salary DECIMAL(10, 2),
    department VARCHAR(50)
);

INSERT INTO employee (emp_id, salary, department) VALUES
(100, 40000, 'Analytics'),
(101, 30000, 'Analytics'),
(102, 50000, 'Analytics'),
(103, 45000, 'Engineering'),
(104, 48000, 'Engineering'),
(105, 51000, 'Engineering'),
(106, 46000, 'Science'),
(107, 38000, 'Science'),
(108, 37000, 'Science'),
(109, 42000, 'Analytics'),
(110, 55000, 'Engineering'),
(111, 39000, 'Science'),
(112, 47000, 'Analytics'),
(113, 43000, 'Engineering'),
(114, 36000, 'Science');

Output:
+--------+--------+-------------+
| emp_id | salary | department  |
+--------+--------+-------------+
|    102 |  50000 | Analytics   |
|    103 |  45000 | Engineering |
|    104 |  48000 | Engineering |
|    105 |  51000 | Engineering |
|    106 |  46000 | Science     |
|    110 |  55000 | Engineering |
|    112 |  47000 | Analytics   |
|    113 |  43000 | Engineering |
+--------+--------+-------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 32 - Warikoo 20-6-20

Statement - Ankur Warikoo, an influential figure in Indian social media, shares a guideline in one of his videos called the 20-6-20 rule for determining whether one can afford to buy a phone or not. The rule for affordability entails three conditions:

 

1. Having enough savings to cover a 20 percent down payment.
2. Utilizing a maximum 6-month EMI plan (no-cost) for the remaining cost.
3. Monthly EMI should not exceed 20 percent of one's monthly salary.
Given the salary and savings of various users, along with data on phone costs, the task is to write an SQL to generate a list of phones (comma-separated) that each user can afford based on these criteria, display the output in ascending order of the user name.

 

Table:

CREATE TABLE users (
    user_name VARCHAR(50),
    monthly_salary DECIMAL(10, 2),
    savings DECIMAL(10, 2)
);

INSERT INTO users (user_name, monthly_salary, savings) VALUES
('Rahul', 40000, 15000),
('Vivek', 70000, 10000);

CREATE TABLE phones (
    phone_name VARCHAR(50),
    cost DECIMAL(10, 2)
);

INSERT INTO phones (phone_name, cost) VALUES
('iphone-12', 60000),
('oneplus-12', 50000),
('iphone-14', 70000);


Output:
+-----------+----------------------+
| user_name | affordable_phones    |
+-----------+----------------------+
| Rahul     | iphone-12,oneplus-12 |
| Vivek     | oneplus-12           |
+-----------+----------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 33 - Average Order Value

Statement - Write an SQL query to determine the transaction date with the lowest average order value (AOV) among all dates recorded in the transaction table. Display the transaction date, its corresponding AOV, and the difference between the AOV for that date and the highest AOV for any day in the dataset. Round the result to 2 decimal places.

 

Table: 
CREATE TABLE transactions (
    order_id INT,
    user_id INT,
    transaction_amount DECIMAL(10, 2),
    transaction_date DATE
);

INSERT INTO transactions (order_id, user_id, transaction_amount, transaction_date) VALUES
(1, 101, 50.00, '2024-02-24'),
(2, 102, 75.00, '2024-02-24'),
(3, 103, 100.00, '2024-02-25'),
(4, 104, 30.00, '2024-02-26'),
(5, 105, 200.00, '2024-02-27'),
(6, 106, 50.00, '2024-02-27'),
(7, 107, 150.00, '2024-02-27'),
(8, 108, 80.00, '2024-02-29');

Output:
+------------------+-------+-----------------------+
| transaction_date | aov   | diff_from_highest_aov |
+------------------+-------+-----------------------+
| 2024-02-26       | 30.00 |                103.33 |
+------------------+-------+-----------------------+



---------------------------------------------------------------------------------------------------------------------------------------------



Q 34 - Employee vs Manager

Statement - You are given the table of employee details. Write an SQL to find details of employee with salary more than their manager salary but they joined the company after the manager joined.

Display employee name, salary and joining date along with their manager's salary and joining date, sort the output in ascending order of employee name.

Please note that manager id in the employee table referring to emp id of the same table.

Table:

CREATE TABLE employee (
    emp_id INT,
    emp_name VARCHAR(50),
    joining_date DATE,
    salary DECIMAL(10, 2),
    manager_id INT
);

INSERT INTO employee (emp_id, emp_name, joining_date, salary, manager_id) VALUES
(1, 'Ankit', '2021-01-01', 10000, 4),
(2, 'Mohit', '2022-05-01', 15000, 5),
(3, 'Vikas', '2023-06-01', 10000, 4),
(4, 'Rohit', '2022-02-01', 5000, 2),
(5, 'Mudit', '2021-03-01', 12000, 6),
(6, 'Agam', '2024-02-01', 12000, 2),
(7, 'Sanjay', '2024-02-21', 9000, 2),
(8, 'Ashish', '2023-01-05', 5000, 2),
(9, 'Mukesh', '2020-02-03', 6000, 6),
(10, 'Rakesh', '2022-08-01', 7000, 6);


Output:
+----------+--------+--------------+----------------+----------------------+
| emp_name | salary | joining_date | manager_salary | manager_joining_date |
+----------+--------+--------------+----------------+----------------------+
| Mohit    |  15000 | 2022-05-01   |          12000 | 2021-03-01           |
| Vikas    |  10000 | 2023-06-01   |           5000 | 2022-02-01           |
+----------+--------+--------------+----------------+----------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 35 - Cancellation vs Return

Statement - You are given orders data of an ecommerce website with order date, delivery date and cancel date information. If the order is cancelled after it is delivered then it will be considered as a return order else cancelled order.  In case of canceled order delivery will not take place.

Write an SQL to calculate cancellation rate and return rate for each month (as per order date).  Round the rates to 2 decimal places.

 

cancel rate = (# orders cancelled / # orders placed but not returned ) * 100 
return rate = (# orders returned/ #orders placed but not cancelled) * 100 
Sort the output by increasing order of year order and year month.

Table:
CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    order_date DATE,
    delivery_date DATE,
    cancel_date DATE
);

INSERT INTO orders (order_id, customer_id, order_date, delivery_date, cancel_date) VALUES
(1, 101, '2023-01-05', '2023-01-10', NULL),
(2, 102, '2023-01-10', '2023-01-15', '2023-01-16'),
(3, 103, '2023-01-15', NULL, '2023-01-20'),
(4, 104, '2023-01-07', '2023-01-10', NULL),
(5, 105, '2023-01-13', '2023-01-17', '2023-01-19'),
(6, 106, '2023-02-15', '2023-02-20', NULL),
(7, 107, '2023-02-05', '2023-02-05', '2023-02-08'),
(8, 108, '2023-02-10', NULL, '2023-02-15');


Output: 
+------------+-------------+-------------------+-------------+
| order_year | order_month | cancellation_rate | return_rate |
+------------+-------------+-------------------+-------------+
|       2023 |           1 |             33.33 |       50.00 |
|       2023 |           2 |             50.00 |       50.00 |
+------------+-------------+-------------------+-------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 36 - Airbnb Business

Statement - You are planning to list a property on Airbnb. To maximize profits, you need to analyze the Airbnb data for the month of January 2023 to determine the best room type for each location. The best room type is based on the maximum average occupancy during the given month.

Write an SQL query to find the best room type for each location based on the average occupancy days. Order the results in descending order of average occupancy days, rounded to 2 decimal places.

Table:
CREATE TABLE listings (
    listing_id INT,
    host_id INT,
    location VARCHAR(50),
    room_type VARCHAR(50),
    price DECIMAL(10, 2),
    minimum_nights INT
);

INSERT INTO listings (listing_id, host_id, location, room_type, price, minimum_nights) VALUES
(1, 101, 'Downtown', 'Entire home/apt', 150.00, 2),
(2, 101, 'Downtown', 'Private room', 80.00, 1),
(3, 101, 'Downtown', 'Entire home/apt', 200.00, 3),
(4, 102, 'Downtown', 'Entire home/apt', 120.00, 2),
(5, 102, 'Downtown', 'Private room', 100.00, 1),
(6, 102, 'Midtown', 'Entire home/apt', 250.00, 2),
(7, 103, 'Midtown', 'Entire home/apt', 70.00, 1),
(8, 103, 'Midtown', 'Private room', 90.00, 1),
(9, 104, 'Midtown', 'Private room', 170.00, 1);


CREATE TABLE bookings (
    booking_id INT,
    listing_id INT,
    checkin_date DATE,
    checkout_date DATE
);

INSERT INTO bookings (booking_id, listing_id, checkin_date, checkout_date) VALUES
(1, 1, '2023-01-05', '2023-01-10'),
(2, 1, '2023-01-11', '2023-01-13'),
(3, 2, '2023-01-15', '2023-01-25'),
(4, 3, '2023-01-10', '2023-01-17'),
(5, 3, '2023-01-19', '2023-01-21'),
(6, 3, '2023-01-22', '2023-01-23'),
(7, 4, '2023-01-03', '2023-01-05'),
(8, 5, '2023-01-10', '2023-01-12'),
(9, 6, '2023-01-15', '2023-01-19'),
(10, 6, '2023-01-20', '2023-01-22'),
(11, 7, '2023-01-25', '2023-01-29'),
(12, 8, '2023-01-05', '2023-01-17'),
(13, 9, '2023-01-10', '2023-01-12');


Output:
+----------+-----------------+---------------+
| location | room_type       | avg_book_days |
+----------+-----------------+---------------+
| Midtown  | Private room    |          7.00 |
| Downtown | Entire home/apt |          6.33 |
+----------+-----------------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 37 - Spotify Popular Tracks
Statement - Suppose you are a data analyst working for Spotify (a music streaming service company) . Your company is interested in analyzing user engagement with playlists and wants to identify the most popular tracks among all the playlists.

Write an SQL query to find the top 2 most popular tracks based on number of playlists they are part of. 

Your query should return the top 2 track ID along with total number of playlist they are part of , sorted by the same and  track id in descending order , Please consider only those playlists which were played by at least 2 distinct users.


Table:
CREATE TABLE playlists (
    playlist_id INT,
    playlist_name VARCHAR(50)
);

INSERT INTO playlists (playlist_id, playlist_name) VALUES
(1, 'Chill Vibes'),
(2, 'Morning Jams'),
(3, 'Workout Beats'),
(4, 'Party Mix'),
(5, 'Study Playlist');


CREATE TABLE playlist_tracks (
    playlist_id INT,
    track_id INT
);

INSERT INTO playlist_tracks (playlist_id, track_id) VALUES
(1, 101),
(1, 102),
(1, 103),
(1, 104),
(2, 104),
(2, 102),
(3, 104),
(3, 107),
(4, 101),
(4, 104),
(4, 110),
(5, 104),
(5, 109),
(5, 101);


CREATE TABLE playlist_plays (
    playlist_id INT,
    user_id VARCHAR(10)
);

INSERT INTO playlist_plays (playlist_id, user_id) VALUES
(1, 'u1'),
(1, 'u2'),
(2, 'u3'),
(3, 'u3'),
(3, 'u1'),
(1, 'u4'),
(4, 'u1'),
(4, 'u2'),
(5, 'u3'),
(5, 'u1');


Output:

+----------+----------------+
| track_id | no_of_playlist |
+----------+----------------+
|      104 |              4 |
|      101 |              3 |
+----------+----------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 38 - Product Reviews

Statement - Suppose you are a data analyst working for a retail company, and your team is interested in analysing customer feedback to identify trends and patterns in product reviews.

Your task is to write an SQL query to find all product reviews containing the word "excellent" or "amazing" in the review text. However, you want to exclude reviews that contain the word "not" immediately before "excellent" or "amazing". Please note that the words can be in upper or lower case or combination of both. 

Your query should return the review_id,product_id, and review_text for each review meeting the criteria, display the output in ascending order of review_id.

Table:
CREATE TABLE product_reviews (
    review_id INT,
    product_id INT,
    review_text VARCHAR(255)
);

INSERT INTO product_reviews (review_id, product_id, review_text) VALUES
(1, 101, 'The product is excellent!'),
(2, 102, 'This product is Amazing.'),
(3, 103, 'Not an excellent product.'),
(4, 104, 'The quality is Excellent.'),
(5, 105, 'An amazing product!'),
(6, 106, 'This is not an amazing product.'),
(7, 107, 'This product is not Excellent.'),
(8, 108, 'This is a not excellent product.'),
(9, 109, 'The product is not amazing.'),
(10, 110, 'An excellent product, not amazing.'),
(11, 101, 'A good product');


Output:
+-----------+------------+---------------------------------+
| review_id | product_id | review_text                     |
+-----------+------------+---------------------------------+
|         1 |        101 | The product is excellent!       |
|         2 |        102 | This product is Amazing.        |
|         3 |        103 | Not an excellent product.       |
|         4 |        104 | The quality is Excellent.       |
|         5 |        105 | An amazing product!             |
|         6 |        106 | This is not an amazing product. |
+-----------+------------+---------------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 39 - Walmart Sales Pattern

Statement - You are tasked with analyzing the sales data of a Walmart chain with multiple stores across different locations. The company wants to identify the highest and lowest sales months for each location for the year 2023 to gain insights into their sales patterns, display the output in ascending order of location. In case of a tie display the latest month.

Table:
CREATE TABLE stores (
    store_id INT,
    store_name VARCHAR(50),
    location VARCHAR(50)
);

INSERT INTO stores (store_id, store_name, location) VALUES
(1, 'Store A', 'New York'),
(2, 'Store B', 'New York'),
(3, 'Store C', 'Los Angeles'),
(4, 'Store D', 'Los Angeles'),
(5, 'Store E', 'Chicago'),
(6, 'Store F', 'Chicago');


CREATE TABLE transactions (
    transaction_id INT,
    customer_id INT,
    store_id INT,
    transaction_date DATE,
    amount DECIMAL(10, 2)
);

INSERT INTO transactions (transaction_id, customer_id, store_id, transaction_date, amount) VALUES
(1, 101, 1, '2023-01-05', 100),
(2, 102, 1, '2023-01-10', 150),
(3, 103, 3, '2023-01-15', 200),
(4, 104, 3, '2023-01-20', 250),
(5, 105, 5, '2023-01-25', 800),
(6, 101, 2, '2023-02-05', 120),
(7, 102, 2, '2023-02-10', 130),
(8, 103, 4, '2023-02-15', 180),
(9, 104, 4, '2023-02-20', 230),
(10, 105, 6, '2023-02-25', 270),
(11, 101, 1, '2023-03-05', 90),
(12, 102, 1, '2023-03-10', 170),
(13, 103, 3, '2023-03-15', 220),
(14, 104, 3, '2023-03-20', 260),
(15, 105, 5, '2023-03-25', 290),
(16, 101, 2, '2023-04-05', 110),
(17, 102, 2, '2023-04-10', 140),
(18, 103, 4, '2023-04-15', 190),
(19, 104, 4, '2023-04-20', 240),
(20, 105, 6, '2023-04-25', 280),
(21, 101, 1, '2023-05-05', 130),
(22, 102, 1, '2023-05-10', 160),
(23, 103, 3, '2023-05-15', 210),
(24, 104, 3, '2023-05-20', 250),
(25, 105, 5, '2023-05-25', 300),
(26, 101, 2, '2023-06-05', 140),
(27, 102, 2, '2023-06-10', 150),
(28, 103, 4, '2023-06-15', 200),
(29, 104, 4, '2023-06-20', 240),
(30, 105, 6, '2023-06-25', 280),
(31, 101, 1, '2023-07-05', 150),
(32, 102, 1, '2023-07-10', 170),
(33, 103, 3, '2023-07-15', 210),
(34, 104, 3, '2023-07-20', 250),
(35, 105, 5, '2023-07-25', 300),
(36, 101, 2, '2023-08-05', 160),
(37, 102, 2, '2023-08-10', 180),
(38, 103, 4, '2023-08-15', 220),
(39, 104, 4, '2023-08-20', 260),
(40, 105, 6, '2023-08-25', 310),
(41, 101, 1, '2023-09-05', 170),
(42, 102, 1, '2023-09-10', 190),
(43, 103, 3, '2023-09-15', 230),
(44, 104, 3, '2023-09-20', 270),
(45, 105, 5, '2023-09-25', 320),
(46, 101, 2, '2023-10-05', 180),
(47, 102, 2, '2023-10-10', 200),
(48, 103, 4, '2023-10-15', 240),
(49, 104, 4, '2023-10-20', 280),
(50, 105, 6, '2023-10-25', 330),
(51, 101, 1, '2023-11-05', 190),
(52, 102, 1, '2023-11-10', 210),
(53, 103, 3, '2023-11-15', 250),
(54, 104, 3, '2023-11-20', 290),
(55, 105, 5, '2023-11-25', 340),
(56, 101, 2, '2023-12-05', 200),
(57, 102, 2, '2023-12-10', 220),
(58, 103, 4, '2023-12-15', 260),
(59, 104, 4, '2023-12-20', 300),
(60, 105, 6, '2023-12-25', 350);


Output:
+-------------+---------------------+--------------------+
| location    | highest_sales_month | lowest_sales_month |
+-------------+---------------------+--------------------+
| Chicago     |                   1 |                  2 |
| Los Angeles |                  12 |                  2 |
| New York    |                  12 |                  4 |
+-------------+---------------------+--------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 40 – Uber Driver Ratings

Suppose you are a data analyst working for ride-sharing platform Uber. Uber is interested in analyzing the performance of drivers based on their ratings and wants to categorize them into different performance tiers. 

Write an SQL query to categorize drivers equally into three performance tiers (Top, Middle, and Bottom) based on their average ratings. Drivers with the highest average ratings should be placed in the top tier, drivers with ratings below the top tier but above the bottom tier should be placed in the middle tier, and drivers with the lowest average ratings should be placed in the bottom tier. Sort the output in decreasing order of average rating.

Table :
CREATE TABLE driver_ratings (
    driver_id INT,
    avg_rating DECIMAL(3, 2)
);

INSERT INTO driver_ratings (driver_id, avg_rating) VALUES
(1, 4.80),
(2, 4.50),
(3, 3.90),
(4, 4.20),
(5, 4.70),
(6, 3.60),
(7, 4.90),
(8, 3.80),
(9, 4.40),
(10, 3.50),
(11, 4.10),
(12, 4.60);


Output:
+-----------+------------+------------------+
| driver_id | avg_rating | performance_tier |
+-----------+------------+------------------+
|         7 |       4.90 | Top              |
|         1 |       4.80 | Top              |
|         5 |       4.70 | Top              |
|        12 |       4.60 | Top              |
|         2 |       4.50 | Middle           |
|         9 |       4.40 | Middle           |
|         4 |       4.20 | Middle           |
|        11 |       4.10 | Middle           |
|         3 |       3.90 | Bottom           |
|         8 |       3.80 | Bottom           |
|         6 |       3.60 | Bottom           |
|        10 |       3.50 | Bottom           |
+-----------+------------+------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 41 - Zomato Customer Behavior

Statement - Suppose you are a data analyst working for Zomato (a online food delivery company) . Zomato is interested in analysing customer food ordering behavior and wants to identify customers who have exhibited inconsistent patterns over time.

Your task is to write an SQL query to identify customers who have placed orders on both weekdays and weekends, but with a significant difference in the average order amount between weekdays and weekends. Specifically, you need to identify customers who have a minimum of 3 orders placed both on weekdays and weekends each, and where the average order amount on weekends is at least 20% higher than the average order amount on weekdays.

Your query should return the customer id, the average order amount on weekends, the average order amount on weekdays, and the percentage difference in average order amount between weekends and weekdays for each customer meeting the criteria.

Table:
CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    order_date DATE,
    order_amount DECIMAL(10, 2)
);

INSERT INTO orders (order_id, customer_id, order_date, order_amount) VALUES
(1, 101, '2023-01-04', 100),
(2, 101, '2023-01-05', 200),
(3, 101, '2023-01-06', 80),
(4, 101, '2023-01-07', 110),
(5, 101, '2023-01-08', 90),
(6, 101, '2023-01-14', 130),
(7, 101, '2023-01-15', 150),
(8, 101, '2023-01-21', 100),
(9, 101, '2023-01-22', 120),
(10, 101, '2023-01-28', 90),
(11, 102, '2023-01-29', 110),
(12, 102, '2023-02-04', 80),
(13, 102, '2023-02-05', 100),
(14, 102, '2023-02-11', 120),
(15, 102, '2023-02-15', 140),
(16, 102, '2023-02-18', 80),
(17, 102, '2023-02-19', 100),
(18, 102, '2023-02-25', 120),
(19, 102, '2023-02-28', 140),
(20, 102, '2023-03-04', 80),
(31, 104, '2023-04-09', 140),
(32, 104, '2023-04-13', 80),
(33, 104, '2023-04-16', 100),
(34, 104, '2023-04-22', 200),
(35, 104, '2023-04-27', 140),
(36, 104, '2023-04-28', 80),
(37, 104, '2023-04-30', 100);


Output:
+-------------+--------------------+--------------------+--------------+
| customer_id | weekend_avg_amount | weekday_avg_amount | percent_diff |
+-------------+--------------------+--------------------+--------------+
|         104 |           135.0000 |           100.0000 | 35.000000000 |
+-------------+--------------------+--------------------+--------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 42 - Points Table

Statement - You are given table of cricket match played in a ICC cricket tournament with the details of winner for each match. You need to derive a points table using below rules.

1- For each win a team gets 2 points. 
2- For a loss team gets 0 points.
3- In case of a draw both the team gets 1 point each.
Display team name , matches played, # of wins , # of losses and points.  Sort output in ascending order of team name.

Table:
CREATE TABLE icc_world_cup (
    team_1 VARCHAR(50),
    team_2 VARCHAR(50),
    winner VARCHAR(50)
);

INSERT INTO icc_world_cup (team_1, team_2, winner) VALUES
('India', 'SL', 'India'),
('SL', 'Aus', 'Draw'),
('SA', 'Eng', 'Eng'),
('Eng', 'NZ', 'NZ'),
('Aus', 'India', 'India'),
('Eng', 'SA', 'Draw');


Output:
+-----------+--------------+------------+--------------+--------------+
| team_name | match_played | no_of_wins | no_of_losses | total_points |
+-----------+--------------+------------+--------------+--------------+
| Aus       |            2 |          0 |            1 |            1 |
| Eng       |            3 |          1 |            1 |            3 |
| India     |            2 |          2 |            0 |            4 |
| NZ        |            1 |          1 |            0 |            2 |
| SA        |            2 |          0 |            1 |            1 |
| SL        |            2 |          0 |            1 |            1 |
+-----------+--------------+------------+--------------+--------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 43 - Customer Retention

Statement - Customer retention can be defined as number of customers who continue to make purchases over a certain period compared to the total number of customers. Here's a step-by-step approach to calculate customer retention rate:

1- Determine the number of customers who made purchases 
in the current period (e.g., month: m )
2- Identify the number of customers from month m who made purchases 
in month m+1 , m+2 as well.
Suppose you are a data analyst working for Amazon. The company is interested in measuring customer retention over the months to understand how many customers continue to make purchases over time. Your task is to write an SQL to derive customer retention month over month, display the output in ascending order of current year, month & future year, month.

Table:

CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    order_date DATE
);

INSERT INTO orders (order_id, customer_id, order_date) VALUES
(1, 101, '2023-12-01'),
(2, 102, '2023-12-02'),
(3, 103, '2023-12-13'),
(4, 104, '2024-01-05'),
(5, 101, '2024-01-06'),
(6, 102, '2024-01-08'),
(7, 102, '2024-01-10'),
(8, 104, '2024-02-15'),
(9, 105, '2024-02-20'),
(10, 102, '2024-02-25');


Output:
+--------------+---------------+-------------+--------------+-----------------+--------------------+
| current_year | current_month | future_year | future_month | total_customers | retained_customers |
+--------------+---------------+-------------+--------------+-----------------+--------------------+
|         2023 |            12 |        2024 |            1 |               3 |                  2 |
|         2023 |            12 |        2024 |            2 |               3 |                  1 |
|         2024 |             1 |        2024 |            2 |               3 |                  2 |
+--------------+---------------+-------------+--------------+-----------------+--------------------+

---------------------------------------------------------------------------------------------------------------------------------------------


Q 44 - Excess/insufficient Inventory

Statement - Suppose you are a data analyst working for Flipkart. Your task is to identify excess and insufficient inventory at various Flipkart warehouses in terms of no of units and cost.  Excess inventory is when inventory levels are greater than inventory targets else its insufficient inventory.

Write an SQL to derive excess/insufficient Inventory volume and value in cost for each location as well as at overall company level, display the results in ascending order of location id.

Table:
CREATE TABLE inventory (
    location_id INT,
    product_id INT,
    inventory_level INT,
    inventory_target INT
);

INSERT INTO inventory (location_id, product_id, inventory_level, inventory_target) VALUES
(1, 101, 90, 80),
(1, 102, 100, 85),
(2, 102, 90, 80),
(2, 103, 70, 95),
(2, 104, 50, 60),
(3, 103, 120, 100),
(4, 104, 90, 102);

CREATE TABLE products (
    product_id INT,
    unit_cost DECIMAL(10, 2)
);

INSERT INTO products (product_id, unit_cost) VALUES
(101, 51.50),
(102, 55.50),
(103, 59.00),
(104, 50.00);


Output:
+-------------+-------------------------+---------------------------+
| location_id | excess_insufficient_qty | excess_insufficient_value |
+-------------+-------------------------+---------------------------+
| 1           |                      25 |                   1347.50 |
| 2           |                     -25 |                  -1420.00 |
| 3           |                      20 |                   1180.00 |
| 4           |                     -12 |                   -600.00 |
| Overall     |                       8 |                    507.50 |
+-------------+-------------------------+---------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 45 - Zomato Membership

Statement - Zomato is planning to offer a premium membership to customers who have placed multiple orders in a single day.

Your task is to write a SQL to find those customers who have placed multiple orders in a single day at least once , total order value generate by those customers and order value generated only by those orders, display the results in ascending order of total order value.

Table:



CREATE TABLE orders (
    order_id INT,
    order_date DATETIME,
    customer_name VARCHAR(255),
    order_value DECIMAL(10, 2)
);

INSERT INTO orders (order_id, order_date, customer_name, order_value) VALUES
(1, '2023-01-13 12:30:00', 'Rahul', 250),
(2, '2023-01-13 08:30:00', 'Rahul', 350),
(3, '2023-01-13 09:00:00', 'Mudit', 230),
(4, '2023-01-14 08:30:00', 'Rahul', 150),
(5, '2023-01-14 12:03:00', 'Suresh', 130),
(6, '2023-01-15 09:34:00', 'Mudit', 250),
(7, '2023-01-15 12:30:00', 'Mudit', 300),
(8, '2023-01-15 09:30:00', 'Rahul', 250),
(9, '2023-01-15 12:35:00', 'Rahul', 300),
(10, '2023-01-15 12:03:00', 'Suresh', 130);

Output:
+---------------+-------------------+-------------+
| customer_name | total_order_value | order_value |
+---------------+-------------------+-------------+
| Mudit         |               780 |         550 |
| Rahul         |              1300 |        1150 |
+---------------+-------------------+-------------+



---------------------------------------------------------------------------------------------------------------------------------------------


Q 45 - Zomato Membership

Statement - Zomato is planning to offer a premium membership to customers who have placed multiple orders in a single day.

Your task is to write a SQL to find those customers who have placed multiple orders in a single day at least once , total order value generate by those customers and order value generated only by those orders, display the results in ascending order of total order value.

Table:


CREATE TABLE orders (
    order_id INT,
    order_date DATETIME,
    customer_name VARCHAR(255),
    order_value DECIMAL(10, 2)
);

INSERT INTO orders (order_id, order_date, customer_name, order_value) VALUES
(1, '2023-01-13 12:30:00', 'Rahul', 250),
(2, '2023-01-13 08:30:00', 'Rahul', 350),
(3, '2023-01-13 09:00:00', 'Mudit', 230),
(4, '2023-01-14 08:30:00', 'Rahul', 150),
(5, '2023-01-14 12:03:00', 'Suresh', 130),
(6, '2023-01-15 09:34:00', 'Mudit', 250),
(7, '2023-01-15 12:30:00', 'Mudit', 300),
(8, '2023-01-15 09:30:00', 'Rahul', 250),
(9, '2023-01-15 12:35:00', 'Rahul', 300),
(10, '2023-01-15 12:03:00', 'Suresh', 130);



Output:

+---------------+-------------------+-------------+
| customer_name | total_order_value | order_value |
+---------------+-------------------+-------------+
| Mudit         |               780 |         550 |
| Rahul         |              1300 |        1150 |
+---------------+-------------------+-------------+



---------------------------------------------------------------------------------------------------------------------------------------------



Q 46 - Employees Inside Office (Part 1)

Statement - A company record its employee's movement In and Out of office in a table. Please note below points about the data:

1- First entry for each employee is “in”
2- Every “in” is succeeded by an “out”
3- Employee can work across days
Write a SQL to find the number of employees inside the Office at “2019-04-01 19:05:00".

Table:
CREATE TABLE employee_record (
    emp_id INT,
    action VARCHAR(10),
    created_at DATETIME
);

INSERT INTO employee_record (emp_id, action, created_at) VALUES
(1, 'in', '2019-04-01 12:00:00'),
(1, 'out', '2019-04-01 15:00:00'),
(1, 'in', '2019-04-01 17:00:00'),
(1, 'out', '2019-04-01 21:00:00'),
(2, 'in', '2019-04-01 10:00:00'),
(2, 'out', '2019-04-01 16:00:00'),
(3, 'in', '2019-04-01 19:00:00'),
(3, 'out', '2019-04-02 05:00:00'),
(4, 'in', '2019-04-01 10:00:00'),
(4, 'out', '2019-04-01 20:00:00');


Ouput:
+------------------+
| no_of_emp_inside |
+------------------+
|                3 |
+------------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 47 - Employees Inside Office (Part 2)
Statement - A company record its employee's movement In and Out of office in a table. Please note below points about the data:

1- First entry for each employee is “in”
2- Every “in” is succeeded by an “out”
3- Employee can work across days
Write an SQL to measure the time spent by each employee inside the office between “2019-04-01 14:00:00” and “2019-04-02 10:00:00" in minutes, display the output in ascending order of employee id .

Table:

CREATE TABLE employee_record (
    emp_id INT,
    action VARCHAR(10),
    created_at DATETIME
);

INSERT INTO employee_record (emp_id, action, created_at) VALUES
(1, 'in', '2019-04-01 12:00:00'),
(1, 'out', '2019-04-01 15:00:00'),
(1, 'in', '2019-04-01 17:00:00'),
(1, 'out', '2019-04-01 21:00:00'),
(2, 'in', '2019-04-01 10:00:00'),
(2, 'out', '2019-04-01 13:00:00'),
(3, 'in', '2019-04-01 19:00:00'),
(3, 'out', '2019-04-02 05:00:00'),
(4, 'in', '2019-04-01 18:00:00'),
(4, 'out', '2019-04-02 20:00:00'),
(5, 'in', '2019-04-01 10:00:00'),
(5, 'out', '2019-04-02 11:00:00'),
(6, 'in', '2019-04-02 11:00:00'),
(6, 'out', '2019-04-02 16:00:00');



Output:
+--------+--------------------+
| emp_id | time_spent_in_mins |
+--------+--------------------+
|      1 |                300 |
|      2 |                  0 |
|      3 |                600 |
|      4 |                960 |
|      5 |               1200 |
|      6 |                  0 |
+--------+--------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 48 – Female Contribution

Statement - You are given a history of credit card transaction data for the people of India across cities. Write an SQL to find percentage contribution of spends by females in each city.  Round the percentage to 2 decimal places. Display city, total spend , female spend and female contribution in ascending order of city.

Table:

CREATE TABLE credit_card_transactions (
    transaction_id INT,
    city VARCHAR(50),
    transaction_date DATE,
    card_type VARCHAR(20),
    gender CHAR(1),
    amount DECIMAL(10, 2)
);

INSERT INTO credit_card_transactions (transaction_id, city, transaction_date, card_type, gender, amount) VALUES
(1, 'Delhi', '2024-01-13', 'Gold', 'F', 500.00),
(2, 'Bengaluru', '2024-01-13', 'Silver', 'M', 1000.00),
(3, 'Mumbai', '2024-01-14', 'Silver', 'F', 1200.00),
(4, 'Bengaluru', '2024-01-14', 'Gold', 'M', 900.00),
(5, 'Bengaluru', '2024-01-14', 'Gold', 'F', 300.00),
(6, 'Delhi', '2024-01-15', 'Silver', 'M', 200.00),
(7, 'Mumbai', '2024-01-15', 'Gold', 'F', 900.00),
(8, 'Delhi', '2024-01-15', 'Gold', 'F', 800.00),
(9, 'Mumbai', '2024-01-15', 'Silver', 'F', 150.00),
(10, 'Mumbai', '2024-01-16', 'Platinum', 'F', 1900.00),
(11, 'Bengaluru', '2024-01-16', 'Platinum', 'M', 1250.00),
(12, 'Delhi', '2024-01-16', 'Platinum', 'F', 130.00);



Output:
+-----------+-------------+--------------+---------------------+
| city      | total_spend | female_spend | female_contribution |
+-----------+-------------+--------------+---------------------+
| Bengaluru |        3450 |          300 |                8.70 |
| Delhi     |        1630 |         1430 |               87.73 |
| Mumbai    |        4150 |         4150 |              100.00 |
+-----------+-------------+--------------+---------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 49 - Credit Card Transactions (Part-1)

Statement - You are given a history of credit card transaction data for the people of India across cities . Write an SQL to find how many days each city took to reach cumulative spend of 1500 from its first day of transactions. 

Display city, first transaction date , date of 1500 spend and # of days in the ascending order of city.

Table:

CREATE TABLE credit_card_transactions (
    transaction_id INT,
    city VARCHAR(50),
    transaction_date DATE,
    card_type VARCHAR(20),
    gender CHAR(1),
    amount DECIMAL(10, 2)
);

INSERT INTO credit_card_transactions (transaction_id, city, transaction_date, card_type, gender, amount) VALUES
(1, 'Delhi', '2024-01-13', 'Gold', 'F', 500.00),
(2, 'Bengaluru', '2024-01-12', 'Silver', 'M', 1000.00),
(3, 'Mumbai', '2024-01-14', 'Silver', 'F', 300.00),
(4, 'Bengaluru', '2024-01-14', 'Gold', 'M', 900.00),
(5, 'Bengaluru', '2024-01-14', 'Gold', 'F', 300.00),
(6, 'Delhi', '2024-01-15', 'Silver', 'M', 200.00),
(7, 'Mumbai', '2024-01-15', 'Gold', 'F', 500.00),
(8, 'Delhi', '2024-01-15', 'Gold', 'F', 700.00),
(9, 'Mumbai', '2024-01-15', 'Silver', 'F', 150.00),
(10, 'Mumbai', '2024-01-18', 'Platinum', 'F', 1000.00),
(11, 'Bengaluru', '2024-01-16', 'Platinum', 'M', 1250.00),
(12, 'Delhi', '2024-01-16', 'Platinum', 'F', 130.00);



Output:


+-----------+------------------------+----------------+------------+
| city      | first_transaction_date | tran_date_1500 | no_of_days |
+-----------+------------------------+----------------+------------+
| Bengaluru | 2024-01-12             | 2024-01-14     |          2 |
| Delhi     | 2024-01-13             | 2024-01-16     |          3 |
| Mumbai    | 2024-01-14             | 2024-01-18     |          4 |
+-----------+------------------------+----------------+------------+



---------------------------------------------------------------------------------------------------------------------------------------------


Q 50 - Adverse Reactions

In the field of pharmacovigilance, it's crucial to monitor and assess adverse reactions that patients may experience after taking certain medications. Adverse reactions, also known as side effects, can range from mild to severe and can impact the safety and efficacy of a medication.

For each medication, count the number of adverse reactions reported within the first 30 days of the prescription being issued. Assume that the prescription date in the Prescriptions table represents the start date of the medication usage, display the output in ascending order of medication name.

table : -- Create the table
CREATE TABLE patients (
    patient_id INT,
    name VARCHAR(100),
    age INT,
    gender VARCHAR(10)
);

-- Insert the data
INSERT INTO patients (patient_id, name, age, gender)
VALUES
    (1, 'John Doe', 35, 'Male'),
    (2, 'Jane Smith', 45, 'Female'),
    (3, 'Alice Johnson', 25, 'Female');




-- Create the table
CREATE TABLE medications (
    medication_id INT,
    medication_name VARCHAR(100),
    manufacturer VARCHAR(100)
);

-- Insert the data
INSERT INTO medications (medication_id, medication_name, manufacturer)
VALUES
    (1, 'Aspirin', 'Pfizer'),
    (2, 'Tylenol', 'Johnson & Johnson'),
    (3, 'Lipitor', 'Pfizer');




-- Create the table
CREATE TABLE prescriptions (
    prescription_id INT,
    patient_id INT,
    medication_id INT,
    prescription_date DATE
);

-- Insert the data
INSERT INTO prescriptions (prescription_id, patient_id, medication_id, prescription_date)
VALUES
    (1, 1, 1, '2023-01-01'),
    (2, 1, 2, '2023-02-15'),
    (3, 2, 1, '2023-03-10'),
    (4, 3, 3, '2023-04-20');



-- Create the table
CREATE TABLE adverse_reactions (
    reaction_id INT,
    patient_id INT,
    reaction_description VARCHAR(255),
    reaction_date DATE
);

-- Insert the data
INSERT INTO adverse_reactions (reaction_id, patient_id, reaction_description, reaction_date)
VALUES
    (1, 1, 'Nausea', '2023-01-05'),
    (2, 2, 'Headache', '2023-03-20'),
    (3, 3, 'Dizziness', '2023-05-01'),
    (4, 1, 'Rash', '2023-01-20'),
    (5, 2, 'Nausea', '2023-04-05');

output : 
+-----------------+-------------------+-----------------------+
| medication_name | manufacturer      | num_adverse_reactions |
+-----------------+-------------------+-----------------------+
| Aspirin         | Pfizer            |                     4 |
| Lipitor         | Pfizer            |                     1 |
| Tylenol         | Johnson & Johnson |                     0 |
+-----------------+-------------------+-----------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 51 - Balanced Team


Suppose you are a manager of a data analytics company. You are tasked to build a new team consists of senior and junior data analysts. The total budget for the salaries is 70000.  You need to use the below criterion for hiring:

 

1- Keep hiring the seniors with the smallest salaries until you cannot hire anymore seniors.
2- Use the remaining budget to hire the juniors with the smallest salaries until you cannot hire anymore juniors.
Display employee id, experience and salary. Sort in decreasing order of salary.

table : -- Create the table
CREATE TABLE candidates (
    emp_id INT,
    experience VARCHAR(20),
    salary DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO candidates (emp_id, experience, salary)
VALUES
    (1, 'Junior', 10000),
    (2, 'Junior', 15000),
    (3, 'Junior', 40000),
    (4, 'Senior', 16000),
    (5, 'Senior', 20000),
    (6, 'Senior', 50000);


output : +--------+------------+--------+
| emp_id | experience | salary |
+--------+------------+--------+
|      5 | Senior     |  20000 |
|      4 | Senior     |  16000 |
|      2 | Junior     |  15000 |
|      1 | Junior     |  10000 |
+--------+------------+--------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 52 - Loan Repayment

You're working for a large financial institution that provides various types of loans to customers. Your task is to analyze loan repayment data to assess credit risk and improve risk management strategies.

Write an SQL to create 2 flags for each loan as per below rules. Display loan id, loan amount , due date and the 2 flags.

 

1- fully_paid_flag: 1 if the loan was fully repaid irrespective of payment date else it should be 0.
2- on_time_flag : 1 if the loan was fully repaid on or before due date else 


table : -- Create the table
CREATE TABLE loans (
    loan_id INT,
    customer_id INT,
    loan_amount DECIMAL(10, 2),
    due_date DATE
);

-- Insert the data
INSERT INTO loans (loan_id, customer_id, loan_amount, due_date)
VALUES
    (1, 1, 5000, '2023-01-15'),
    (2, 2, 8000, '2023-02-20'),
    (3, 3, 10000, '2023-03-10'),
    (4, 4, 6000, '2023-04-05'),
    (5, 5, 7000, '2023-05-01');


-- Create the table
CREATE TABLE payments (
    payment_id INT,
    loan_id INT,
    payment_date DATE,
    amount_paid DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO payments (payment_id, loan_id, payment_date, amount_paid)
VALUES
    (1, 1, '2023-01-10', 2000),
    (2, 1, '2023-02-10', 1500),
    (3, 2, '2023-02-20', 8000),
    (4, 3, '2023-04-20', 5000),
    (5, 4, '2023-03-15', 2000),
    (6, 4, '2023-04-02', 4000),
    (7, 5, '2023-04-02', 4000),
    (8, 5, '2023-05-02', 3000);



output : 

+---------+-------------+------------+-----------------+--------------+
| loan_id | loan_amount | due_date   | fully_paid_flag | on_time_flag |
+---------+-------------+------------+-----------------+--------------+
|       1 |        5000 | 2023-01-15 |               0 |            0 |
|       2 |        8000 | 2023-02-20 |               1 |            1 |
|       3 |       10000 | 2023-03-10 |               0 |            0 |
|       4 |        6000 | 2023-04-05 |               1 |            1 |
|       5 |        7000 | 2023-05-01 |               1 |            0 |
+---------+-------------+------------+-----------------+----------


---------------------------------------------------------------------------------------------------------------------------------------------

Q 53 - LinkedIn Recommendation

LinkedIn stores information of post likes in below format. Every time a user likes a post there will be an entry made in post likes table.

LinkedIn also stores the information when someone follows another user in below format.


The marketing team wants to send one recommendation post to each user . Write an SQL to find out that one post id for each user that is liked by the most number of users that they follow. Display user id, post id and no of likes.


Please note that team do not want to recommend a post which is already liked by the user. If for any user,  2 or more posts are liked by equal number of users that they follow then select the smallest post id, display the output in ascending order of user id.


table : -- Create the table
CREATE TABLE post_likes (
    user_id INT,
    post_id INT
);

-- Insert the data
INSERT INTO post_likes (user_id, post_id)
VALUES
    (1, 100),
    (2, 100),
    (3, 200),
    (4, 300),
    (5, 300),
    (1, 300),
    (2, 300),
    (3, 400),
    (4, 400),
    (5, 400),
    (1, 400);




-- Create the table
CREATE TABLE user_follows (
    user_id INT,
    follows_user_id INT
);

-- Insert the data
INSERT INTO user_follows (user_id, follows_user_id)
VALUES
    (1, 2),
    (1, 3),
    (1, 4),
    (2, 1),
    (2, 3),
    (2, 4),
    (3, 1),
    (3, 2),
    (4, 1),
    (4, 2);



output : 

+---------+---------+-------------+
| user_id | post_id | no_of_likes |
+---------+---------+-------------+
|       1 |     200 |           1 |
|       2 |     400 |           3 |
|       3 |     100 |           2 |
|       4 |     100 |           2 |
+---------+---------+-------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 54 - Employees Payout

An IT company pays its employees on hourly basis. You are given the database of employees along with their department id.

Department table which consist of hourly rate for each department.


Given the daily entry_time and exit_time of each employee, calculate the total amount payable to each employee.

Please note that company also pays overtime to employees who work for more than 8 hours a day which is 1.5 times of hourly rate. So for example if hourly rate is 10 and a employee works for 9 hours then total payable will be 10*8+15*1 = 95 for that day. In this example 95 is total payout and 15 is overtime payout.  Round the result to 2 decimal places and sort the output by decreasing order of total payout.


table : -- Create the table
CREATE TABLE employees (
    emp_id INT,
    emp_name VARCHAR(100),
    dept_id INT
);

-- Insert the data
INSERT INTO employees (emp_id, emp_name, dept_id)
VALUES
    (1, 'John', 1),
    (2, 'Jane', 2),
    (3, 'Alice', 1),
    (4, 'Bob', 3),
    (5, 'Emily', 2);



-- Create the table
CREATE TABLE dept (
    dept_id INT,
    hourly_rate DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO dept (dept_id, hourly_rate)
VALUES
    (1, 10.00),
    (2, 12.00),
    (3, 15.00);



-- Create the table
CREATE TABLE daily_time (
    emp_id INT,
    entry_time DATETIME,
    exit_time DATETIME
);

-- Insert the data
INSERT INTO daily_time (emp_id, entry_time, exit_time)
VALUES
    (1, '2023-01-01 09:00:00', '2023-01-01 17:00:00'),
    (2, '2023-01-01 08:00:00', '2023-01-01 15:00:00'),
    (3, '2023-01-01 08:30:00', '2023-01-01 18:30:00'),
    (4, '2023-01-01 09:00:00', '2023-01-01 16:00:00'),
    (5, '2023-01-01 08:00:00', '2023-01-01 18:00:00'),
    (1, '2023-01-02 10:00:00', '2023-01-02 18:00:00'),
    (2, '2023-01-02 08:00:00', '2023-01-02 19:00:00'),
    (3, '2023-01-02 08:00:00', '2023-01-02 17:30:00'),
    (4, '2023-01-02 10:00:00', '2023-01-02 17:00:00'),
    (5, '2023-01-02 09:00:00', '2023-01-02 15:00:00');


output : 

+----------+--------------+-----------------+
| emp_name | total_payout | overtime_payout |
+----------+--------------+-----------------+
| Jane     |       234.00 |           54.00 |
| Alice    |       212.50 |           52.50 |
| Bob      |       210.00 |            0.00 |
| Emily    |       204.00 |           36.00 |
| John     |       160.00 |            0.00 |
+----------+--------------+-----------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 55 - Lowest Price


You own a small online store, and want to analyze customer ratings for the products that you're selling. After doing a data pull, you have a list of products and a log of purchases. Within the purchase log, each record includes the number of stars (from 1 to 5) as a customer rating for the product.

For each category, find the lowest price among all products that received at least one 4-star or above rating from customers.
If a product category did not have any products that received at least one 4-star or above rating, the lowest price is considered to be 0. The final output should be sorted by product category in alphabetical order.

table : -- Create the table
CREATE TABLE products (
    id INT PRIMARY KEY,
    name VARCHAR(100),
    category VARCHAR(50),
    price DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO products (id, name, category, price)
VALUES
    (1, 'Cripps Pink', 'apple', 10.00),
    (2, 'Navel Orange', 'orange', 12.00),
    (3, 'Golden Delicious', 'apple', 6.00),
    (4, 'Clementine', 'orange', 14.00),
    (5, 'Pinot Noir', 'grape', 20.00),
    (6, 'Bing Cherries', 'cherry', 36.00),
    (7, 'Sweet Cherries', 'cherry', 40.00);




-- Create the table
CREATE TABLE purchases (
    id INT PRIMARY KEY,
    product_id INT,
    stars INT
);

-- Insert the data
INSERT INTO purchases (id, product_id, stars)
VALUES
    (1, 1, 2),
    (2, 3, 3),
    (3, 2, 2),
    (4, 4, 4),
    (5, 6, 5),
    (6, 6, 4),
    (7, 7, 5);


output : 

+----------+-------+
| category | price |
+----------+-------+
| apple    |     0 |
| cherry   |    36 |
| grape    |     0 |
| orange   |    14 |
+----------+-------+



---------------------------------------------------------------------------------------------------------------------------------------------

Q 56 – Expenses Excluding MasterCard

You're working for a financial analytics company that specializes in analyzing credit card expenditures. You have a dataset containing information about users' credit card expenditures across different card companies.
Write an SQL query to find the total expenditure from other cards (excluding Mastercard) for users who hold Mastercard.  Display only the users(along with Mastercard expense and other expense) for which expense from other cards together is more than Mastercard expense.


table : 
-- Create the table
CREATE TABLE expenditures (
    user_name VARCHAR(100),
    card_company VARCHAR(50),
    expenditure DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO expenditures (user_name, card_company, expenditure)
VALUES
    ('user1', 'Mastercard', 1000.00),
    ('user1', 'Visa', 500.00),
    ('user1', 'RuPay', 2000.00),
    ('user2', 'Visa', 2000.00),
    ('user3', 'Mastercard', 5000.00),
    ('user3', 'Visa', 2000.00),
    ('user3', 'Slice', 500.00),
    ('user3', 'Amex', 1000.00),
    ('user4', 'Mastercard', 2000.00);


output : 
+-----------+--------------------+---------------+
| user_name | mastercard_expense | other_expense |
+-----------+--------------------+---------------+
| user1     |               1000 |          2500 |
+-----------+--------------------+---------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 57 - Dashboard Visits

You're working as a data analyst for a popular website's dashboard analytics team. Your task is to analyze user visits to the dashboard and identify users who are highly engaged with the platform. The dashboard records user visits along with timestamps to provide insights into user activity patterns.
A user can visit the dashboard multiple times within a day. However, to be counted as separate visits, there should be a minimum gap of 60 minutes between consecutive visits. If the next visit occurs within 60 minutes of the previous one, it's considered part of the same visit.

Write an SQL query to find total number of visits by each user along with number of distinct days user has visited the dashboard. While calculating the number of distinct days you have to consider a visit even if it is same as previous days visit.
So for example if there is a visit at 2024-01-12 23:30:00 and next visit at 2024-01-13 00:15:00 , The visit on 13th will not be considered as new visit because it is within 1 hour window of previous visit but number of days will be counted as 2 only, display the output in ascending order of user id.


table : -- Create the table
CREATE TABLE dashboard_visit (
    user_id VARCHAR(100),
    visit_time DATETIME
);

-- Insert the data
INSERT INTO dashboard_visit (user_id, visit_time)
VALUES
    ('Alice', '2021-12-04 10:44:56'),
    ('Alice', '2021-12-04 10:55:56'),
    ('Alice', '2021-12-04 12:56:56'),
    ('Bob', '2021-12-05 12:55:50'),
    ('Bob', '2021-12-06 14:55:50'),
    ('Charlie', '2021-11-06 17:53:50'),
    ('Charlie', '2021-11-06 17:56:50'),
    ('David', '2021-11-29 13:53:50'),
    ('David', '2021-12-01 10:53:50'),
    ('David', '2021-12-06 23:53:50'),
    ('David', '2021-12-07 00:20:50');


output : 
+---------+--------------+------------+
| user_id | no_of_visits | visit_days |
+---------+--------------+------------+
| Alice   |            2 |          1 |
| Bob     |            2 |          2 |
| Charlie |            1 |          1 |
| David   |            3 |          4 |
+---------+--------------+------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 58 - Final Account Balance

You are given history of your bank account for the year 2020. Each transaction is either a credit card payment or incoming transfer. There is a fee of holding a credit card which you have to pay every month, Fee is 5 per month. However, you are not charged for a given month if you made at least 2 credit card payments for a total cost of at least 100 within that month. Note that this fee is not included in the supplied history of transactions.
Each row in the table contains information about a single transaction. If the amount value is negative, it is a credit card payment otherwise it is an incoming transfer. At the beginning of the year, the balance of your account was 0 . Your task is to compute the balance at the end of the year. 

table : -- Create the table
CREATE TABLE transactions (
    transaction_date DATE,
    amount DECIMAL(10, 2)
);

-- Insert the data
INSERT INTO transactions (transaction_date, amount)
VALUES
    ('2020-01-01', -30.00),
    ('2020-01-05', -80.00),
    ('2020-01-24', 30.00),
    ('2020-03-01', -40.00),
    ('2020-03-01', 30.00),
    ('2020-04-10', 70.00),
    ('2020-04-13', 40.00),
    ('2020-07-05', -30.00),
    ('2020-10-19', 60.00),
    ('2020-12-01', -40.00),
    ('2020-12-05', -30.00),
    ('2020-12-19', -20.00);


output :

 +---------------+
| final_balance |
+---------------+
|           -95 |
+---------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 59 - Order Lead Time

You are given orders data of an online ecommerce company. Dataset contains order_id , order_date and ship_date. Your task is to find lead time in days between order date and ship date using below rules:

 

1- Exclude holidays. List of holidays present in holiday table. 
2- If the order date is on weekends, then consider it as order placed on immediate next Monday 
and if the ship date is on weekends, then consider it as immediate previous Friday to do calculations.
For example, if order date is March 14th 2024 and ship date is March 20th 2024. Consider March 18th is a holiday then lead time will be (20-14) -1 holiday = 5 days.

table : -- Create the table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    order_date DATE,
    ship_date DATE
);

-- Insert the data
INSERT INTO orders (order_id, order_date, ship_date)
VALUES
    (1, '2024-03-14', '2024-03-20'),
    (2, '2024-03-10', '2024-03-16'),
    (3, '2024-03-04', '2024-03-12'),
    (4, '2024-03-05', '2024-03-07'),
    (5, '2024-03-03', '2024-03-08'),
    (6, '2024-03-07', '2024-03-24');




-- Create the table
CREATE TABLE holidays (
    holiday_id INT PRIMARY KEY,
    holiday_date DATE
);

-- Insert the data
INSERT INTO holidays (holiday_id, holiday_date)
VALUES
    (1, '2024-03-10'),
    (2, '2024-03-18'),
    (3, '2024-03-21');


output : 
+----------+-----------+
| order_id | lead_time |
+----------+-----------+
|        1 |         5 |
|        2 |         4 |
|        3 |         7 |
|        4 |         2 |
|        5 |         4 |
|        6 |        12 |
+----------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 60 - Instagram Marketing Agency


You are working for a marketing agency that manages multiple Instagram influencer accounts. Your task is to analyze the engagement performance of these influencers before and after they join your company.
Write an SQL query to calculate average engagement growth rate percent for each influencer after they joined your company compare to before. Round the growth rate to 2 decimal places and sort the output in decreasing order of growth rate.

Engagement = (# of likes + # of comments on each post)


table : -- Create the table
CREATE TABLE influencers (
    influencer_id INT PRIMARY KEY,
    username VARCHAR(100),
    join_date DATE
);

-- Insert the data
INSERT INTO influencers (influencer_id, username, join_date)
VALUES
    (1, 'Ankit', '2023-02-01'),
    (2, 'Rahul', '2023-03-05'),
    (3, 'Suresh', '2023-05-20');




-- Create the table
CREATE TABLE posts (
    post_id INT,
    influencer_id INT,
    post_date DATE,
    likes INT,
    comments INT
);

-- Insert the data
INSERT INTO posts (post_id, influencer_id, post_date, likes, comments)
VALUES
    (1, 1, '2023-01-05', 100, 20),
    (2, 1, '2023-01-10', 150, 30),
    (3, 1, '2023-02-05', 200, 45),
    (4, 1, '2023-02-10', 120, 25),
    (1, 2, '2023-02-15', 150, 30),
    (2, 2, '2023-02-20', 200, 25),
    (3, 2, '2023-03-10', 250, 15),
    (4, 2, '2023-03-15', 200, 35);



output : 
+----------+-------------------+------------------+--------+
| username | before_engagement | after_engagement | growth |
+----------+-------------------+------------------+--------+
| Ankit    |          150.0000 |         195.0000 |  30.00 |
| Rahul    |          202.5000 |         250.0000 |  23.46 |
+----------+-------------------+------------------+--------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 61 - Category Sales (Part 1)

Write an SQL query to retrieve the total sales amount for each product category in the month of February 2022, only including sales made on weekdays (Monday to Friday). Display the output in ascending order of total sales.

table : -- Create the 'sales' table
CREATE TABLE sales (
    id INT PRIMARY KEY,               -- Unique identifier for each sale
    product_id INT,                   -- Product identifier
    category VARCHAR(50),             -- Product category (e.g., Electronics, Clothing, Books)
    amount DECIMAL(10, 2),            -- Sale amount
    order_date DATE                   -- Date of the order
);

-- Insert data into the 'sales' table
INSERT INTO sales (id, product_id, category, amount, order_date) VALUES
(1, 101, 'Electronics', 1500, '2022-02-05'),
(2, 102, 'Electronics', 2000, '2022-02-10'),
(3, 103, 'Clothing', 500, '2022-02-15'),
(4, 104, 'Clothing', 800, '2022-02-20'),
(5, 105, 'Books', 300, '2022-02-25'),
(6, 106, 'Electronics', 1800, '2022-03-08'),
(7, 107, 'Clothing', 600, '2022-03-15'),
(8, 108, 'Books', 400, '2022-03-20'),
(9, 109, 'Electronics', 2200, '2022-04-05'),
(10, 110, 'Clothing', 700, '2022-04-10'),
(11, 111, 'Books', 500, '2022-04-15'),
(12, 112, 'Electronics', 2500, '2022-05-05'),
(13, 113, 'Clothing', 900, '2022-05-10'),
(14, 114, 'Books', 600, '2022-05-15'),
(15, 105, 'Books', 100, '2022-02-25');


output : 

+-------------+-------------+
| category    | total_sales |
+-------------+-------------+
| Books       |         400 |
| Clothing    |         500 |
| Electronics |        2000 |
+-------------+-------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 62 - Category Sales (Part 2)	

Write an SQL query to retrieve the total sales amount in each category. Include all categories, if no products were sold in a category display as 0. Display the output in ascending order of total_sales.

table : -- Create the 'categories' table
CREATE TABLE categories (
    category_id INT PRIMARY KEY,        -- Unique identifier for each category
    category_name VARCHAR(50)           -- Name of the category (e.g., Electronics, Clothing)
);

-- Insert data into the 'categories' table
INSERT INTO categories (category_id, category_name) VALUES
(1, 'Electronics'),
(2, 'Clothing'),
(3, 'Books'),
(4, 'Home Decor');



-- Create the 'sales' table
CREATE TABLE sales (
    sale_id INT PRIMARY KEY,            -- Unique identifier for each sale
    category_id INT,                    -- Foreign key referencing the 'categories' table
    amount DECIMAL(10, 2),              -- Sale amount
    sale_date DATE,                     -- Date of the sale
    CONSTRAINT fk_category_id FOREIGN KEY (category_id) REFERENCES categories(category_id)  -- Foreign key constraint
);

-- Insert data into the 'sales' table
INSERT INTO sales (sale_id, category_id, amount, sale_date) VALUES
(1, 1, 500, '2022-01-05'),
(2, 1, 800, '2022-02-10'),
(4, 3, 200, '2022-02-20'),
(5, 3, 150, '2022-03-01'),
(6, 4, 400, '2022-02-25'),
(7, 4, 600, '2022-03-05');


output : 

+---------------+-------------+
| category_name | total_sales |
+---------------+-------------+
| Clothing      |           0 |
| Books         |         350 |
| Home Decor    |        1000 |
| Electronics   |        1300 |
+---------------+-------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 63 - Prime Subscription

Amazon, the world's largest online retailer, offers various services to its customers, including Amazon Prime membership, Video streaming, Amazon Music, Amazon Pay, and more. The company is interested in analyzing which of its services are most effective at converting regular customers into Amazon Prime members.
You are given a table of events which consists services accessed by each users along with service access date. This table also contains the event when customer bought the prime membership (type='prime').

 

Write an SQL to get date when each customer became prime member, last service used and last service access date (just before becoming prime member). If a customer never became prime member, then populate only the last service used and last service access date by the customer, display the output in ascending order of last service access date.


table : -- Create the 'users' table
CREATE TABLE users (
    user_id INT PRIMARY KEY,           -- Unique identifier for each user
    name VARCHAR(50)                   -- Name of the user
);

-- Insert data into the 'users' table
INSERT INTO users (user_id, name) VALUES
(1, 'Saurabh'),
(2, 'Amit'),
(3, 'Ankit');



-- Create the 'events' table
CREATE TABLE events (
    user_id INT,                        -- Foreign key referencing the 'users' table
    type VARCHAR(50),                   -- Event type (e.g., Amazon Music, Amazon Video, Prime)
    access_date DATE,                   -- Date when the event was accessed
    CONSTRAINT fk_user_id FOREIGN KEY (user_id) REFERENCES users(user_id)  -- Foreign key constraint
);

-- Insert data into the 'events' table
INSERT INTO events (user_id, type, access_date) VALUES
(1, 'Amazon Music', '2024-01-05'),
(1, 'Amazon Video', '2024-01-07'),
(1, 'Prime', '2024-01-08'),
(1, 'Amazon Video', '2024-01-09'),
(2, 'Amazon Pay', '2024-01-08'),
(2, 'Prime', '2024-01-09'),
(3, 'Amazon Pay', '2024-01-07'),
(3, 'Amazon Music', '2024-01-09');


output : 
+-----------+-------------------+---------------------+--------------------------+
| user_name | prime_member_date | last_access_service | last_access_service_date |
+-----------+-------------------+---------------------+--------------------------+
| Saurabh   | 2024-01-08        | Amazon Video        | 2024-01-07               |
| Amit      | 2024-01-09        | Amazon Pay          | 2024-01-08               |
| Ankit     | NULL              | Amazon Music        | 2024-01-09               |
+-----------+-------------------+---------------------+--------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 64 - Penultimate Order

You are a data analyst working for an e-commerce company, responsible for analysing customer orders to gain insights into their purchasing behaviour. Your task is to write a SQL query to retrieve the details of the penultimate order for each customer. However, if a customer has placed only one order, you need to retrieve the details of that order instead, display the output in ascending order of customer name.


table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,         -- Unique identifier for each order
    order_date DATE,                  -- Date when the order was placed
    customer_name VARCHAR(50),        -- Name of the customer
    product_name VARCHAR(50),         -- Name of the product ordered
    sales DECIMAL(10, 2)              -- Sales amount for the order
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, order_date, customer_name, product_name, sales) VALUES
(1, '2023-01-01', 'Alexa', 'iphone', 100),
(2, '2023-01-02', 'Alexa', 'boAt', 300),
(3, '2023-01-03', 'Alexa', 'Rolex', 400),
(4, '2023-01-01', 'Ramesh', 'Titan', 200),
(5, '2023-01-02', 'Ramesh', 'Shirt', 300),
(6, '2023-01-03', 'Neha', 'Dress', 100);
 

output : 

+----------+------------+---------------+--------------+-------+
| order_id | order_date | customer_name | product_name | sales |
+----------+------------+---------------+--------------+-------+
|        2 | 2023-01-02 | Alexa         | boAt         |   300 |
|        6 | 2023-01-03 | Neha          | Dress        |   100 |
|        4 | 2023-01-01 | Ramesh        | Titan        |   200 |
+----------+------------+---------------+--------------+-------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 65 - Service Downtime

You are a DevOps engineer responsible for monitoring the health and status of various services in your organization's infrastructure. Your team conducts canary tests on each service every minute to ensure their reliability and performance. As part of your responsibilities, you need to develop a SQL to identify any service that experiences continuous downtime for at least 5 minutes so that team can find the root cause and fix the issue. Display the output in descending order of service down minutes.

table : -- Create the 'service_status' table
CREATE TABLE service_status (
    service_name VARCHAR(50),         -- Name of the service (e.g., hdfs, hive)
    updated_time DATETIME,            -- Timestamp when the status was updated
    status VARCHAR(10)                -- Service status (e.g., up, down)
);

-- Insert data into the 'service_status' table
INSERT INTO service_status (service_name, updated_time, status) VALUES
('hdfs', '2024-03-06 10:01:00', 'up'),
('hdfs', '2024-03-06 10:02:00', 'down'),
('hdfs', '2024-03-06 10:03:00', 'down'),
('hdfs', '2024-03-06 10:04:00', 'down'),
('hdfs', '2024-03-06 10:05:00', 'down'),
('hdfs', '2024-03-06 10:06:00', 'down'),
('hdfs', '2024-03-06 10:07:00', 'down'),
('hdfs', '2024-03-06 10:08:00', 'up'),
('hdfs', '2024-03-06 10:09:00', 'down'),
('hive', '2024-03-06 10:01:00', 'down'),
('hive', '2024-03-06 10:02:00', 'up'),
('hive', '2024-03-06 10:03:00', 'down'),
('hive', '2024-03-06 10:04:00', 'down'),
('hive', '2024-03-06 10:05:00', 'down'),
('hive', '2024-03-06 10:06:00', 'down'),
('hive', '2024-03-06 10:07:00', 'down'),
('hive', '2024-03-06 10:08:00', 'up'),
('hive', '2024-03-06 10:09:00', 'down');


output : 
+--------------+---------------------+---------------------+--------------+
| service_name | down_start_time     | down_end_time       | down_minutes |
+--------------+---------------------+---------------------+--------------+
| hdfs         | 2024-03-06 10:02:00 | 2024-03-06 10:07:00 |            6 |
| hive         | 2024-03-06 10:03:00 | 2024-03-06 10:07:00 |            5 |
+--------------+---------------------+---------------------+--------------+

---------------------------------------------------------------------------------------------------------------------------------------------


Q 66 - Fake Ratings

As an analyst at Amazon, you are responsible for ensuring the integrity of product ratings on the platform. Fake ratings can distort the perception of product quality and mislead customers. To maintain trust and reliability, you need to identify potential fake ratings that deviate significantly from the average ratings for each product.
Write an SQL query to identify the single rating that is farthest (in absolute value) from the average rating value for each product, display rating details in ascending order of rating id.

table : -- Create the 'product_ratings' table
CREATE TABLE product_ratings (
    rating_id INT PRIMARY KEY,         -- Unique identifier for each rating
    product_id INT,                    -- ID of the product being rated
    user_id INT,                       -- ID of the user who rated the product
    rating DECIMAL(2, 1)               -- Rating given to the product (scale: 1.0 to 5.0)
);

-- Insert data into the 'product_ratings' table
INSERT INTO product_ratings (rating_id, product_id, user_id, rating) VALUES
(1, 101, 1001, 4.5),
(2, 101, 1002, 4.8),
(3, 101, 1003, 4.9),
(4, 101, 1004, 5.0),
(5, 101, 1005, 3.2),
(6, 102, 1006, 4.7),
(7, 102, 1007, 4.0),
(8, 102, 1008, 4.1),
(9, 102, 1009, 3.8),
(10, 102, 1010, 3.9);


output : 
+-----------+------------+---------+--------+
| rating_id | product_id | user_id | rating |
+-----------+------------+---------+--------+
|         5 |        101 |    1005 |    3.2 |
|         6 |        102 |    1006 |    4.7 |
+-----------+------------+---------+--------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 67 - Food Preparation Time

You're analyzing the efficiency of food delivery on Zomato, focusing on the time taken by restaurants to prepare orders. Total food delivery time for an order is a combination of food preparation time + time taken by rider to deliver the order. 
Write an SQL to calculate average food preparation time(in minutes) for each restaurant . Round the average to 2 decimal points and sort the output in increasing order of average time.


table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,                     -- Unique identifier for each order
    restaurant_id INT,                            -- ID of the restaurant
    order_time TIME,                              -- Time when the order was placed
    expected_delivery_time TIME,                  -- Expected delivery time
    actual_delivery_time TIME,                    -- Actual delivery time
    rider_delivery_mins INT                       -- Time taken by the rider in minutes
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, restaurant_id, order_time, expected_delivery_time, actual_delivery_time, rider_delivery_mins) VALUES
(1, 101, '12:00:00', '12:30:00', '12:45:00', 15),
(2, 102, '12:15:00', '12:45:00', '12:55:00', 10),
(3, 103, '12:30:00', '13:00:00', '13:10:00', 15),
(4, 101, '12:45:00', '13:15:00', '13:21:00', 5),
(5, 102, '13:00:00', '13:30:00', '13:36:00', 10),
(6, 103, '13:15:00', '13:45:00', '13:58:00', 10),
(7, 101, '13:30:00', '14:00:00', '14:12:00', 20),
(8, 102, '13:45:00', '14:15:00', '14:25:00', 10),
(9, 103, '14:00:00', '14:30:00', '14:30:00', 5),
(10, 101, '14:15:00', '14:45:00', '15:05:00', 15);


output : 
+---------------+--------------------+
| restaurant_id | avg_food_prep_mins |
+---------------+--------------------+
|           103 |              27.67 |
|           102 |              28.67 |
|           101 |              29.50 |
+---------------+--------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 68 - Late Food Deliveries

You're analyzing the efficiency of food delivery on Zomato, focusing on the late deliveries. Total food delivery time for an order is a combination of food preparation time + time taken by rider to deliver the order. 
Suppose that as per order time and expected time of delivery there is equal time allocated to restaurant for food preparation and rider to deliver the order. Write an SQL to find orders which got delayed only because of more than expected time taken by the rider, display order_id, expected_delivery_mins, rider_delivery_mins, food_prep_mins in ascending order of order_id.

table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,                     -- Unique identifier for each order
    restaurant_id INT,                            -- ID of the restaurant
    order_time TIME,                              -- Time when the order was placed
    expected_delivery_time TIME,                  -- Expected delivery time
    actual_delivery_time TIME,                    -- Actual delivery time
    rider_delivery_mins INT                       -- Time taken by the rider in minutes
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, restaurant_id, order_time, expected_delivery_time, actual_delivery_time, rider_delivery_mins) VALUES
(1, 101, '12:00:00', '12:30:00', '12:25:00', 18),
(2, 102, '12:15:00', '12:40:00', '12:55:00', 30),
(3, 103, '12:30:00', '13:05:00', '13:10:00', 15),
(4, 101, '12:45:00', '13:12:00', '13:21:00', 5),
(5, 102, '13:00:00', '13:30:00', '13:36:00', 10),
(6, 103, '13:15:00', '13:45:00', '13:58:00', 29),
(7, 101, '13:30:00', '14:00:00', '14:12:00', 20),
(8, 102, '13:45:00', '14:20:00', '14:25:00', 10),
(9, 103, '14:00:00', '14:32:00', '14:32:00', 5),
(10, 101, '14:15:00', '14:50:00', '15:05:00', 18);


output : 

+----------+------------------------+---------------------+----------------+
| order_id | expected_delivery_mins | rider_delivery_mins | food_prep_mins |
+----------+------------------------+---------------------+----------------+
|        2 |                     25 |                  30 |             10 |
|        6 |                     30 |                  29 |             14 |
+----------+------------------------+---------------------+----------------+

---------------------------------------------------------------------------------------------------------------------------------------------
Q 69 - Country Indicators

In the realm of global indicators and country-level assessments, it's imperative to identify the years in which certain indicators hit their lowest values for each country. Leveraging a dataset provided by government, which contains indicators across multiple years for various countries, your task is to formulate an SQL query to find the following information:
For each country and indicator combination, determine the year in which the indicator value was lowest, along with the corresponding indicator value. Sort the output by country name and indicator name.

table : -- Create the 'country_data' table
CREATE TABLE country_data (
    country_name VARCHAR(100),               -- Name of the country
    indicator_name VARCHAR(100),             -- Name of the indicator (e.g., Control of Corruption)
    year_2010 DECIMAL(3, 2),                 -- Data for the year 2010
    year_2011 DECIMAL(3, 2),                 -- Data for the year 2011
    year_2012 DECIMAL(3, 2),                 -- Data for the year 2012
    year_2013 DECIMAL(3, 2),                 -- Data for the year 2013
    year_2014 DECIMAL(3, 2)                  -- Data for the year 2014
);

-- Insert data into the 'country_data' table
INSERT INTO country_data (country_name, indicator_name, year_2010, year_2011, year_2012, year_2013, year_2014) VALUES
('United States', 'Control of Corruption', 1.26, 1.51, 1.52, 1.50, 1.46),
('United States', 'Government Effectiveness', 1.27, 1.45, 1.28, 1.25, 1.27),
('United States', 'Regulatory Quality', 1.28, 1.63, 1.63, 1.54, 1.62),
('United States', 'Rule of Law', 1.32, 1.61, 1.60, 1.54, 1.62),
('United States', 'Voice and Accountability', 1.30, 1.11, 1.13, 1.08, 1.05),
('Canada', 'Control of Corruption', 1.46, 1.61, 1.71, 1.50, 1.56),
('Canada', 'Government Effectiveness', 1.47, 1.55, 1.38, 1.35, 1.47),
('Canada', 'Regulatory Quality', 1.38, 1.73, 1.63, 1.59, 1.68),
('Canada', 'Rule of Law', 1.42, 1.71, 1.80, 1.64, 1.72),
('Canada', 'Voice and Accountability', 1.40, 1.19, 1.21, 1.16, 1.09);

output : 

+---------------+--------------------------+-----------------+-------------+
| country_name  | indicator_name           | indicator_value | year_number |
+---------------+--------------------------+-----------------+-------------+
| Canada        | Control of Corruption    |            1.46 |        2010 |
| Canada        | Government Effectiveness |            1.35 |        2013 |
| Canada        | Regulatory Quality       |            1.38 |        2010 |
| Canada        | Rule of Law              |            1.42 |        2010 |
| Canada        | Voice and Accountability |            1.09 |        2014 |
| United States | Control of Corruption    |            1.26 |        2010 |
| United States | Government Effectiveness |            1.25 |        2013 |
| United States | Regulatory Quality       |            1.28 |        2010 |
| United States | Rule of Law              |            1.32 |        2010 |
| United States | Voice and Accountability |            1.05 |        2014 |
+---------------+--------------------------+-----------------+-------------+

---------------------------------------------------------------------------------------------------------------------------------------------
Q 70 - Employee Name

The HR department needs to extract the first name, middle name and last name of each employee from the full name column. However, the full name column contains names in the format "Lastname,Firstname Middlename". 
Please consider that an employee name can be in one of the 3 following formats.
1- "Lastname,Firstname Middlename"
2- "Lastname,Firstname"
3- "Firstname"

table : -- Create the 'employee' table
CREATE TABLE employee (
    employeeid INT PRIMARY KEY,          -- Unique identifier for each employee
    fullname VARCHAR(100)                -- Full name of the employee
);

-- Insert data into the 'employee' table
INSERT INTO employee (employeeid, fullname) VALUES
(1, 'Doe,John Michael'),
(2, 'Smith,Alice'),
(3, 'Johnson,Robert Lee'),
(4, 'Alex'),
(5, 'White,Sarah');
	
output : 

+--------------------+------------+-------------+-----------+
| fullname           | first_name | middle_name | last_name |
+--------------------+------------+-------------+-----------+
| Doe,John Michael   | John       | Michael     | Doe       |
| Smith,Alice        | Alice      | NULL        | Smith     |
| Johnson,Robert Lee | Robert     | Lee         | Johnson   |
| Alex               | Alex       | NULL        | NULL      |
| White,Sarah        | Sarah      | NULL        | White     |
+--------------------+------------+-------------+-----------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 71 - Department Average Salary

You are provided with two tables: Employees and Departments. The Employees table contains information about employees, including their IDs, names, salaries, and department IDs. The Departments table contains information about departments, including their IDs and names. Your task is to write a SQL query to find the average salary of employees in each department, but only include departments that have more than 2 employees . Display department name and average salary round to 2 decimal places. Sort the result by average salary in descending order.

table : -- Create the 'employees' table
CREATE TABLE employees (
    employee_id INT PRIMARY KEY,          -- Unique identifier for each employee
    employee_name VARCHAR(100),           -- Name of the employee
    salary DECIMAL(10, 2),                -- Salary of the employee
    department_id INT                     -- ID of the department the employee belongs to
);

-- Insert data into the 'employees' table
INSERT INTO employees (employee_id, employee_name, salary, department_id) VALUES
(1, 'John Doe', 50000, 1),
(2, 'Jane Smith', 60000, 1),
(3, 'Alice Johnson', 70000, 2),
(4, 'Bob Brown', 55000, 2),
(5, 'Emily Clark', 48000, 1),
(6, 'Michael Lee', 62000, 3),
(7, 'Sarah Taylor', 53000, 3),
(8, 'David Martinez', 58000, 1),
(9, 'Laura White', 65000, 1),
(10, 'Chris Wilson', 56000, 3);



-- Create the 'departments' table
CREATE TABLE departments (
    department_id INT PRIMARY KEY,        -- Unique identifier for each department
    department_name VARCHAR(100)          -- Name of the department
);

-- Insert data into the 'departments' table
INSERT INTO departments (department_id, department_name) VALUES
(1, 'Sales'),
(2, 'Marketing'),
(3, 'Finance');


output : 

+-----------------+----------------+
| department_name | average_salary |
+-----------------+----------------+
| Finance         |       57000.00 |
| Sales           |       56200.00 |
+-----------------+----------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 72 - Product Sales

You are provided with two tables: Products and Sales. The Products table contains information about various products, including their IDs, names, and prices. The Sales table contains data about sales transactions, including the product IDs, quantities sold, and dates of sale. Your task is to write a SQL query to find the total sales amount for each product. Display product name and total sales . Sort the result by product name.

table : -- Create the 'products' table
CREATE TABLE products (
    product_id INT PRIMARY KEY,        -- Unique identifier for each product
    product_name VARCHAR(100),         -- Name of the product
    price DECIMAL(10, 2)               -- Price of the product
);

-- Insert data into the 'products' table
INSERT INTO products (product_id, product_name, price) VALUES
(1, 'Laptop', 800),
(2, 'Smartphone', 600),
(3, 'Headphones', 50),
(4, 'Tablet', 400);


-- Create the 'sales' table
CREATE TABLE sales (
    sale_id INT PRIMARY KEY,           -- Unique identifier for each sale
    product_id INT,                    -- ID of the product sold
    quantity INT,                      -- Quantity of the product sold
    sale_date DATE                     -- Date of the sale
);




-- Insert data into the 'sales' table
INSERT INTO sales (sale_id, product_id, quantity, sale_date) VALUES
(1, 1, 3, '2023-05-15'),
(2, 2, 2, '2023-05-16'),
(3, 3, 5, '2023-05-17'),
(4, 1, 2, '2023-05-18'),
(5, 4, 1, '2023-05-19'),
(6, 2, 3, '2023-05-20'),
(7, 3, 4, '2023-05-21'),
(8, 1, 1, '2023-05-22'),
(9, 2, 4, '2023-05-23'),
(10, 4, 2, '2023-05-24'),
(11, 1, 5, '2023-05-25'),
(12, 2, 1, '2023-05-26'),
(13, 3, 3, '2023-05-27'),
(14, 1, 2, '2023-05-28'),
(15, 4, 3, '2023-05-29'),
(16, 2, 2, '2023-05-30'),
(17, 3, 5, '2023-05-31'),
(18, 1, 4, '2023-06-01'),
(19, 2, 3, '2023-06-02'),
(20, 4, 1, '2023-06-03');


output : 

+--------------+--------------------+
| product_name | total_sales_amount |
+--------------+--------------------+
| Headphones   |                850 |
| Laptop       |              13600 |
| Smartphone   |               9000 |
| Tablet       |               2800 |
+--------------+--------------------+	

---------------------------------------------------------------------------------------------------------------------------------------------

Q 73 - Category Product Count

You are provided with a table that lists various product categories, each containing a comma-separated list of products. Your task is to write a SQL query to count the number of products in each category. Sort the result by product count.

table : -- Create the 'categories' table
CREATE TABLE categories (
    category_id INT PRIMARY KEY AUTO_INCREMENT,  -- Unique identifier for each category
    category_name VARCHAR(100)                   -- Name of the category
);

-- Insert data into the 'categories' table
INSERT INTO categories (category_name) VALUES
('Electronics'),
('Furniture'),
('Clothing'),
('Groceries');

-- Create the 'products' table
CREATE TABLE products (
    product_id INT PRIMARY KEY AUTO_INCREMENT,    -- Unique identifier for each product
    product_name VARCHAR(100),                   -- Name of the product
    category_id INT,                            -- Foreign key to the 'categories' table
    FOREIGN KEY (category_id) REFERENCES categories(category_id)  -- Foreign key constraint
);

-- Insert data into the 'products' table
INSERT INTO products (product_name, category_id) VALUES
('TV', (SELECT category_id FROM categories WHERE category_name = 'Electronics')),
('Radio', (SELECT category_id FROM categories WHERE category_name = 'Electronics')),
('Laptop', (SELECT category_id FROM categories WHERE category_name = 'Electronics')),
('Chair', (SELECT category_id FROM categories WHERE category_name = 'Furniture')),
('Shirt', (SELECT category_id FROM categories WHERE category_name = 'Clothing')),
('Pants', (SELECT category_id FROM categories WHERE category_name = 'Clothing')),
('Jacket', (SELECT category_id FROM categories WHERE category_name = 'Clothing')),
('Shoes', (SELECT category_id FROM categories WHERE category_name = 'Clothing')),
('Rice', (SELECT category_id FROM categories WHERE category_name = 'Groceries')),
('Sugar', (SELECT category_id FROM categories WHERE category_name = 'Groceries'));


output : 

+-------------+---------------+
| category    | product_count |
+-------------+---------------+
| Furniture   |             1 |
| Groceries   |             2 |
| Electronics |             3 |
| Clothing    |             4 |
+-------------+---------------+
---------------------------------------------------------------------------------------------------------------------------------------------

Q 74 - Above Average Employees

You are working as a data analyst at a tech company called "TechGuru Inc." that specializes in software development and data science solutions. The HR department has tasked you with analyzing the salaries of employees. Your goal is to identify employees who earn above the average salary for their respective job title but are not among the top 3 earners within their job title. Consider the sum of base_pay, overtime_pay and other_pay as total salary. 


In case multiple employees have same total salary then ranked them based on higher base pay. Sort the output by total salary in descending order.

table : -- Create the 'employee' table
CREATE TABLE employee (
    emp_id INT PRIMARY KEY,          -- Unique identifier for each employee
    emp_name VARCHAR(100),           -- Name of the employee
    job_title VARCHAR(100)           -- Job title of the employee
);

-- Insert data into the 'employee' table
INSERT INTO employee (emp_id, emp_name, job_title) VALUES
(1, 'John Doe', 'Software Engineer'),
(2, 'Jane Smith', 'Software Engineer'),
(3, 'Michael Johnson', 'Software Engineer'),
(4, 'Emily Brown', 'Software Engineer'),
(5, 'David Lee', 'Software Engineer'),
(6, 'Sarah Jones', 'Software Engineer'),
(7, 'Kevin Davis', 'Software Engineer'),
(8, 'Emma Wilson', 'Software Engineer'),
(9, 'Matthew Taylor', 'Software Engineer'),
(10, 'Olivia Martinez', 'Software Engineer'),
(11, 'Liam Miller', 'Data Scientist'),
(12, 'Sophia Wilson', 'Data Scientist'),
(13, 'Benjamin Davis', 'Data Scientist'),
(14, 'Mia Taylor', 'Data Scientist'),
(15, 'William Anderson', 'Data Scientist'),
(16, 'Ella Martinez', 'Data Scientist'),
(17, 'James Garcia', 'Data Scientist'),
(18, 'Ava Lopez', 'Data Scientist'),
(19, 'Logan Perez', 'Data Scientist'),
(20, 'Harper Gonzalez', 'Data Scientist');




-- Create the 'salary' table
CREATE TABLE salary (
    emp_id INT PRIMARY KEY,          -- Employee ID (foreign key)
    base_pay DECIMAL(10, 2),         -- Base pay of the employee
    overtime_pay DECIMAL(10, 2),     -- Overtime pay of the employee
    other_pay DECIMAL(10, 2)         -- Other pay of the employee
);

-- Insert data into the 'salary' table
INSERT INTO salary (emp_id, base_pay, overtime_pay, other_pay) VALUES
(1, 60000, 2000, 1000),
(2, 62000, 1800, 1200),
(3, 58000, 2500, 1100),
(4, 57000, 2200, 1300),
(5, 63000, 2300, 1400),
(6, 59000, 2400, 1500),
(7, 61000, 2100, 1600),
(8, 64000, 2000, 1700),
(9, 57000, 2200, 1800),
(10, 65000, 2500, 1900),
(11, 70000, 3000, 1500),
(12, 73300, 2800, 1600),
(13, 68000, 3200, 1700),
(14, 69000, 2900, 1800),
(15, 71000, 3100, 1900),
(16, 73500, 2200, 2000),
(17, 67000, 3300, 2100),
(18, 74000, 2600, 2200),
(19, 68000, 3000, 2300),
(20, 75000, 2800, 2400);



output  :


+------------------+-------------------+-----------+----------+---------------+
| emp_name         | job_title         | total_pay | base_pay | title_avg_pay |
+------------------+-------------------+-----------+----------+---------------+
| Sophia Wilson    | Data Scientist    |     77700 |    73300 |    75720.0000 |
| William Anderson | Data Scientist    |     76000 |    71000 |    75720.0000 |
| Jane Smith       | Software Engineer |     65000 |    62000 |    64250.0000 |
| Kevin Davis      | Software Engineer |     64700 |    61000 |    64250.0000 |
+------------------+-------------------+-----------+----------+---------------+




---------------------------------------------------------------------------------------------------------------------------------------------

Q 75 - Rider Ride Time

You are working with Zomato, a food delivery platform, and you need to analyze the performance of Zomato riders in terms of the time they spend delivering orders each day. Given the pickup and delivery times for each order, your task is to calculate the duration of time spent by each rider on deliveries each day.  Order the output by rider id and ride date.

table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,          -- Unique identifier for the order
    rider_id INT,                      -- Identifier for the rider
    pickup_time DATETIME,              -- Time when the order was picked up
    delivery_time DATETIME             -- Time when the order was delivered
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, rider_id, pickup_time, delivery_time) VALUES
(1, 101, '2024-01-01 10:00:00', '2024-01-01 10:30:00'),
(2, 102, '2024-01-01 23:50:00', '2024-01-02 00:10:00'),
(3, 103, '2024-01-01 13:45:00', '2024-01-01 14:15:00'),
(4, 101, '2024-01-01 23:45:00', '2024-01-02 00:15:00'),
(5, 102, '2024-01-02 01:30:00', '2024-01-02 02:00:00'),
(6, 103, '2024-01-02 23:59:00', '2024-01-03 00:31:00'),
(7, 101, '2024-01-03 09:00:00', '2024-01-03 09:30:00'),
(8, 102, '2024-01-03 10:45:00', '2024-01-03 11:15:00'),
(9, 103, '2024-01-03 23:55:00', '2024-01-04 00:15:00'),
(10, 101, '2024-01-03 23:30:00', '2024-01-04 00:00:00');


output : 

+----------+------------+----------------+
| rider_id | ride_date  | ride_time_mins |
+----------+------------+----------------+
|      101 | 2024-01-01 |             45 |
|      101 | 2024-01-02 |             15 |
|      101 | 2024-01-03 |             60 |
|      102 | 2024-01-01 |             10 |
|      102 | 2024-01-02 |             40 |
|      102 | 2024-01-03 |             30 |
|      103 | 2024-01-01 |             30 |
|      103 | 2024-01-02 |              1 |
|      103 | 2024-01-03 |             36 |
|      103 | 2024-01-04 |             15 |
+----------+------------+----------------+
---------------------------------------------------------------------------------------------------------------------------------------------

Q 76 - Amazon Notifications

 Your task is to analyze the effectiveness of Amazon's notifications in driving user engagement and conversions, considering the user purchase data. A purchase is considered to be associated with a notification if the purchase happens within the timeframe of earliest of below 2 events:
1-  2 hours from notification delivered time
2-  Next notification delivered time.


Each notification is sent for a particular product id but a customer may purchase same or another product. Considering these rules write an SQL to find number of purchases associated with each notification for same product or a different product in 2 separate columns, display the output in ascending order of notification id.

table : -- Create the 'notifications' table
CREATE TABLE notifications (
    notification_id INT PRIMARY KEY,   -- Unique identifier for the notification
    product_id VARCHAR(10),            -- Identifier for the product
    delivered_at DATETIME              -- Timestamp when the notification was delivered
);

-- Insert data into the 'notifications' table
INSERT INTO notifications (notification_id, product_id, delivered_at) VALUES
(1, 'p1', '2024-01-01 08:00:00'),
(2, 'p2', '2024-01-01 10:30:00'),
(3, 'p3', '2024-01-01 11:30:00');



-- Create the 'purchases' table
CREATE TABLE purchases (
    user_id INT,                      -- Identifier for the user who made the purchase
    product_id VARCHAR(10),            -- Identifier for the product that was purchased
    purchase_timestamp DATETIME        -- Timestamp when the purchase was made
);

-- Insert data into the 'purchases' table
INSERT INTO purchases (user_id, product_id, purchase_timestamp) VALUES
(1, 'p1', '2024-01-01 09:00:00'),
(2, 'p2', '2024-01-01 09:00:00'),
(3, 'p2', '2024-01-01 09:30:00'),
(3, 'p1', '2024-01-01 10:20:00'),
(4, 'p2', '2024-01-01 10:40:00'),
(1, 'p2', '2024-01-01 10:50:00'),
(5, 'p2', '2024-01-01 11:45:00'),
(2, 'p3', '2024-01-01 11:45:00'),
(2, 'p3', '2024-01-01 12:30:00'),
(3, 'p3', '2024-01-01 14:30:00');



output : 

+-----------------+------------------------+-----------------------------+
| notification_id | same_product_purchases | different_product_purchases |
+-----------------+------------------------+-----------------------------+
|               1 |                      1 |                           2 |
|               2 |                      2 |                           0 |
|               3 |                      2 |                           1 |
+-----------------+------------------------+-----------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 77 - 2022 vs 2023 vs 2024 Sales

You are tasked with analyzing the sales growth of products over the years 2022, 2023, and 2024. Your goal is to identify months where the sales for a product have consistently increased from 2022 to 2023 and from 2023 to 2024.
Your task is to write an SQL query to generate a report that includes the sales for each product at the month level for the years 2022, 2023, and 2024. However, you should only include product and months combination where the sales have consistently increased from 2022 to 2023 and from 2023 to 2024, display the output in ascending order of product_id.

table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT,                     -- Unique identifier for each order
    customer_id INT,                 -- Identifier for the customer who placed the order
    order_date DATE,                 -- Date when the order was placed
    product_id INT,                  -- Identifier for the product ordered
    sales DECIMAL(10, 2)             -- Sales amount for the order
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, customer_id, order_date, product_id, sales) VALUES
(1, 101, '2023-01-01', 1, 100),
(2, 102, '2023-01-03', 2, 75),
(3, 103, '2023-01-05', 3, 90),
(4, 104, '2023-01-08', 1, 250),
(5, 105, '2023-01-10', 2, 150),
(6, 106, '2023-02-02', 3, 30),
(7, 107, '2023-02-05', 1, 420),
(8, 108, '2023-02-08', 2, 75),
(9, 109, '2023-02-12', 3, 60),
(10, 110, '2023-02-15', 1, 100),
(11, 101, '2023-03-01', 2, 75),
(12, 102, '2023-03-03', 3, 60),
(13, 103, '2023-03-05', 1, 100),
(14, 104, '2023-03-10', 2, 225),
(15, 105, '2023-03-12', 3, 30),
(16, 106, '2023-04-01', 1, 50),
(17, 107, '2023-04-05', 2, 150),
(18, 108, '2023-04-08', 3, 190),
(19, 109, '2023-04-12', 1, 50),
(20, 110, '2023-04-15', 2, 150),
(21, 101, '2023-05-01', 3, 90),
(22, 102, '2023-05-03', 1, 50),
(23, 103, '2023-05-05', 2, 150),
(24, 104, '2023-05-08', 3, 90),
(25, 105, '2023-05-10', 1, 50),
(26, 106, '2023-06-01', 2, 150),
(27, 107, '2023-06-03', 3, 90),
(28, 108, '2023-06-05', 1, 50),
(29, 109, '2023-06-08', 2, 150),
(30, 110, '2023-06-10', 3, 90),
(31, 101, '2023-07-01', 1, 100),
(32, 102, '2023-07-03', 2, 175),
(33, 103, '2023-07-05', 3, 90),
(34, 104, '2023-07-08', 1, 50),
(35, 105, '2023-07-10', 2, 150),
(36, 106, '2023-08-01', 3, 30),
(37, 107, '2023-08-03', 1, 120),
(38, 108, '2023-08-05', 2, 75),
(39, 109, '2023-08-08', 3, 60),
(40, 110, '2023-08-15', 1, 100),
(41, 101, '2023-09-01', 2, 75),
(42, 102, '2023-09-03', 3, 60),
(43, 103, '2023-09-05', 1, 100),
(44, 104, '2023-09-10', 2, 225),
(45, 105, '2023-09-12', 3, 130),
(46, 106, '2023-10-01', 1, 50),
(47, 107, '2023-10-05', 2, 150),
(48, 108, '2023-10-08', 3, 90),
(49, 109, '2023-10-12', 1, 50),
(50, 110, '2023-10-15', 2, 150),
(51, 101, '2023-11-01', 3, 90),
(52, 102, '2023-11-03', 1, 50),
(53, 103, '2023-11-05', 2, 150),
(54, 104, '2023-11-08', 3, 90),
(55, 105, '2023-11-10', 1, 50),
(56, 106, '2023-12-01', 2, 150),
(57, 107, '2023-12-03', 3, 390),
(58, 108, '2023-12-05', 1, 50),
(59, 109, '2023-12-08', 2, 150),
(60, 110, '2023-12-10', 3, 90),
(61, 101, '2024-01-01', 1, 100),
(62, 102, '2024-01-03', 2, 75),
(63, 103, '2024-01-05', 3, 90),
(64, 104, '2024-01-08', 1, 50),
(65, 105, '2024-01-10', 2, 150),
(66, 106, '2024-02-02', 3, 30),
(67, 107, '2024-02-05', 1, 630),
(68, 108, '2024-02-08', 2, 75),
(69, 109, '2024-02-12', 3, 60),
(70, 110, '2024-02-15', 1, 100),
(71, 101, '2024-03-01', 2, 75),
(72, 102, '2024-03-03', 3, 60),
(73, 103, '2024-03-05', 1, 100),
(74, 104, '2024-03-10', 2, 225),
(75, 105, '2024-03-12', 3, 30),
(76, 106, '2024-04-01', 1, 50),
(77, 107, '2024-04-05', 2, 150),
(78, 108, '2024-04-08', 3, 90),
(79, 109, '2024-04-12', 1, 50),
(80, 110, '2024-04-15', 2, 150),
(81, 101, '2024-05-01', 3, 90),
(82, 102, '2024-05-03', 1, 50),
(83, 103, '2024-05-05', 2, 150),
(84, 104, '2024-05-08', 3, 90),
(85, 105, '2024-05-10', 1, 50),
(86, 106, '2024-06-01', 2, 150),
(87, 107, '2024-06-03', 3, 90),
(88, 108, '2024-06-05', 1, 50),
(89, 109, '2024-06-08', 2, 150),
(90, 110, '2024-06-10', 3, 90),
(91, 101, '2024-07-01', 1, 100),
(92, 102, '2024-07-03', 2, 375),
(93, 103, '2024-07-05', 3, 90),
(94, 104, '2024-07-08', 1, 50),
(95, 105, '2024-07-10', 2, 150),
(96, 106, '2024-08-01', 3, 30),
(97, 107, '2024-08-03', 1, 120),
(98, 108, '2024-08-05', 2, 75),
(99, 109, '2024-08-08', 3, 60),
(100, 110, '2024-08-15', 1, 100),
(101, 101, '2024-09-01', 2, 75),
(102, 102, '2024-09-03', 3, 60),
(103, 103, '2024-09-05', 1, 100),
(104, 104, '2024-09-10', 2, 225),
(105, 105, '2024-09-12', 3, 130),
(106, 106, '2024-10-01', 1, 50),
(107, 107, '2024-10-05', 2, 150),
(108, 108, '2024-10-08', 3, 90),
(109, 109, '2024-10-12', 1, 50),
(110, 110, '2024-10-15', 2, 150);


output : 

+------------+-------------+------------+------------+------------+
| product_id | order_month | sales_2022 | sales_2023 | sales_2024 |
+------------+-------------+------------+------------+------------+
|          1 |           2 |        280 |        520 |        730 |
|          2 |           7 |        225 |        325 |        525 |
|          3 |           9 |         90 |        190 |        290 |
+------------+-------------+------------+------------+------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 78 - Hotel Booking Mistake

A hotel has accidentally made overbookings for certain rooms on specific dates. Due to this error, some rooms have been assigned to multiple customers for overlapping periods, leading to potential conflicts. The hotel management needs to rectify this mistake by contacting the affected customers and providing them with alternative arrangements.

 

Your task is to write an SQL query to identify the overlapping bookings for each room and determine the list of customers affected by these overlaps. For each room and overlapping date, the query should list the customers who have booked the room for that date. 
 

A booking's check-out date is not inclusive, meaning that if a room is booked from April 1st to April 4th, it is considered occupied from April 1st to April 3rd , another customer can check-in on April 4th and that will not be considered as overlap.
 

Order the result by room id, booking date. You may use calendar dim table which has all the dates for the year April 2024.

table : -- Create the 'bookings' table
CREATE TABLE bookings (
    room_id INT,                      -- Identifier for the room being booked
    customer_id INT,                 -- Identifier for the customer making the booking
    check_in_date DATE,              -- Check-in date for the booking
    check_out_date DATE              -- Check-out date for the booking
);

-- Insert data into the 'bookings' table
INSERT INTO bookings (room_id, customer_id, check_in_date, check_out_date) VALUES
(1, 101, '2024-04-01', '2024-04-04'),
(2, 102, '2024-04-02', '2024-04-05'),
(1, 103, '2024-04-02', '2024-04-06'),
(3, 104, '2024-04-03', '2024-04-05'),
(2, 105, '2024-04-04', '2024-04-07'),
(1, 106, '2024-04-05', '2024-04-08'),
(3, 107, '2024-04-05', '2024-04-09');






-- Create the 'calendar_dim' table
CREATE TABLE calendar_dim (
    cal_date DATE  -- Date of the calendar entry
);

-- Insert data into the 'calendar_dim' table
INSERT INTO calendar_dim (cal_date) VALUES
('2024-04-01'),
('2024-04-02'),
('2024-04-03'),
('2024-04-04'),
('2024-04-05'),
('2024-04-06'),
('2024-04-07'),
('2024-04-08'),
('2024-04-09'),
('2024-04-10'),
('2024-04-11'),
('2024-04-12'),
('2024-04-13'),
('2024-04-14'),
('2024-04-15'),
('2024-04-16'),
('2024-04-17'),
('2024-04-18'),
('2024-04-19'),
('2024-04-20'),
('2024-04-21'),
('2024-04-22'),
('2024-04-23'),
('2024-04-24'),
('2024-04-25'),
('2024-04-26'),
('2024-04-27'),
('2024-04-28'),
('2024-04-29'),
('2024-04-30');



output : 

+---------+------------+-----------+
| room_id | book_date  | customers |
+---------+------------+-----------+
|       1 | 2024-04-02 | 101,103   |
|       1 | 2024-04-03 | 101,103   |
|       1 | 2024-04-05 | 103,106   |
|       2 | 2024-04-04 | 102,105   |
+---------+------------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 79 - Top Products of Top Category

You are analyzing sales data from an e-commerce platform, which includes information about orders placed for various products across different categories. Each order contains details such as the order ID, order date, product ID, category, and amount.
Write an SQL to identify the top 3 products within the top-selling category based on total sales. The top-selling category is determined by the sum of the amounts sold for all products within that category. Sort the output by products sales in descending order.

table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,          -- Unique identifier for the order
    order_date DATE,                  -- Date of the order
    product_id INT,                   -- ID of the product ordered
    category VARCHAR(50),             -- Category of the product
    amount DECIMAL(10, 2)             -- Amount of the order
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, order_date, product_id, category, amount) VALUES
(1, '2024-01-01', 1, 'Furniture', 100.00),
(2, '2024-01-02', 6, 'Technology', 150.00),
(3, '2024-01-03', 11, 'Home Appliances', 120.00),
(4, '2024-01-04', 4, 'Furniture', 200.00),
(5, '2024-01-05', 7, 'Technology', 180.00),
(6, '2024-01-06', 1, 'Furniture', 110.00),
(7, '2024-01-07', 8, 'Technology', 220.00),
(8, '2024-01-08', 12, 'Home Appliances', 130.00),
(9, '2024-01-09', 3, 'Furniture', 190.00),
(10, '2024-01-10', 9, 'Technology', 240.00),
(11, '2024-01-11', 2, 'Furniture', 140.00),
(12, '2024-01-12', 10, 'Technology', 200.00),
(13, '2024-01-13', 13, 'Home Appliances', 260.00),
(14, '2024-01-14', 2, 'Furniture', 150.00),
(15, '2024-01-15', 6, 'Technology', 210.00),
(16, '2024-01-16', 1, 'Furniture', 280.00),
(17, '2024-01-17', 7, 'Technology', 160.00),
(18, '2024-01-18', 14, 'Home Appliances', 220.00),
(19, '2024-01-19', 4, 'Furniture', 300.00),
(20, '2024-01-20', 8, 'Technology', 170.00),
(21, '2024-01-21', 3, 'Furniture', 230.00),
(22, '2024-01-22', 2, 'Furniture', 320.00),
(23, '2024-01-23', 15, 'Home Appliances', 180.00),
(24, '2024-01-24', 5, 'Furniture', 240.00),
(25, '2024-01-25', 9, 'Technology', 340.00),
(26, '2024-01-26', 2, 'Furniture', 190.00),
(27, '2024-01-27', 10, 'Technology', 250.00),
(28, '2024-01-28', 11, 'Home Appliances', 360.00),
(29, '2024-01-29', 1, 'Furniture', 200.00),
(30, '2024-01-30', 6, 'Technology', 260.00);


output : 


+------------+-----------+-------------+
| product_id | category  | total_sales |
+------------+-----------+-------------+
|          2 | Furniture |         800 |
|          1 | Furniture |         690 |
|          4 | Furniture |         500 |
+------------+-----------+-------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 80 - Rolling Sales

You are tasked with analysing the sales data for products during the month of January 2024. Your goal is to calculate the rolling sum of sales for each product and each day of Jan 2024, considering the sales for the current day and the two previous days. Note that for some days, there might not be any sales for certain products, and you need to consider these days as having sales of 0.

You can make use of the calendar table which has the all the dates for Jan-2024.

table : -- Create the 'orders' table
CREATE TABLE orders (
    order_id INT PRIMARY KEY,          -- Unique identifier for the order
    order_date DATE,                  -- Date of the order
    product_id VARCHAR(10),           -- ID of the product (e.g., 'p1', 'p2')
    amount DECIMAL(10, 2)             -- Amount of the order
);

-- Insert data into the 'orders' table
INSERT INTO orders (order_id, order_date, product_id, amount) VALUES
(1, '2024-01-01', 'p1', 100.00),
(2, '2024-01-01', 'p1', 150.00),
(3, '2024-01-03', 'p1', 120.00),
(4, '2024-01-04', 'p2', 200.00),
(5, '2024-01-05', 'p1', 180.00),
(6, '2024-01-06', 'p1', 110.00),
(7, '2024-01-07', 'p1', 220.00),
(8, '2024-01-08', 'p2', 130.00),
(9, '2024-01-09', 'p1', 190.00),
(10, '2024-01-10', 'p2', 240.00),
(11, '2024-01-11', 'p1', 140.00),
(12, '2024-01-12', 'p2', 200.00),
(13, '2024-01-13', 'p2', 260.00),
(14, '2024-01-14', 'p2', 150.00),
(15, '2024-01-15', 'p1', 210.00),
(16, '2024-01-16', 'p2', 280.00),
(17, '2024-01-16', 'p2', 160.00),
(18, '2024-01-18', 'p2', 220.00),
(19, '2024-01-19', 'p1', 300.00),
(20, '2024-01-20', 'p2', 170.00),
(21, '2024-01-21', 'p1', 230.00),
(22, '2024-01-22', 'p2', 320.00),
(23, '2024-01-23', 'p1', 180.00),
(24, '2024-01-24', 'p1', 240.00),
(25, '2024-01-25', 'p1', 340.00),
(26, '2024-01-26', 'p2', 190.00),
(27, '2024-01-27', 'p1', 250.00),
(28, '2024-01-28', 'p2', 360.00),
(29, '2024-01-29', 'p1', 200.00),
(30, '2024-01-30', 'p2', 260.00);


output :

 +------------+------------+-------+--------------+
| product_id | order_date | sales | rolling3_sum |
+------------+------------+-------+--------------+
| p1         | 2024-01-01 |   250 |          250 |
| p1         | 2024-01-02 |     0 |          250 |
| p1         | 2024-01-03 |   120 |          370 |
| p1         | 2024-01-04 |     0 |          120 |
| p1         | 2024-01-05 |   180 |          300 |
| p1         | 2024-01-06 |   110 |          290 |
| p1         | 2024-01-07 |   220 |          510 |
| p1         | 2024-01-08 |     0 |          330 |
| p1         | 2024-01-09 |   190 |          410 |
| p1         | 2024-01-10 |     0 |          190 |
| p1         | 2024-01-11 |   140 |          330 |
| p1         | 2024-01-12 |     0 |          140 |
| p1         | 2024-01-13 |     0 |          140 |
| p1         | 2024-01-14 |     0 |            0 |
| p1         | 2024-01-15 |   210 |          210 |
| p1         | 2024-01-16 |     0 |          210 |
| p1         | 2024-01-17 |     0 |          210 |
| p1         | 2024-01-18 |     0 |            0 |
| p1         | 2024-01-19 |   300 |          300 |
| p1         | 2024-01-20 |     0 |          300 |
| p1         | 2024-01-21 |   230 |          530 |
| p1         | 2024-01-22 |     0 |          230 |
| p1         | 2024-01-23 |   180 |          410 |
| p1         | 2024-01-24 |   240 |          420 |
| p1         | 2024-01-25 |   340 |          760 |
| p1         | 2024-01-26 |     0 |          580 |
| p1         | 2024-01-27 |   250 |          590 |
| p1         | 2024-01-28 |     0 |          250 |
| p1         | 2024-01-29 |   200 |          450 |
| p1         | 2024-01-30 |     0 |          200 |
| p1         | 2024-01-31 |     0 |          200 |
| p2         | 2024-01-01 |     0 |            0 |
| p2         | 2024-01-02 |     0 |            0 |
| p2         | 2024-01-03 |     0 |            0 |
| p2         | 2024-01-04 |   200 |          200 |
| p2         | 2024-01-05 |     0 |          200 |
| p2         | 2024-01-06 |     0 |          200 |
| p2         | 2024-01-07 |     0 |            0 |
| p2         | 2024-01-08 |   130 |          130 |
| p2         | 2024-01-09 |     0 |          130 |
| p2         | 2024-01-10 |   240 |          370 |
| p2         | 2024-01-11 |     0 |          240 |
| p2         | 2024-01-12 |   200 |          440 |
| p2         | 2024-01-13 |   260 |          460 |
| p2         | 2024-01-14 |   150 |          610 |
| p2         | 2024-01-15 |     0 |          410 |
| p2         | 2024-01-16 |   440 |          590 |
| p2         | 2024-01-17 |     0 |          440 |
| p2         | 2024-01-18 |   220 |          660 |
| p2         | 2024-01-19 |     0 |          220 |
| p2         | 2024-01-20 |   170 |          390 |
| p2         | 2024-01-21 |     0 |          170 |
| p2         | 2024-01-22 |   320 |          490 |
| p2         | 2024-01-23 |     0 |          320 |
| p2         | 2024-01-24 |     0 |          320 |
| p2         | 2024-01-25 |     0 |            0 |
| p2         | 2024-01-26 |   190 |          190 |
| p2         | 2024-01-27 |     0 |          190 |
| p2         | 2024-01-28 |   360 |          550 |
| p2         | 2024-01-29 |     0 |          360 |
| p2         | 2024-01-30 |   260 |          620 |
| p2         | 2024-01-31 |     0 |          260 |
+------------+------------+-------+--------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 81 - Consistent Growth

In a financial analysis project, you are tasked with identifying companies that have consistently increased their revenue by at least 25% every year. You have a table named revenue that contains information about the revenue of different companies over several years.
Your goal is to find companies whose revenue has increased by at least 25% every year consecutively. So for example If a company's revenue has increased by 25% or more for three consecutive years but not for the fourth year, it will not be considered.


Write an SQL query to retrieve the names of companies that meet the criteria mentioned above along with total lifetime revenue , display the output in ascending order of company id

table : -- Create the 'revenue' table
CREATE TABLE revenue (
    company_id INT,                -- ID of the company
    year INT,                      -- Year of revenue
    revenue DECIMAL(15, 2),       -- Revenue amount
    PRIMARY KEY (company_id, year) -- Composite primary key
);

-- Insert data into the 'revenue' table
INSERT INTO revenue (company_id, year, revenue) VALUES
(1, 2018, 100000.00),
(1, 2019, 125000.00),
(1, 2020, 156250.00),
(1, 2021, 200000.00),
(1, 2022, 260000.00),
(2, 2018,  80000.00),
(2, 2019, 100000.00),
(2, 2020, 130000.00),
(2, 2021, 156000.00),
(2, 2022, 180000.00),
(3, 2018,  50000.00),
(3, 2019,  60000.00),
(3, 2020,  72000.00),
(3, 2021,  80000.00),
(3, 2022,  85000.00),
(4, 2018, 200000.00),
(4, 2019, 260000.00),
(4, 2020, 350000.00),
(4, 2021, 450000.00),
(4, 2022, 600000.00);


output : 

+------------+---------------+
| company_id | total_revenue |
+------------+---------------+
|          1 |     841250.00 |
|          4 |    1860000.00 |
+------------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 82 - Child and Parents

You are tasked to determine the mother and father's name for each child based on the given data. The people table provides information about individuals, including their names and genders. The relations table specifies parent-child relationships, linking each child (c_id) to their parent (p_id). Each parent is identified by their ID, and their gender is used to distinguish between mothers (F) and fathers (M).

Write an SQL query to retrieve the names of each child along with the names of their respective mother and father, if available. If a child has only one parent listed in the relations table, the query should still include that parent's name and leave the other parent's name as NULL. Order the output by child name in ascending order.

table : -- Create the 'people' table
CREATE TABLE people (
    id INT PRIMARY KEY,              -- Unique ID for each person
    name VARCHAR(50),               -- Name of the person
    gender CHAR(1)                  -- Gender of the person (M/F)
);

-- Insert data into the 'people' table
INSERT INTO people (id, name, gender) VALUES
(107, 'Days', 'F'),
(145, 'Hawbaker', 'M'),
(155, 'Hansel', 'F'),
(202, 'Blackston', 'M'),
(227, 'Criss', 'F'),
(278, 'Keffer', 'M'),
(305, 'Canty', 'M'),
(329, 'Mozingo', 'M'),
(425, 'Nolf', 'M'),
(534, 'Waugh', 'M'),
(586, 'Tong', 'M'),
(618, 'Dimartino', 'M'),
(747, 'Beane', 'M'),
(878, 'Chatmon', 'F'),
(904, 'Hansard', 'F');




-- Create the 'relations' table
CREATE TABLE relations (
    c_id INT,     -- Customer ID
    p_id INT,     -- Person ID
    PRIMARY KEY (c_id, p_id)  -- Composite primary key
);

-- Insert data into the 'relations' table
INSERT INTO relations (c_id, p_id) VALUES
(145, 202),
(145, 107),
(278, 305),
(278, 155),
(329, 425),
(329, 227),
(534, 586),
(618, 904);


output : 

+------------+-------------+-------------+
| child_name | mother_name | father_name |
+------------+-------------+-------------+
| Dimartino  | Hansard     | NULL        |
| Hawbaker   | Days        | Blackston   |
| Keffer     | Hansel      | Canty       |
| Mozingo    | Criss       | Nolf        |
| Waugh      | NULL        | Tong        |
+------------+-------------+-------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 83 - Unique Daily Purchases

Suppose you are analyzing the purchase history of customers in an e-commerce platform. Your task is to identify customers who have bought different products on different dates.
Write an SQL to find customers who have bought different products on different dates, means product purchased on a given day is not repeated on any other day by the customer. Also note that for the customer to qualify he should have made purchases on at least 2 distinct dates. Please note that customer can purchase same product more than once on the same day and that doesn't disqualify him. Output should contain customer id and number of products bought by the customer in ascending order of userid.

table : -- Create the 'purchase_history' table
CREATE TABLE purchase_history (
    userid INT,          -- User ID
    productid INT,       -- Product ID
    purchasedate DATE,  -- Date of purchase
    PRIMARY KEY (userid, productid, purchasedate)  -- Composite primary key
);

-- Insert data into the 'purchase_history' table
INSERT INTO purchase_history (userid, productid, purchasedate) VALUES
(1, 1, '2012-01-23'),
(1, 1, '2012-01-23'),
(1, 2, '2012-01-23'),
(1, 3, '2012-01-25'),
(2, 1, '2012-01-23'),
(2, 2, '2012-01-23'),
(2, 2, '2012-01-25'),
(2, 4, '2012-01-25'),
(3, 4, '2012-01-23'),
(3, 1, '2012-01-23'),
(4, 1, '2012-01-23'),
(4, 2, '2012-01-25');


output : 

+--------+--------------+
| userid | cnt_products |
+--------+--------------+
|      1 |            3 |
|      4 |            2 |
+--------+--------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 84 - Uber Commission

In a bustling city, Uber operates a fleet of drivers who provide transportation services to passengers. As part of Uber's policy, drivers are subject to a commission deduction from their total earnings. The commission rate is determined based on the average rating received by the driver over their recent trips. This ensures that drivers delivering exceptional service are rewarded with lower commission rates, while those with lower ratings are subject to higher commission rates. 

Commission Calculation: For the first 3 trips of each driver, a standard commission rate of 24% is applied.
After the first 3 trips, the commission rate is determined based on the average rating of the driver's last 3 trips before the current trip:
If the average rating is between 4.7 and 5 (inclusive), the commission rate is 20%.
If the average rating is between 4.5 and 4.7 (inclusive), the commission rate is 23%.
For any other average rating, the default commission rate remains at 24%.

Write an SQL query to calculate the total earnings for each driver after deducting Uber's commission, considering the commission rates as per the given criteria, display the output in ascending order of driver id.

table : -- Create the 'trips' table
CREATE TABLE trips (
    trip_id INT PRIMARY KEY,   -- Trip ID
    driver_id INT,             -- Driver ID
    fare DECIMAL(10, 2),       -- Fare amount
    rating DECIMAL(3, 2)       -- Rating (out of 5.00)
);

-- Insert data into the 'trips' table
INSERT INTO trips (trip_id, driver_id, fare, rating) VALUES
(1, 101, 1500, 4.50),
(2, 101, 2000, 4.20),
(3, 101, 2500, 5.00),
(4, 101, 3000, 4.70),
(5, 101, 3500, 4.40),
(6, 101, 4000, 4.90),
(7, 101, 4500, 4.60),
(8, 101, 5000, 4.30),
(9, 101, 5500, 4.10),
(10, 101, 6000, 4.70),
(11, 102, 2000, 4.20),
(12, 102, 2500, 4.60),
(13, 102, 3000, 4.90),
(14, 102, 3500, 5.00),
(15, 102, 4000, 4.30),
(16, 102, 4500, 4.80),
(17, 102, 5000, 4.70),
(18, 102, 5500, 4.40),
(19, 102, 6000, 4.10),
(20, 102, 6500, 4.50),
(21, 103, 3000, 4.60),
(22, 103, 3500, 4.80),
(23, 103, 4000, 4.40),
(24, 103, 4500, 4.70),
(25, 103, 5000, 4.20),
(26, 103, 5500, 4.60),
(27, 103, 6000, 5.00),
(28, 103, 6500, 4.80),
(29, 103, 7000, 4.10),
(30, 103, 7500, 4.50);


output : 

+-----------+----------------+
| driver_id | total_earnings |
+-----------+----------------+
|       101 |       28755.00 |
|       102 |       32840.00 |
|       103 |       40415.00 |
+-----------+----------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 85 - Customer Support Metrics


You are working for a customer support team at an e-commerce company. The company provides customer support through both web-based chat and mobile app chat. Each conversation between a customer and a support agent is logged in a database table named conversation. The table contains information about the sender (customer or agent), the message content, the order related to the conversation, and other relevant details.
Your task is to analyze the conversation data to extract meaningful insights for improving customer support efficiency. Write an SQL query to fetch the following information from the conversation table for each order_id and sort the output by order_id.

 

order_id: The unique identifier of the order related to the conversation.
city_code: The city code where the conversation took place. This is unique to each order_id.
first_agent_message: The timestamp of the first message sent by a support agent in the conversation.
first_customer_message: The timestamp of the first message sent by a customer in the conversation.
num_messages_agent: The total number of messages sent by the support agent in the conversation.
num_messages_customer: The total number of messages sent by the customer in the conversation.
first_message_by: Indicates whether the first message in the conversation was sent by a support agent or a customer.
resolved(0 or 1): Indicates whether the conversation has a message marked as resolution = true, atleast once.
reassigned(0 or 1): Indicates whether the conversation has had interactions by more than one support agent.

table : -- Create the 'conversation' table
CREATE TABLE conversation (
    senderDeviceType VARCHAR(50), -- Type of device sender is using
    customerId INT,               -- ID of the customer
    orderId INT,                  -- ID of the order
    resolution BOOLEAN,           -- Whether the issue was resolved
    agentId INT,                  -- ID of the agent
    messageSentTime TIMESTAMP,    -- Time when the message was sent
    cityCode VARCHAR(10)          -- Code of the city
);

-- Insert data into the 'conversation' table
INSERT INTO conversation (senderDeviceType, customerId, orderId, resolution, agentId, messageSentTime, cityCode) VALUES
('Android Customer', 17071099, 59528555, TRUE, 16293039, '2019-08-19 08:01:04', 'LOS'),
('Web Agent', 17071099, 59528555, FALSE, 16293039, '2019-08-19 08:01:04', 'LOS'),
('Android Customer', 17071099, 59528555, FALSE, 16293039, '2019-08-19 08:00:04', 'LOS'),
('Web Agent', 12874122, 59528038, FALSE, 18325287, '2019-08-19 07:59:33', 'Mysore'),
('Web Agent', 12345678, 59528556, FALSE, 87654321, '2019-08-20 10:15:32', 'NYC'),
('Android Customer', 87654321, 59528556, FALSE, 12345678, '2019-08-20 10:16:25', 'NYC'),
('Web Agent', 98765432, 59528557, FALSE, 98765432, '2019-08-21 09:30:18', 'LA'),
('Android Customer', 24681357, 59528557, FALSE, 98765432, '2019-08-21 09:32:05', 'LA');


output : 

+----------+-----------+---------------------+------------------------+--------------------+-----------------------+------------------+----------+------------+
| order_id | city_code | first_agent_message | first_customer_message | num_messages_agent | num_messages_customer | first_message_by | resolved | reassigned |
+----------+-----------+---------------------+------------------------+--------------------+-----------------------+------------------+----------+------------+
| 59528038 | Mysore    | 2019-08-19 07:59:33 | NULL                   |                  1 |                     0 | Agent            |        0 |          0 |
| 59528555 | LOS       | 2019-08-19 08:01:04 | 2019-08-19 08:00:04    |                  1 |                     2 | Customer         |        1 |          0 |
| 59528556 | NYC       | 2019-08-20 10:15:32 | 2019-08-20 10:16:25    |                  1 |                     1 | Agent            |        0 |          1 |
| 59528557 | LA        | 2019-08-21 09:30:18 | 2019-08-21 09:32:05    |                  1 |                     1 | Agent            |        0 |          0 |
+----------+-----------+---------------------+------------------------+--------------------+-----------------------+------------------+----------+------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 86 - IPL Away Wins

In the Indian Premier League (IPL), each team plays two matches against every other team: one at their home venue and one at their opponent's venue. We want to identify team combinations where each team wins the away match but loses the home match against the same opponent. Write an SQL query to find such team combinations, where each team wins at the opponent's venue but loses at their own home venue.

table : -- Create the 'matches' table
CREATE TABLE matches (
    match_id INT PRIMARY KEY,     -- ID of the match
    home_team VARCHAR(50),        -- Home team
    away_team VARCHAR(50),        -- Away team
    winner_team VARCHAR(50)       -- Winner team
);

-- Insert data into the 'matches' table
INSERT INTO matches (match_id, home_team, away_team, winner_team) VALUES
(1, 'CSK', 'MI', 'MI'),
(2, 'GL', 'RR', 'GL'),
(3, 'SRH', 'Kings11', 'SRH'),
(4, 'DD', 'KKR', 'KKR'),
(5, 'MI', 'CSK', 'MI'),
(6, 'RR', 'GL', 'GL'),
(7, 'Kings11', 'SRH', 'Kings11'),
(8, 'KKR', 'DD', 'DD');

output : 

+-------+-------+
| team1 | team2 |
+-------+-------+
| DD    | KKR   |
+-------+-------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 87 - Leave Approval

You are tasked with writing an SQL query to determine whether a leave request can be approved for each employee based on their available leave balance for 2024. Employees receive 1.5 leaves at the start of each month, and they may have some balance leaves carried over from the previous year 2023(available in employees table). A leave request can only be approved if the employee has a sufficient leave balance at the start date of planned leave period. 

Write an SQL to derive a new status column stating if leave request is Approved or Rejected for each leave request. Sort the output by request id. Consider the following assumptions:

 

1- If a leave request is eligible for approval, then it will always be taken by employee and leave balance will be deducted as per the leave period. If the leave is rejected then the balance will not be deducted.
2- A leave will either be fully approved or cancelled. No partial approvals possible.
3- If a weekend is falling between the leave start and end date then do consider them when calculating the leave days, Meaning no exclusion of weekends.

table : -- Create the 'employees' table
CREATE TABLE employees (
    employee_id INT PRIMARY KEY,             -- ID of the employee
    name VARCHAR(100),                       -- Name of the employee
    leave_balance_from_2023 INT              -- Leave balance from 2023
);

-- Insert data into the 'employees' table
INSERT INTO employees (employee_id, name, leave_balance_from_2023) VALUES
(1, 'John Doe', 5),
(2, 'Jane Smith', 6),
(3, 'Alice Johnson', 4);




-- Create the 'leave_requests' table
CREATE TABLE leave_requests (
    request_id INT PRIMARY KEY,               -- ID of the leave request
    employee_id INT,                         -- ID of the employee requesting leave
    leave_start_date DATE,                   -- Start date of the leave
    leave_end_date DATE,                     -- End date of the leave
    FOREIGN KEY (employee_id) REFERENCES employees(employee_id)  -- Foreign key referencing 'employees'
);

-- Insert data into the 'leave_requests' table
INSERT INTO leave_requests (request_id, employee_id, leave_start_date, leave_end_date) VALUES
(1, 1, '2024-01-05', '2024-01-15'),
(2, 1, '2024-01-21', '2024-01-27'),
(3, 1, '2024-02-12', '2024-02-17'),
(4, 1, '2024-07-03', '2024-07-12'),
(5, 2, '2024-01-20', '2024-01-25'),
(6, 2, '2024-03-20', '2024-03-30'),
(7, 2, '2024-10-05', '2024-10-12'),
(8, 3, '2024-01-17', '2024-01-25'),
(9, 3, '2024-10-05', '2024-10-14');


output : 

+------------+-------------+------------------+----------------+----------+
| request_id | employee_id | leave_start_date | leave_end_date | status   |
+------------+-------------+------------------+----------------+----------+
|          1 |           1 | 2024-01-05       | 2024-01-15     | Rejected |
|          2 |           1 | 2024-01-21       | 2024-01-27     | Rejected |
|          3 |           1 | 2024-02-12       | 2024-02-17     | Approved |
|          4 |           1 | 2024-07-03       | 2024-07-12     | Rejected |
|          5 |           2 | 2024-01-20       | 2024-01-25     | Approved |
|          6 |           2 | 2024-03-20       | 2024-03-30     | Rejected |
|          7 |           2 | 2024-10-05       | 2024-10-12     | Approved |
|          8 |           3 | 2024-01-17       | 2024-01-25     | Rejected |
|          9 |           3 | 2024-10-05       | 2024-10-14     | Approved |
+------------+-------------+------------------+----------------+----------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q  88 - Netflix Device Type (PART-1)

In the Netflix dataset containing information about viewers and their viewing history, devise a query to identify viewers who primarily use mobile devices for viewing, but occasionally switch to other devices. Specifically, find viewers who have watched at least 75% of their total viewing time on mobile devices but have also used at least one other devices such as tablets or smart TVs for viewing. Provide the user ID and the percentage of viewing time spent on mobile devices. Round the result to nearest integer.


table : -- Create the 'viewing_history' table
CREATE TABLE viewing_history (
    user_id INT,                            -- ID of the user
    title VARCHAR(255),                     -- Title of the content viewed
    device_type VARCHAR(50),                -- Type of device used
    watch_mins INT,                         -- Number of minutes watched
    PRIMARY KEY (user_id, title, device_type)  -- Composite primary key
);

-- Insert data into the 'viewing_history' table
INSERT INTO viewing_history (user_id, title, device_type, watch_mins) VALUES
(1, 'Stranger Things', 'Mobile', 60),
(1, 'The Crown', 'Mobile', 45),
(1, 'Narcos', 'Smart TV', 90),
(2, 'Stranger Things', 'Mobile', 100),
(2, 'The Crown', 'Tablet', 55),
(2, 'Narcos', 'Mobile', 95),
(3, 'Stranger Things', 'Mobile', 40),
(3, 'The Crown', 'Mobile', 60),
(3, 'Narcos', 'Mobile', 70),
(4, 'Stranger Things', 'Mobile', 70),
(4, 'The Crown', 'Smart TV', 65),
(4, 'Narcos', 'Tablet', 80);


output : 

+---------+------------------------+
| user_id | mobile_percentage_view |
+---------+------------------------+
|       2 |                     78 |
+---------+------------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 89 - Netflix Device Type (PART-2)

In the Netflix viewing history dataset, you are tasked with identifying viewers who have a consistent viewing pattern across multiple devices. Specifically, viewers who have watched the same title on more than 1 device type. 
Write an SQL query to find users who have watched more number of titles on multiple devices than the number of titles they watched on single device. Output the user id , no of titles watched on multiple devices and no of titles watched on single device, display the output in ascending order of user_id.

table : -- Create the 'viewing_history' table
CREATE TABLE viewing_history (
    user_id INT,                            -- ID of the user
    title VARCHAR(255),                     -- Title of the content viewed
    device_type VARCHAR(50),                -- Type of device used
    PRIMARY KEY (user_id, title, device_type)  -- Composite primary key
);

-- Insert data into the 'viewing_history' table
INSERT INTO viewing_history (user_id, title, device_type) VALUES
(1, 'Stranger Things', 'Mobile'),
(1, 'The Crown', 'Mobile'),
(1, 'Narcos', 'Smart TV'),
(1, 'The Crown', 'Smart TV'),
(1, 'Stranger Things', 'Smart TV'),
(2, 'Stranger Things', 'Mobile'),
(2, 'The Crown', 'Tablet'),
(2, 'Narcos', 'Mobile'),
(2, 'Narcos', 'Tablet'),
(3, 'Stranger Things', 'Mobile'),
(3, 'Stranger Things', 'Tablet'),
(3, 'Stranger Things', 'Smart TV'),
(4, 'Stranger Things', 'Mobile');


output : 

+---------+---------------------+-------------------+
| user_id | multiple_device_cnt | single_device_cnt |
+---------+---------------------+-------------------+
|       1 |                   2 |                 1 |
|       3 |                   1 |                 0 |
+---------+---------------------+-------------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 90 - Calculate Customer Interest

You are tasked with analyzing the interest earned by customers based on their account balances and transaction history. Each customer's account accrues interest based on their balance and prevailing interest rates. The interest is calculated for the ending balance on each day. Your goal is to determine the total interest earned by each customer for the month of March-2024. The interest rates (per day) are given in the interest table as per the balance amount range. 

 

Please assume that the account balance for each customer was 0 at the start of March 2024.  Write an SQL to calculate interest earned by each customer from March 1st 2024 to March 31st 2024, display the output in ascending order of customer id.

table : -- Create the 'transactions' table
CREATE TABLE transactions (
    transaction_id INT PRIMARY KEY,         -- Unique ID for each transaction
    customer_id INT,                        -- ID of the customer involved in the transaction
    transaction_date DATE,                  -- Date of the transaction
    amount DECIMAL(10, 2)                   -- Amount of the transaction
);

-- Insert data into the 'transactions' table
INSERT INTO transactions (transaction_id, customer_id, transaction_date, amount) VALUES
(1, 1, '2024-03-01', 1000.00),
(2, 2, '2024-03-02', 500.00),
(3, 3, '2024-03-03', 1500.00),
(4, 1, '2024-03-15', -300.00),
(5, 2, '2024-03-20', 700.00),
(6, 3, '2024-03-25', -200.00),
(7, 1, '2024-03-28', 400.00),
(8, 2, '2024-03-30', -800.00),
(9, 3, '2024-03-31', 1000.00),
(10, 3, '2024-03-31', 100.00);




-- Create the 'InterestRates' table
CREATE TABLE InterestRates (
    rate_id INT PRIMARY KEY,          -- Unique identifier for the interest rate tier
    min_balance DECIMAL(10, 2),      -- Minimum balance for this interest rate tier
    max_balance DECIMAL(10, 2),      -- Maximum balance for this interest rate tier
    interest_rate DECIMAL(5, 4)      -- Interest rate for the tier
);

-- Insert data into the 'InterestRates' table
INSERT INTO InterestRates (rate_id, min_balance, max_balance, interest_rate) VALUES
(1, 0.00, 499.00, 0.0100),
(2, 500.00, 999.00, 0.0200),
(3, 1000.00, 1499.00, 0.0300),
(4, 1500.00, 99999.00, 0.0400);


output : 

+-------------+-----------------+
| customer_id | interest_earned |
+-------------+-----------------+
|           1 |        734.0000 |
|           2 |        548.0000 |
|           3 |       1650.0000 |
+-------------+-----------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 91 - Election Winner

You are provided with election data from multiple districts in India. Each district conducted elections for selecting a representative from various political parties. Your task is to analyze the election results to determine the winning party at national levels.  Here are the steps to identify winner:


1- Determine the winning party in each district based on the candidate with the highest number of votes.
2- If multiple candidates from different parties have the same highest number of votes in a district
  , consider it a tie, and all tied candidates are declared winners for that district.
3- Calculate the total number of seats won by each party across all districts
4- A party wins the election if it secures more than 50% of the total seats available nationwide.

Display the total number of seats won by each party and a result column specifying Winner or Loser. Order the output by total seats won in descending order.

table : CREATE TABLE elections (
    district_name VARCHAR(50),
    candidate_id INT,
    party_name VARCHAR(50),
    votes INT
);

INSERT INTO elections (district_name, candidate_id, party_name, votes) VALUES
('Delhi North', 101, 'Congress', 1500),
('Delhi North', 102, 'BJP', 1500),
('Delhi North', 103, 'AAP', 1100),
('Mumbai South', 106, 'Congress', 2000),
('Mumbai South', 107, 'BJP', 1800),
('Mumbai South', 110, 'AAP', 1500),
('Kolkata East', 111, 'Congress', 2200),
('Kolkata East', 113, 'BJP', 2300),
('Kolkata East', 114, 'AAP', 2000),
('Chennai Central', 116, 'Congress', 1600),
('Chennai Central', 117, 'BJP', 1700),
('Chennai Central', 119, 'AAP', 1500),
('Bangalore West', 121, 'Congress', 2100),
('Bangalore West', 122, 'BJP', 2200),
('Bangalore West', 124, 'AAP', 2000),
('Hyderabad North', 126, 'Congress', 1800),
('Hyderabad North', 127, 'BJP', 1900),
('Hyderabad North', 129, 'AAP', 1700),
('Pune East', 131, 'Congress', 2000),
('Pune East', 132, 'BJP', 1900),
('Pune East', 134, 'AAP', 2200),
('Ahmedabad South', 136, 'Congress', 1700),
('Ahmedabad South', 137, 'BJP', 2100),
('Ahmedabad South', 139, 'AAP', 1600),
('Jaipur West', 141, 'Congress', 1900),
('Jaipur West', 142, 'BJP', 2000),
('Jaipur West', 144, 'AAP', 1800),
('Lucknow Central', 146, 'Congress', 2500),
('Lucknow Central', 147, 'BJP', 1900),
('Lucknow Central', 149, 'AAP', 2100);


output : 

+------------+-----------+--------+
| party_name | seats_won | result |
+------------+-----------+--------+
| BJP        |         7 | Winner |
| Congress   |         3 | Loser  |
| AAP        |         1 | Loser  |
+------------+-----------+--------+
---------------------------------------------------------------------------------------------------------------------------------------------

Q 92 - Eat and Win

A pizza eating competition is organized. All the participants are organized into different groups. In a contest , A participant who eat the most pieces of pizza is the winner and recieves their original bet plus 30% of all losing participants bets. In case of a tie all winning participants will get equal share (of 30%) divided among them .Return the winning participants' names for each group and amount of their payout(round to 2 decimal places) . ordered ascending by group_id , participant_name.

table: CREATE TABLE competition (
    group_id INT,
    participant_name VARCHAR(50),
    slice_count INT,
    bet INT
);

INSERT INTO competition (group_id, participant_name, slice_count, bet) VALUES
(1, 'Alice', 10, 51),
(1, 'Bob', 15, 42),
(1, 'Eve', 15, 30),
(1, 'Tom', 8, 21),
(1, 'Jerry', 12, 12),
(2, 'Charlie', 20, 60),
(2, 'David', 20, 72),
(2, 'Mike', 20, 54),
(2, 'Nancy', 18, 42),
(2, 'Oliver', 10, 30),
(3, 'Frank', 12, 51),
(3, 'Grace', 18, 48),
(3, 'Hank', 15, 30),
(3, 'Irene', 14, 21),
(3, 'John', 16, 60),
(4, 'Ivy', 25, 102),
(4, 'Jack', 22, 81),
(4, 'Kathy', 20, 90),
(4, 'Leo', 18, 72),
(4, 'Mia', 15, 51);


output : 

+----------+------------------+--------------+
| group_id | participant_name | total_payout |
+----------+------------------+--------------+
|        1 | Bob              |        54.60 |
|        1 | Eve              |        42.60 |
|        2 | Charlie          |        67.20 |
|        2 | David            |        79.20 |
|        2 | Mike             |        61.20 |
|        3 | Grace            |        96.60 |
|        4 | Ivy              |       190.20 |
+----------+------------------+--------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 93 - OTT Viewership

You have a table named ott_viewership. Write an SQL query to find the top 2 most-watched shows in each genre in the United States. Return the show name, genre, and total duration watched for each of the top 2 most-watched shows in each genre. sort the result by genre and total duration.

table : -- Create the ott_viewership table
CREATE TABLE ott_viewership (
    viewer_id INT,
    show_id INT,
    show_name VARCHAR(50),
    genre VARCHAR(20),
    country VARCHAR(20),
    view_date DATE,
    duration_min INT
);

-- Insert data into the ott_viewership table
INSERT INTO ott_viewership (viewer_id, show_id, show_name, genre, country, view_date, duration_min) VALUES
(1, 101, 'Stranger Things', 'Drama', 'United States', '2023-05-01', 60),
(2, 102, 'The Crown', 'Drama', 'United States', '2023-05-01', 45),
(3, 103, 'Breaking Bad', 'Drama', 'United States', '2023-05-02', 50),
(4, 104, 'Game of Thrones', 'Fantasy', 'United States', '2023-05-02', 55),
(5, 105, 'The Mandalorian', 'Sci-Fi', 'United States', '2023-05-03', 40),
(6, 106, 'The Witcher', 'Fantasy', 'United States', '2023-05-03', 60),
(7, 107, 'Friends', 'Comedy', 'United States', '2023-05-01', 30),
(8, 108, 'Brooklyn Nine-Nine', 'Comedy', 'Canada', '2023-05-01', 25),
(9, 109, 'The Office', 'Comedy', 'United States', '2023-05-02', 35),
(10, 110, 'Parks and Recreation', 'Comedy', 'United States', '2023-05-02', 40),
(11, 111, 'Stranger Things', 'Drama', 'United States', '2023-05-03', 55),
(12, 112, 'Breaking Bad', 'Drama', 'United States', '2023-05-03', 60),
(13, 113, 'Game of Thrones', 'Fantasy', 'United States', '2023-05-01', 50),
(14, 114, 'The Witcher', 'Fantasy', 'United States', '2023-05-01', 55),
(15, 115, 'The Mandalorian', 'Sci-Fi', 'United States', '2023-05-02', 45),
(16, 116, 'Friends', 'Comedy', 'United States', '2023-05-02', 30),
(17, 117, 'The Office', 'Comedy', 'United States', '2023-05-03', 35),
(18, 118, 'Parks and Recreation', 'Comedy', 'Canada', '2023-05-03', 40);


output : 

+-----------------+---------+----------------+
| show_name       | genre   | total_duration |
+-----------------+---------+----------------+
| Friends         | Comedy  |             60 |
| The Office      | Comedy  |             70 |
| Breaking Bad    | Drama   |            110 |
| Stranger Things | Drama   |            115 |
| Game of Thrones | Fantasy |            105 |
| The Witcher     | Fantasy |            115 |
| The Mandalorian | Sci-Fi  |             85 |
+-----------------+---------+----------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 94 - GAP Sales

You have a table called gap_sales. Write an SQL query to find the total sales for each category in each store for the Q2(April-June) of  2023. Return the store ID, category name, and total sales for each category in each store. Sort the result by total sales in ascending order.

table : -- Create the gap_sales table
CREATE TABLE gap_sales (
    sale_id INT,
    store_id INT,
    sale_date DATE,
    category VARCHAR(20),
    total_sales INT
);

-- Insert data into the gap_sales table
INSERT INTO gap_sales (sale_id, store_id, sale_date, category, total_sales) VALUES
(1, 101, '2023-01-01', 'Clothing', 6000),
(2, 101, '2023-05-01', 'Outerwear', 2000),
(3, 101, '2023-05-02', 'Clothing', 4000),
(4, 101, '2023-05-02', 'Outerwear', 1500),
(5, 101, '2023-05-03', 'Clothing', 3500),
(6, 101, '2023-05-03', 'Outerwear', 2500),
(7, 102, '2023-05-01', 'Clothing', 7000),
(8, 102, '2023-06-01', 'Outerwear', 3000),
(9, 102, '2023-05-02', 'Clothing', 5000),
(10, 102, '2023-05-02', 'Outerwear', 2500),
(11, 102, '2023-05-03', 'Clothing', 4000),
(12, 102, '2023-04-03', 'Outerwear', 2000),
(13, 103, '2023-05-01', 'Clothing', 8000),
(14, 103, '2023-02-01', 'Outerwear', 3500),
(15, 103, '2023-05-02', 'Clothing', 6000),
(16, 103, '2023-05-02', 'Outerwear', 3000),
(17, 103, '2023-05-03', 'Clothing', 4500),
(18, 103, '2023-07-03', 'Outerwear', 2500);

output: 

+----------+-----------+-------------+
| store_id | category  | total_sales |
+----------+-----------+-------------+
|      103 | Outerwear |        3000 |
|      101 | Outerwear |        6000 |
|      101 | Clothing  |        7500 |
|      102 | Outerwear |        7500 |
|      102 | Clothing  |       16000 |
|      103 | Clothing  |       18500 |
+----------+-----------+-------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 95 - Electronics Items Sale

You have a table called electronic_items. Write an SQL query to find the average price of electronic items in each category, considering only categories where the average price exceeds 500 and at least 20 total quantity of items is available. Additionally, only include items with a warranty period of 12 months or more. Return the category name along with the average price of items in that category. Order the result by average price (round to 2 decimal places) in descending order

table : CREATE TABLE electronic_items (
    item_id INT,
    item_name VARCHAR(100),
    category VARCHAR(50),
    price DECIMAL(10, 2),
    quantity INT,
    warranty_months INT
);

INSERT INTO electronic_items (item_id, item_name, category, price, quantity, warranty_months) VALUES
(1, 'Laptop', 'Computers', 1000.0, 20, 24),
(2, 'Smartphone', 'Phones', 700.0, 50, 18),
(3, 'Television', 'TVs', 1500.0, 30, 12),
(4, 'Headphones', 'Accessories', 100.0, 100, 6),
(5, 'Tablet', 'Computers', 500.0, 40, 12),
(6, 'Smartwatch', 'Wearables', 300.0, 60, 24),
(7, 'Camera', 'Cameras', 800.0, 25, 12),
(8, 'Printer', 'Printers', 400.0, 15, 18),
(9, 'Bluetooth Speaker', 'Accessories', 150.0, 80, 12),
(10, 'Gaming Console', 'Gaming', 450.0, 35, 24);

output : 

+-----------+---------------+
| category  | average_price |
+-----------+---------------+
| TVs       |       1500.00 |
| Cameras   |        800.00 |
| Computers |        750.00 |
| Phones    |        700.00 |
+-----------+---------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 96 - Busiest Airline Route

You are given a table named "tickets" containing information about airline tickets sold. Write an SQL query to find the busiest route based on the total number of tickets sold. Also display total ticket count for that route.
oneway_round ='O' -> One Way Trip 
oneway_round ='R' -> Round Trip 
Note: DEL -> BOM is different route from BOM -> DEL

table :  CREATE TABLE tickets (
    airline_number VARCHAR(10),
    origin VARCHAR(10),
    destination VARCHAR(10),
    oneway_round CHAR(1),
    ticket_count INT
);

INSERT INTO tickets (airline_number, origin, destination, oneway_round, ticket_count) VALUES
('DEF456', 'BOM', 'DEL', 'O', 150),
('GHI789', 'DEL', 'BOM', 'R', 50),
('JKL012', 'BOM', 'DEL', 'R', 75),
('MNO345', 'DEL', 'NYC', 'O', 200),
('PQR678', 'NYC', 'DEL', 'O', 180),
('STU901', 'NYC', 'DEL', 'R', 60),
('ABC123', 'DEL', 'BOM', 'O', 100),
('VWX234', 'DEL', 'NYC', 'R', 90);

output : 

+--------+-------------+------+
| origin | destination | tc   |
+--------+-------------+------+
| DEL    | NYC         |  350 |
+--------+-------------+------+
---------------------------------------------------------------------------------------------------------------------------------------------

Q 97 - Domain Names

Write an SQL query to extract the domain names from email addresses stored in the Customers table.

table : CREATE TABLE customers (
    CustomerID INT,
    Email VARCHAR(100)
);

INSERT INTO customers (CustomerID, Email) VALUES
(1, 'john@gmail.com'),
(2, 'jane.doe@yahoo.org'),
(3, 'alice.smith@amazon.net'),
(4, 'bob@gmail.com'),
(5, 'charlie@microsoft.com');

output : 

+------------------------+---------------+
| Email                  | domain_name   |
+------------------------+---------------+
| john@gmail.com         | gmail.com     |
| jane.doe@yahoo.org     | yahoo.org     |
| alice.smith@amazon.net | amazon.net    |
| bob@gmail.com          | gmail.com     |
| charlie@microsoft.com  | microsoft.com |
+------------------------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 98 - Credit Card Transactions (Part-2)

You are given a history of credit card transaction data for the people of India across cities as below. Your task is to find out highest spend card type and lowest spent card type for each city, display the output in ascending order of city.

table : CREATE TABLE credit_card_transactions (
    transaction_id INT,
    city VARCHAR(50),
    transaction_date DATE,
    card_type VARCHAR(20),
    gender CHAR(1),
    amount DECIMAL(10, 2)
);

INSERT INTO credit_card_transactions (transaction_id, city, transaction_date, card_type, gender, amount) VALUES
(1, 'Delhi', '2024-01-13', 'Gold', 'F', 500),
(2, 'Bengaluru', '2024-01-13', 'Silver', 'M', 1000),
(3, 'Mumbai', '2024-01-14', 'Silver', 'F', 1200),
(4, 'Bengaluru', '2024-01-14', 'Gold', 'M', 900),
(5, 'Bengaluru', '2024-01-14', 'Gold', 'F', 300),
(6, 'Delhi', '2024-01-15', 'Silver', 'M', 200),
(7, 'Mumbai', '2024-01-15', 'Gold', 'F', 900),
(8, 'Delhi', '2024-01-15', 'Gold', 'F', 800),
(9, 'Mumbai', '2024-01-15', 'Silver', 'F', 150),
(10, 'Mumbai', '2024-01-16', 'Platinum', 'F', 1900),
(11, 'Bengaluru', '2024-01-16', 'Platinum', 'M', 1250),
(12, 'Delhi', '2024-01-16', 'Platinum', 'F', 130);

output : 

+-----------+----------------------+---------------------+
| city      | highest_expense_type | lowest_expense_type |
+-----------+----------------------+---------------------+
| Bengaluru | Platinum             | Silver              |
| Delhi     | Gold                 | Platinum            |
| Mumbai    | Platinum             | Gold                |
+-----------+----------------------+---------------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 99 - Most Visited Floor

You are a facilities manager at a corporate office building, responsible for tracking employee visits, floor preferences, and resource usage within the premises. The office building has multiple floors, each equipped with various resources such as desks, computers, monitors, and other office supplies. You have a database table “entries” that stores information about employee visits to the office building. Each record in the table represents a visit by an employee and includes details such as their name, the floor they visited, and the resources they used during their visit.
Write an SQL query to retrieve the total visits, most visited floor, and resources used by each employee, display the output in ascending order of employee name.

table : CREATE TABLE entries (
    emp_name VARCHAR(50),
    address VARCHAR(100),
    floor INT,
    resources VARCHAR(50)
);

INSERT INTO entries (emp_name, address, floor, resources) VALUES
('Ankit', 'Bangalore', 1, 'CPU'),
('Ankit', 'Bangalore', 1, 'CPU'),
('Ankit', 'Bangalore', 2, 'DESKTOP'),
('Bikaas', 'Bangalore', 2, 'DESKTOP'),
('Bikaas', 'Bangalore', 2, 'DESKTOP'),
('Bikaas', 'Bangalore', 1, 'MONITOR');

output : 

+----------+--------------+--------------------+-----------------+
| emp_name | total_visits | most_visited_floor | resources_used  |
+----------+--------------+--------------------+-----------------+
| Ankit    |            3 |                  1 | CPU,DESKTOP     |
| Bikaas   |            3 |                  2 | DESKTOP,MONITOR |
+----------+--------------+--------------------+-----------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 100 - Loyal Customers

In the domain of retail analytics, understanding customer behavior is crucial for driving business growth and enhancing customer satisfaction. One essential aspect is identifying customers who have purchased all available products, as they exhibit strong engagement with the product offerings and represent potential loyal customers.
Write an SQL to identify customers who have bought all the products available in products table along with total revenue generated by them. Sort the output by total revenue in decreasing order.

table : CREATE TABLE customers (
    customer_id INT,
    customer_name VARCHAR(100)
);

INSERT INTO customers (customer_id, customer_name) VALUES
(1, 'John Doe'),
(2, 'Jane Smith'),
(3, 'Alice Johnson'),
(4, 'Somnath');



CREATE TABLE products (
    product_id INT,
    product_name VARCHAR(100),
    unit_price DECIMAL(10, 2)
);

INSERT INTO products (product_id, product_name, unit_price) VALUES
(101, 'Product A', 150),
(102, 'Product B', 200),
(103, 'Product C', 250);



CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    product_id INT,
    quantity INT,
    order_date DATE
);

INSERT INTO orders (order_id, customer_id, product_id, quantity, order_date) VALUES
(1, 1, 101, 1, '2024-01-01'),
(2, 1, 102, 1, '2024-01-02'),
(3, 2, 101, 3, '2024-01-03'),
(4, 2, 102, 2, '2024-01-04'),
(5, 3, 103, 1, '2024-01-05'),
(6, 3, 101, 2, '2024-01-06'),
(7, 3, 102, 1, '2024-01-07'),
(8, 1, 102, 1, '2024-01-08'),
(9, 3, 103, 2, '2024-01-09'),
(10, 4, 102, 1, '2024-01-07'),
(11, 4, 101, 3, '2024-01-08'),
(12, 4, 103, 2, '2024-01-09');


output : 

+---------------+---------------+
| customer_name | total_revenue |
+---------------+---------------+
| Alice Johnson |          1250 |
| Somnath       |          1150 |
+---------------+---------------+
---------------------------------------------------------------------------------------------------------------------------------------------

Q 101 - Email Response Rate

Given a sample table with emails sent vs. received by the users, calculate the response rate (%) which is given as emails sent/ emails received. For simplicity consider sent emails are delivered. List all the users that fall under the top 25 percent based on the highest response rate.
Please consider users who have sent at least one email and have received at least one email.

table : CREATE TABLE gmail_data (
    from_user VARCHAR(50),
    to_user VARCHAR(50),
    email_day DATE
);

INSERT INTO gmail_data (from_user, to_user, email_day) VALUES
('a84065b7933ad01019', '75d295377a46f83236', '2023-11-28'),
('6b503743a13d778200', '32ded68d89443e808', '2023-12-29'),
('32ded68d89443e808', '55e60cfcc9dc49c17e', '2023-08-20'),
('157e3e9278e32aba3e', 'e0e0defbb9ec47f6f7', '2023-08-04'),
('114bafadff2d882864', '47be2887786891367e', '2023-07-04'),
('406539987dd9b679c0', '2813e59cf6c1ff698e', '2023-04-28'),
('6edf0be4b2267df1fa', 'a84065b7933ad01019', '2023-02-10'),
('a84065b7933ad01019', '850badf89ed8f06854', '2023-11-27'),
('d63386c884aeb9f71d', '6b503743a13d778200', '2023-11-08'),
('32ded68d89443e808', 'd63386c884aeb9f71d', '2023-01-28'),
('6edf0be4b2267df1fa', '5b8754928306a18b68', '2023-05-20'),
('6edf0be4b2267df1fa', '6edf0be4b2267df1fa', '2024-01-02'),
('6edf0be4b2267df1fa', '406539987dd9b679c0', '2023-06-13'),
('6edf0be4b2267df1fa', '114bafadff2d882864', '2023-05-18'),
('7cfe354d9a64bf8173', '157e3e9278e32aba3e', '2023-12-06'),
('32ded68d89443e808', '75d295377a46f83236', '2023-06-01'),
('75d295377a46f83236', 'd63386c884aeb9f71d', '2023-12-18'),
('114bafadff2d882864', '55e60cfcc9dc49c17e', '2023-04-22'),
('75d295377a46f83236', '47be2887786891367e', '2023-01-28'),
('32ded68d89443e808', '5b8754928306a18b68', '2023-11-21'),
('75d295377a46f83236', '850badf89ed8f06854', '2023-11-15'),
('75d295377a46f83236', '5eff3a5bfc0687351e', '2023-07-06'),
('7cfe354d9a64bf8173', '5dc768b2f067c56f77', '2023-09-21'),
('75d295377a46f83236', '114bafadff2d882864', '2024-01-14'),
('75d295377a46f83236', 'e0e0defbb9ec47f6f7', '2023-07-17'),
('75d295377a46f83236', '7cfe354d9a64bf8173', '2023-12-17'),
('5dc768b2f067c56f77', '114bafadff2d882864', '2023-10-12'),
('91f59516cb9dee1e88', '2813e59cf6c1ff698e', '2023-03-03'),
('5dc768b2f067c56f77', '91f59516cb9dee1e88', '2023-03-16'),
('5dc768b2f067c56f77', '5b8754928306a18b68', '2023-02-25');


output : 

+--------------------+---------------+
| user_id            | response_rate |
+--------------------+---------------+
| 6edf0be4b2267df1fa |     500.00000 |
| 32ded68d89443e808  |     400.00000 |
| 75d295377a46f83236 |     350.00000 |
+--------------------+---------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 102 - Users With Valid Passwords

Write a SQL query to identify the users with valid passwords according to the conditions below.

The password must be at least 8 characters long.
The password must contain at least one letter (lowercase or uppercase).
The password must contain at least one digit (0-9).
The password must contain at least one special character from the set @#$%^&*.
The password must not contain any spaces.

table : CREATE TABLE user_passwords (
    user_id INT,
    user_name VARCHAR(50),
    password VARCHAR(50)
);

INSERT INTO user_passwords (user_id, user_name, password) VALUES
(1, 'Arjun', 'password123@'),
(2, 'Rahul', 'rahul12'),
(3, 'Sneha', 'Sneha@123'),
(4, 'Vikram', 'Vikram$$$1234'),
(5, 'Priya', 'Priya12345@'),
(6, 'Amit', 'Amit*password 123'),
(7, 'Neha', 'Neha@#123'),
(8, 'Rohit', '@12345678');

output : 

CREATE TABLE user_passwords (
    user_id INT,
    user_name VARCHAR(50),
    password VARCHAR(50)
);

INSERT INTO user_passwords (user_id, user_name, password) VALUES
(1, 'Arjun', 'password123@'),
(2, 'Rahul', 'rahul12'),
(3, 'Sneha', 'Sneha@123'),
(4, 'Vikram', 'Vikram$$$1234'),
(5, 'Priya', 'Priya12345@'),
(6, 'Amit', 'Amit*password 123'),
(7, 'Neha', 'Neha@#123'),
(8, 'Rohit', '@12345678');


---------------------------------------------------------------------------------------------------------------------------------------------

Q 103 - Employee Mentor

You are given a table Employees that contains information about employees in a company. Each employee might have been mentored by another employee. Your task is to find the names of all employees who were not mentored by the employee with id = 3.

table : CREATE TABLE employees (
    id INT,
    name VARCHAR(50),
    mentor_id INT
);

INSERT INTO employees (id, name, mentor_id) VALUES
(1, 'Arjun', NULL),
(2, 'Sneha', 1),
(3, 'Vikram', NULL),
(4, 'Rahul', 3),
(5, 'Priya', 2),
(6, 'Neha', 3),
(7, 'Rohan', 1),
(8, 'Amit', 4);


output : 

+--------+
| name   |
+--------+
| Arjun  |
| Sneha  |
| Vikram |
| Priya  |
| Rohan  |
| Amit   |
+--------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 104 - Seasonal Trends

You're working for a retail company that sells various products. The company wants to identify seasonal trends in sales for its top-selling products across different regions. They are particularly interested in understanding the variation in sales volume across seasons for these products.
For each top-selling product in each region, calculate the total quantity sold for each season (spring, summer, autumn, winter) in 2023, display the output in ascending order of region name, product name & season name.

 
table : CREATE TABLE products (
    product_id INT,
    product_name VARCHAR(50)
);

INSERT INTO products (product_id, product_name) VALUES
(1, 'Apples'),
(2, 'Bananas'),
(3, 'Oranges');




CREATE TABLE sales (
    sale_id INT,
    product_id INT,
    region_name VARCHAR(50),
    sale_date DATE,
    quantity_sold INT
);

INSERT INTO sales (sale_id, product_id, region_name, sale_date, quantity_sold) VALUES
(1, 1, 'North America', '2023-03-15', 200),
(2, 1, 'North America', '2023-06-20', 300),
(3, 1, 'North America', '2023-09-10', 250),
(4, 1, 'North America', '2023-12-05', 400),
(5, 2, 'Europe', '2023-04-25', 150),
(6, 2, 'Europe', '2023-07-30', 200),
(7, 2, 'Europe', '2023-10-15', 180),
(8, 2, 'Europe', '2023-01-20', 220),
(9, 3, 'Asia', '2023-05-05', 300),
(10, 3, 'Asia', '2023-08-10', 350),
(11, 3, 'Asia', '2023-11-20', 400),
(12, 3, 'Asia', '2023-02-15', 280),
(13, 1, 'North America', '2023-04-01', 220),
(14, 1, 'North America', '2023-07-10', 320),
(15, 1, 'North America', '2023-10-20', 280),
(16, 1, 'North America', '2023-01-15', 450),
(17, 2, 'Europe', '2023-03-10', 180),
(18, 2, 'Europe', '2023-06-15', 250),
(19, 2, 'Europe', '2023-09-25', 200),
(20, 2, 'Europe', '2023-12-30', 300),
(21, 3, 'Asia', '2023-03-20', 320),
(22, 3, 'Asia', '2023-06-25', 380),
(23, 3, 'Asia', '2023-09-05', 400),
(24, 3, 'Asia', '2023-12-10', 350),
(25, 3, 'Asia', '2023-01-15', 180);





CREATE TABLE seasons (
    season_name VARCHAR(20),
    start_date DATE,
    end_date DATE
);

INSERT INTO seasons (season_name, start_date, end_date) VALUES
('Autumn', '2023-09-01', '2023-12-31'),
('Spring', '2023-03-01', '2023-05-31'),
('Summer', '2023-06-01', '2023-08-31'),
('Winter', '2023-01-01', '2023-02-28');




output : 

+---------------+--------------+-------------+---------------------+
| region_name   | product_name | season_name | total_quantity_sold |
+---------------+--------------+-------------+---------------------+
| Asia          | Oranges      | Autumn      |                1150 |
| Asia          | Oranges      | Spring      |                 620 |
| Asia          | Oranges      | Summer      |                 730 |
| Asia          | Oranges      | Winter      |                 460 |
| Europe        | Bananas      | Autumn      |                 680 |
| Europe        | Bananas      | Spring      |                 330 |
| Europe        | Bananas      | Summer      |                 450 |
| Europe        | Bananas      | Winter      |                 220 |
| North America | Apples       | Autumn      |                 930 |
| North America | Apples       | Spring      |                 420 |
| North America | Apples       | Summer      |                 620 |
| North America | Apples       | Winter      |                 450 |
+---------------+--------------+-------------+---------------------+



---------------------------------------------------------------------------------------------------------------------------------------------


Q You are provided with information about students enrolled in various courses at a university. Each student can be enrolled in multiple courses, and for each course, it is specified whether the course is a major or an elective for the student.
Write a SQL query to generate a report that lists the primary (major_flag='Y') course for each student. If a student is enrolled in only one course, that course should be considered their primary course by default irrespective of the flag. Sort the output by student_id.

table : 

CREATE TABLE student_courses (
    student_id INT,
    course_id INT,
    major_flag CHAR(1)
);

INSERT INTO student_courses (student_id, course_id, major_flag) VALUES
(1, 101, 'N'),
(2, 101, 'Y'),
(2, 102, 'N'),
(3, 103, 'Y'),
(4, 102, 'N'),
(4, 103, 'Y'),
(4, 104, 'N'),
(5, 104, 'N');

output : 

+------------+-----------+
| student_id | course_id |
+------------+-----------+
|          1 |       101 |
|          2 |       101 |
|          3 |       103 |
|          4 |       103 |
|          5 |       104 |
+------------+-----------+



---------------------------------------------------------------------------------------------------------------------------------------------

Q 106 - Subject Average Score

Write an SQL query to find the course names where the average score of students who scored less than 70 in at least one course is greater than 70. Sort the result by average score in descending order.

table : CREATE TABLE students (
    student_id INT,
    course_name VARCHAR(50),
    score INT
);

INSERT INTO students (student_id, course_name, score) VALUES
(1, 'Math', 85),
(1, 'Science', 65),
(2, 'Math', 90),
(2, 'Science', 75),
(3, 'Math', 60),
(3, 'Science', 70),
(4, 'Math', 95),
(4, 'Science', 85),
(5, 'Math', 50),
(5, 'Science', 80),
(6, 'English', 80),
(6, 'Science', 90),
(7, 'English', 91),
(7, 'History', 91),
(8, 'History', 87),
(8, 'Science', 69),
(8, 'English', 69);


output : 

+-------------+-----------+
| course_name | avg_score |
+-------------+-----------+
| History     |   87.0000 |
| Science     |   71.0000 |
+-------------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 107 - Contiguous Ranges

Write an SQL query to find all the contiguous ranges of log_id values.

table : CREATE TABLE logs (
    log_id INT
);

INSERT INTO logs (log_id) VALUES
(1),
(2),
(3),
(7),
(8),
(10),
(12),
(13),
(14),
(15),
(16),
(20);

output : 

+----------+--------+
| start_id | end_id |
+----------+--------+
|        1 |      3 |
|        7 |      8 |
|       10 |     10 |
|       12 |     16 |
|       20 |     20 |
+----------+--------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 108 - Products Sold in All Cities

A technology company operates in several major cities across India, selling a variety of tech products. The company wants to analyze its sales data to understand which products have been successfully sold in all the cities where they operate(available in cities table).
Write an SQL query to identify the product names that have been sold at least 2 times in every city where the company operates.


table : CREATE TABLE products (
    product_id INT,
    product_name VARCHAR(50)
);

INSERT INTO products (product_id, product_name) VALUES
(1, 'Laptop'),
(2, 'Smartphone'),
(3, 'Tablet'),
(4, 'Headphones'),
(5, 'Smartwatch');



CREATE TABLE cities (
    city_id INT,
    city_name VARCHAR(50)
);

INSERT INTO cities (city_id, city_name) VALUES
(1, 'Mumbai'),
(2, 'Delhi'),
(3, 'Bangalore'),
(4, 'Chennai'),
(5, 'Hyderabad');




CREATE TABLE sales (
    sale_id INT,
    product_id INT,
    city_id INT,
    sale_date DATE,
    quantity INT
);

INSERT INTO sales (sale_id, product_id, city_id, sale_date, quantity) VALUES
(1, 1, 1, '2024-01-01', 30),
(2, 1, 1, '2024-01-02', 40),
(3, 1, 2, '2024-01-03', 25),
(4, 1, 2, '2024-01-04', 35),
(5, 1, 3, '2024-01-05', 50),
(6, 1, 3, '2024-01-06', 60),
(7, 1, 4, '2024-01-07', 45),
(8, 1, 4, '2024-01-08', 55),
(9, 1, 5, '2024-01-09', 30),
(10, 1, 5, '2024-01-10', 40),
(11, 2, 1, '2024-01-11', 20),
(12, 2, 1, '2024-01-12', 30),
(13, 2, 2, '2024-01-13', 35),
(14, 2, 2, '2024-01-14', 45),
(15, 2, 3, '2024-01-15', 50),
(16, 2, 3, '2024-01-16', 60),
(17, 2, 4, '2024-01-17', 55),
(18, 2, 4, '2024-01-18', 65),
(21, 3, 1, '2024-01-01', 10),
(22, 3, 1, '2024-01-02', 20),
(23, 3, 2, '2024-01-03', 25),
(24, 3, 2, '2024-01-04', 35),
(25, 3, 3, '2024-01-05', 30),
(26, 3, 3, '2024-01-06', 40),
(27, 3, 4, '2024-01-07', 45),
(28, 3, 4, '2024-01-08', 55),
(29, 3, 5, '2024-01-09', 30),
(31, 4, 1, '2024-01-01', 30),
(32, 4, 1, '2024-01-02', 40),
(33, 4, 2, '2024-01-03', 35),
(34, 4, 2, '2024-01-04', 45),
(35, 4, 3, '2024-01-05', 50),
(36, 4, 3, '2024-01-06', 60),
(37, 4, 4, '2024-01-07', 55),
(38, 4, 4, '2024-01-08', 65),
(39, 4, 5, '2024-01-09', 40),
(40, 4, 5, '2024-01-10', 50),
(41, 5, 1, '2024-01-01', 20),
(42, 5, 1, '2024-01-02', 30),
(43, 5, 2, '2024-01-03', 35),
(44, 5, 2, '2024-01-04', 45),
(45, 5, 3, '2024-01-05', 50),
(46, 5, 3, '2024-01-06', 60),
(47, 5, 4, '2024-01-07', 55),
(48, 5, 4, '2024-01-08', 65),
(49, 5, 5, '2024-01-09', 40),
(50, 5, 5, '2024-01-10', 50),
(51, 5, 5, '2024-01-11', 50);


output : 

+--------------+
| product_name |
+--------------+
| Headphones   |
| Laptop       |
| Smartwatch   |
+--------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 109 - Top 5 Single-Purchase Spendings

Write an SQL to retrieve the top 5 customers who have spent the most on their single purchase. Sort the result by max single purchase in descending order.

table : CREATE TABLE purchase (
    customer_id INT,
    purchase_date DATE,
    amount DECIMAL(10, 2)
);

INSERT INTO purchase (customer_id, purchase_date, amount) VALUES
(1, '2024-07-01', 1500),
(1, '2024-07-05', 3000),
(1, '2024-07-10', 1200),
(2, '2024-07-02', 5000),
(2, '2024-07-07', 2000),
(2, '2024-07-15', 3200),
(3, '2024-07-03', 1800),
(3, '2024-07-10', 2400),
(3, '2024-07-20', 3100),
(4, '2024-07-04', 2200),
(4, '2024-07-08', 4100),
(4, '2024-07-18', 3500),
(5, '2024-07-05', 6000),
(5, '2024-07-09', 2700),
(5, '2024-07-22', 5300),
(6, '2024-07-06', 2800),
(6, '2024-07-11', 1500),
(6, '2024-07-25', 2600),
(7, '2024-07-07', 3200),
(7, '2024-07-12', 4700),
(7, '2024-07-19', 5400),
(8, '2024-07-08', 3800),
(8, '2024-07-13', 2900),
(8, '2024-07-23', 4400),
(9, '2024-07-09', 4100),
(9, '2024-07-14', 3300),
(9, '2024-07-26', 3700),
(10, '2024-07-10', 4600),
(10, '2024-07-15', 2500),
(10, '2024-07-27', 5100);


output : 

+-------------+------------+
| customer_id | max_amount |
+-------------+------------+
|           5 |       6000 |
|           7 |       5400 |
|          10 |       5100 |
|           2 |       5000 |
|           8 |       4400 |
+-------------+------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 110 - Laptop to Laptop Bag Conversion Rate


The marketing team at a retail company wants to analyze customer purchasing behavior. They are particularly interested in understanding how many customers who bought a laptop later went on to purchase a laptop bag, with no intermediate purchases in between. Write an SQL to get number of customer in each country who bought laptop and number of customers who bought laptop bag just after buying a laptop. Order the result by country.

table : CREATE TABLE transactions (
    transaction_id INT,
    customer_id INT,
    product_name VARCHAR(50),
    transaction_timestamp DATETIME,
    country VARCHAR(50)
);

INSERT INTO transactions (transaction_id, customer_id, product_name, transaction_timestamp, country) VALUES
(1, 101, 'Laptop', '2024-01-01 10:00:00', 'India'),
(2, 101, 'Laptop Bag', '2024-01-01 10:05:00', 'India'),
(3, 101, 'Mouse', '2024-01-02 12:00:00', 'India'),
(4, 102, 'Tablet', '2024-01-03 14:00:00', 'India'),
(5, 102, 'Laptop', '2024-01-04 14:00:00', 'India'),
(6, 102, 'Laptop Bag', '2024-01-04 14:05:00', 'India'),
(7, 103, 'Laptop', '2024-01-05 15:00:00', 'India'),
(8, 103, 'Smartphone', '2024-01-06 16:00:00', 'India'),
(9, 103, 'Laptop Bag', '2024-01-06 16:05:00', 'India'),
(10, 201, 'Keyboard', '2024-01-07 09:00:00', 'USA'),
(11, 201, 'Laptop Bag', '2024-01-07 09:10:00', 'USA'),
(12, 201, 'Laptop', '2024-01-07 09:15:00', 'USA'),
(13, 202, 'Mouse', '2024-01-08 10:00:00', 'USA'),
(14, 202, 'Charger', '2024-01-09 11:00:00', 'USA'),
(15, 202, 'Laptop', '2024-01-09 11:05:00', 'USA'),
(16, 203, 'Laptop', '2024-01-11 13:00:00', 'USA'),
(17, 203, 'Laptop Bag', '2024-01-11 13:05:00', 'USA'),
(18, 203, 'Headphones', '2024-01-12 14:00:00', 'USA'),
(19, 301, 'Tablet', '2024-01-13 15:00:00', 'UK'),
(20, 301, 'Laptop', '2024-01-13 15:05:00', 'UK'),
(21, 301, 'Charger', '2024-01-14 16:00:00', 'UK'),
(22, 302, 'Laptop', '2024-01-15 17:00:00', 'UK'),
(23, 302, 'Laptop Bag', '2024-01-15 17:05:00', 'UK'),
(24, 303, 'Smartwatch', '2024-01-16 18:00:00', 'UK'),
(25, 303, 'Laptop', '2024-01-17 19:00:00', 'UK'),
(26, 303, 'Laptop Bag', '2024-01-17 19:05:00', 'UK'),
(27, 304, 'Headphones', '2024-01-18 10:00:00', 'UK'),
(28, 304, 'Charger', '2024-01-18 11:00:00', 'UK');

output : 

+---------+------------------+----------------------+
| country | laptop_customers | laptop_bag_customers |
+---------+------------------+----------------------+
| India   |                3 |                    2 |
| UK      |                3 |                    2 |
| USA     |                3 |                    1 |
+---------+------------------+----------------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 111 - Hierarchy Reportee Count


Write a SQL query to find the number of reportees (both direct and indirect) under each manager. The output should include:

m_id: The manager ID.

num_of_reportees: The total number of unique reportees (both direct and indirect) under that manager.

Order the result by number of reportees in descending order.


table : CREATE TABLE hierarchy (
    e_id CHAR(1),
    m_id CHAR(1)
);

INSERT INTO hierarchy (e_id, m_id) VALUES
('A', 'C'),
('B', 'C'),
('C', 'F'),
('D', 'E'),
('E', 'F'),
('G', 'E'),
('H', 'G'),
('I', 'F'),
('J', 'I'),
('K', 'I');

output : 

+------+------------------+
| m_id | num_of_reportees |
+------+------------------+
| F    |               10 |
| E    |                3 |
| C    |                2 |
| I    |                2 |
| G    |                1 |
+------+------------------+

---------------------------------------------------------------------------------------------------------------------------------------------

Q 112 - Reel Daily View Averages by State

Meta (formerly Facebook) is analyzing the performance of Instagram Reels across different states in the USA. You have access to a table named REEL that tracks the cumulative views of each reel over time. Write an SQL to get average daily views for each Instagram Reel in each state. Round the average to 2 decimal places and sort the result by average is descending order. 

table : CREATE TABLE reel (
    reel_id INT,
    record_date DATE,
    state VARCHAR(50),
    cumulative_views INT
);

INSERT INTO reel (reel_id, record_date, state, cumulative_views) VALUES
(1, '2024-08-01', 'california', 1000),
(1, '2024-08-02', 'california', 1500),
(1, '2024-08-03', 'california', 2000),
(1, '2024-08-04', 'california', 2500),
(1, '2024-08-05', 'california', 3000),
(1, '2024-08-01', 'nevada', 800),
(1, '2024-08-02', 'nevada', 1200),
(1, '2024-08-03', 'nevada', 1600),
(1, '2024-08-04', 'nevada', 2000),
(1, '2024-08-05', 'nevada', 2400),
(1, '2024-08-06', 'nevada', 2800),
(1, '2024-08-07', 'nevada', 3200),
(2, '2024-08-01', 'texas', 500),
(2, '2024-08-02', 'texas', 1000),
(2, '2024-08-03', 'texas', 1500),
(2, '2024-08-04', 'texas', 2000),
(2, '2024-08-05', 'texas', 2500),
(2, '2024-08-01', 'florida', 700),
(2, '2024-08-02', 'florida', 1300),
(2, '2024-08-03', 'florida', 1800),
(2, '2024-08-04', 'florida', 2300),
(2, '2024-08-05', 'florida', 2800),
(2, '2024-08-06', 'florida', 3300),
(2, '2024-08-07', 'florida', 3800);

output : 

+---------+------------+-----------------+
| Reel_id | State      | Avg_Daily_Views |
+---------+------------+-----------------+
|       1 | california |          600.00 |
|       2 | florida    |          542.86 |
|       2 | texas      |          500.00 |
|       1 | nevada     |          457.14 |
+---------+------------+-----------------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 113 - Cab Driver Streak


A Cab booking company has a dataset of its trip ratings, each row represents a single trip of a driver. A trip has a positive rating if it was rated 4 or above, a streak of positive ratings is when a driver has a rating of 4 and above in consecutive trips. example: If there are 3 consecutive trips with a rating of 4 or above then the streak is 2.
Find out the maximum streak that a driver has had and sort the output in descending order of their maximum streak and then by descending order of driver_id.
Note: only users who have at least 1 streak should be included in the output.

table : CREATE TABLE rating_table (
    trip_time DATETIME,
    driver_id CHAR(1),
    trip_id INT,
    rating INT
);

INSERT INTO rating_table (trip_time, driver_id, trip_id, rating) VALUES
('2023-04-24 10:15:00', 'a', 0, 4),
('2023-04-24 15:20:27', 'a', 1, 5),
('2023-04-24 22:32:27', 'a', 2, 5),
('2023-04-25 08:00:00', 'a', 3, 3),
('2023-04-25 12:00:00', 'a', 4, 4),
('2023-04-25 12:30:00', 'a', 5, 5),
('2023-04-24 09:15:00', 'b', 6, 4),
('2023-04-24 13:20:00', 'b', 7, 4),
('2023-04-25 09:45:00', 'b', 8, 3),
('2023-04-25 11:30:00', 'b', 9, 4),
('2023-04-25 14:00:00', 'b', 10, 5),
('2023-04-24 08:30:00', 'c', 11, 5),
('2023-04-24 12:45:00', 'c', 12, 4),
('2023-04-24 17:00:00', 'c', 13, 5),
('2023-04-25 10:30:00', 'c', 14, 4),
('2023-04-25 15:00:00', 'c', 15, 3),
('2023-04-24 11:00:00', 'd', 16, 2),
('2023-04-24 14:20:00', 'd', 17, 4),
('2023-04-24 18:40:00', 'd', 18, 5),
('2023-04-25 13:30:00', 'd', 19, 2),
('2023-04-25 17:20:00', 'd', 20, 1),
('2023-04-24 12:00:00', 'e', 21, 2),
('2023-04-24 14:45:00', 'e', 22, 5),
('2023-04-24 17:30:00', 'e', 23, 2),
('2023-04-25 09:15:00', 'e', 24, 4),
('2023-04-25 12:45:00', 'e', 25, 3);


output : 

+-----------+------------+
| driver_id | max_streak |
+-----------+------------+
| c         |          3 |
| a         |          2 |
| d         |          1 |
| b         |          1 |
+-----------+------------+



---------------------------------------------------------------------------------------------------------------------------------------------

Q 114 - Tournament Group Winners

You are given two tables, players and matches, with the following structure.

Each record in the table players represents a single player in the tournament. The column player_id contains the ID of each player. The column group_id contains the ID of the group each player belongs to.

Each record in the table matches represents a single match in the group stage. The column first_player (second_player) contains the ID of the first player (second player) in each match. The column first_score (second_score) contains the number of points scored by the first player (second player) in each match. You may assume that, in each match, players belong to the same group.

Write an SQL to compute the winner in each group. The winner in each group is the player who scored the maximum total number of points within the group. If there is more than one such player, the winner is the one with the highest ID. Write an SQL query that returns a table containing the winner of each group. Each record should contain the ID of the group and the ID of the winner in this group. Records should be sorted by group id. 

table : CREATE TABLE players (
    player_id INT,
    group_id INT
);

INSERT INTO players (player_id, group_id) VALUES
(1, 1),
(2, 1),
(3, 1),
(4, 1),
(5, 2),
(6, 2),
(7, 2),
(8, 2),
(9, 3),
(10, 3),
(11, 3),
(12, 3);




CREATE TABLE matches (
    match_id INT,
    first_player INT,
    second_player INT,
    first_score INT,
    second_score INT
);

INSERT INTO matches (match_id, first_player, second_player, first_score, second_score) VALUES
(1, 1, 2, 8, 5),
(2, 3, 4, 4, 2),
(3, 1, 3, 3, 2),
(4, 2, 4, 2, 9),
(5, 5, 6, 4, 9),
(6, 7, 8, 5, 5),
(7, 5, 7, 4, 4),
(8, 6, 8, 3, 2),
(9, 9, 10, 3, 1),
(10, 11, 12, 4, 2),
(11, 9, 11, 5, 5),
(12, 10, 12, 6, 4),
(13, 11, 12, 6, 3);


output : 

+----------+-----------+
| group_id | winner_id |
+----------+-----------+
|        1 |         4 |
|        2 |         6 |
|        3 |        11 |
+----------+-----------+


---------------------------------------------------------------------------------------------------------------------------------------------

Q 115 - Sequence Expansion

You have a table named numbers containing a single column n. You are required to generate an output that expands each number n into a sequence where the number appears n times.

table : CREATE TABLE numbers (
    n INT
);

INSERT INTO numbers (n) VALUES
(1),
(2),
(3),
(4),
(7);

output : 

+-----------------+
| expanded_number |
+-----------------+
|               1 |
|               2 |
|               2 |
|               3 |
|               3 |
|               3 |
|               4 |
|               4 |
|               4 |
|               4 |
|               7 |
|               7 |
|               7 |
|               7 |
|               7 |
|               7 |
|               7 |
+-----------------+


---------------------------------------------------------------------------------------------------------------------------------------------


Q 116 - Goals Scored in Each Game


Please refer to the 3 tables below from a football tournament. Write an SQL which lists every game with the goals scored by each team. The result set should show: match id, match date, team1, score1, team2, score2. Sort the result by match id.

Please note that score1 and score2 should be number of goals scored by team1 and team2 respectively.


table : CREATE TABLE team (
    id INT,
    name VARCHAR(50),
    coach VARCHAR(50)
);

INSERT INTO team (id, name, coach) VALUES
(1, 'Mumbai FC', 'Sunil Chhetri'),
(2, 'Delhi Dynamos', 'Sandesh Jhingan'),
(3, 'Bengaluru FC', 'Gurpreet Singh'),
(4, 'Goa FC', 'Brandon Fernandes');




CREATE TABLE game (
    match_id INT,
    match_date DATE,
    stadium VARCHAR(50),
    team1 INT,
    team2 INT
);

INSERT INTO game (match_id, match_date, stadium, team1, team2) VALUES
(1, '2024-09-01', 'Wankhede', 1, 2),
(2, '2024-09-02', 'Jawaharlal Nehru', 3, 4),
(3, '2024-09-03', 'Sree Kanteerava', 1, 3),
(4, '2024-09-04', 'Wankhede', 1, 4);





CREATE TABLE goal (
    match_id INT,
    team_id INT,
    player VARCHAR(50),
    goal_time TIME
);

INSERT INTO goal (match_id, team_id, player, goal_time) VALUES
(1, 1, 'Anirudh Thapa', '18:23:00'),
(1, 1, 'Sunil Chhetri', '67:12:00'),
(2, 3, 'Udanta Singh', '22:45:00'),
(2, 4, 'Ferran Corominas', '55:21:00'),
(2, 3, 'Sunil Chhetri', '78:34:00'),
(2, 3, 'Sunil Chhetri', '80:34:00'),
(3, 1, 'Bipin Singh', '11:08:00'),
(3, 3, 'Cleiton Silva', '41:20:00'),
(3, 1, 'Sunil Chhetri', '59:45:00'),
(3, 3, 'Cleiton Silva', '62:56:00');


output : 

+----------+------------+-------+--------+-------+--------+
| match_id | match_date | team1 | score1 | team2 | score2 |
+----------+------------+-------+--------+-------+--------+
|        1 | 2024-09-01 |     1 |      2 |     2 |      0 |
|        2 | 2024-09-02 |     3 |      3 |     4 |      1 |
|        3 | 2024-09-03 |     1 |      2 |     3 |      2 |
|        4 | 2024-09-04 |     1 |      0 |     4 |      0 |
+----------+------------+-------+--------+-------+--------+



---------------------------------------------------------------------------------------------------------------------------------------------